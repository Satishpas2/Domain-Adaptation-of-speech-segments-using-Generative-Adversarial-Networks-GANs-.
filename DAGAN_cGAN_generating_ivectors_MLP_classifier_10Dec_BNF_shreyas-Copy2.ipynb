{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/train_feat_BNF_h5_07Nov_Shreyas.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>langid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.141175</td>\n",
       "      <td>-1.160019</td>\n",
       "      <td>0.891814</td>\n",
       "      <td>1.898842</td>\n",
       "      <td>0.393065</td>\n",
       "      <td>0.983582</td>\n",
       "      <td>-0.559143</td>\n",
       "      <td>-0.761900</td>\n",
       "      <td>0.525598</td>\n",
       "      <td>0.344597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587687</td>\n",
       "      <td>-0.609223</td>\n",
       "      <td>1.529694</td>\n",
       "      <td>1.677775</td>\n",
       "      <td>-0.388426</td>\n",
       "      <td>1.044584</td>\n",
       "      <td>-1.365691</td>\n",
       "      <td>-0.354752</td>\n",
       "      <td>-0.815562</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971834</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>0.785385</td>\n",
       "      <td>1.328749</td>\n",
       "      <td>-0.043342</td>\n",
       "      <td>1.219254</td>\n",
       "      <td>0.761090</td>\n",
       "      <td>1.069464</td>\n",
       "      <td>0.879541</td>\n",
       "      <td>0.898939</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208031</td>\n",
       "      <td>0.527433</td>\n",
       "      <td>-0.709180</td>\n",
       "      <td>-1.117489</td>\n",
       "      <td>0.566520</td>\n",
       "      <td>1.642208</td>\n",
       "      <td>-0.703815</td>\n",
       "      <td>0.376027</td>\n",
       "      <td>-1.425985</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.315703</td>\n",
       "      <td>-0.868423</td>\n",
       "      <td>0.619893</td>\n",
       "      <td>1.717784</td>\n",
       "      <td>-0.846024</td>\n",
       "      <td>1.177214</td>\n",
       "      <td>-0.191977</td>\n",
       "      <td>-0.658569</td>\n",
       "      <td>0.529625</td>\n",
       "      <td>0.313590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896515</td>\n",
       "      <td>-0.128051</td>\n",
       "      <td>-0.075781</td>\n",
       "      <td>1.307904</td>\n",
       "      <td>-1.443047</td>\n",
       "      <td>2.551083</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>-0.623076</td>\n",
       "      <td>0.194851</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247949</td>\n",
       "      <td>-0.279720</td>\n",
       "      <td>1.320115</td>\n",
       "      <td>1.772152</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>-0.290516</td>\n",
       "      <td>0.406225</td>\n",
       "      <td>-0.833366</td>\n",
       "      <td>1.567592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.398762</td>\n",
       "      <td>-0.078148</td>\n",
       "      <td>0.168076</td>\n",
       "      <td>-0.272796</td>\n",
       "      <td>-1.102862</td>\n",
       "      <td>0.358274</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>-0.490244</td>\n",
       "      <td>1.819196</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.986578</td>\n",
       "      <td>-0.357548</td>\n",
       "      <td>1.550832</td>\n",
       "      <td>1.400735</td>\n",
       "      <td>0.444350</td>\n",
       "      <td>0.465660</td>\n",
       "      <td>0.209248</td>\n",
       "      <td>1.175847</td>\n",
       "      <td>-1.079963</td>\n",
       "      <td>0.270915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947946</td>\n",
       "      <td>0.917957</td>\n",
       "      <td>-1.043352</td>\n",
       "      <td>0.414811</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>-0.485602</td>\n",
       "      <td>-0.433002</td>\n",
       "      <td>-0.432070</td>\n",
       "      <td>0.778250</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.141175 -1.160019  0.891814  1.898842  0.393065  0.983582 -0.559143   \n",
       "1  0.971834  0.035743  0.785385  1.328749 -0.043342  1.219254  0.761090   \n",
       "2 -0.315703 -0.868423  0.619893  1.717784 -0.846024  1.177214 -0.191977   \n",
       "3  0.247949 -0.279720  1.320115  1.772152 -0.130394  0.517343 -0.290516   \n",
       "4 -0.986578 -0.357548  1.550832  1.400735  0.444350  0.465660  0.209248   \n",
       "\n",
       "          7         8         9   ...          491       492       493  \\\n",
       "0 -0.761900  0.525598  0.344597   ...     1.587687 -0.609223  1.529694   \n",
       "1  1.069464  0.879541  0.898939   ...    -1.208031  0.527433 -0.709180   \n",
       "2 -0.658569  0.529625  0.313590   ...    -0.896515 -0.128051 -0.075781   \n",
       "3  0.406225 -0.833366  1.567592   ...    -0.398762 -0.078148  0.168076   \n",
       "4  1.175847 -1.079963  0.270915   ...     0.947946  0.917957 -1.043352   \n",
       "\n",
       "        494       495       496       497       498       499   langid  \n",
       "0  1.677775 -0.388426  1.044584 -1.365691 -0.354752 -0.815562  spa-eur  \n",
       "1 -1.117489  0.566520  1.642208 -0.703815  0.376027 -1.425985  spa-eur  \n",
       "2  1.307904 -1.443047  2.551083  0.436309 -0.623076  0.194851  spa-eur  \n",
       "3 -0.272796 -1.102862  0.358274  0.090417 -0.490244  1.819196  spa-eur  \n",
       "4  0.414811  0.016396 -0.485602 -0.433002 -0.432070  0.778250  spa-eur  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langid\n",
       "ara-acm    1406\n",
       "ara-apc    3509\n",
       "ara-ary     919\n",
       "ara-arz     440\n",
       "eng-gbr      98\n",
       "eng-usg    2448\n",
       "por-brz     444\n",
       "qsl-pol     587\n",
       "qsl-rus    1221\n",
       "spa-car     688\n",
       "spa-eur     121\n",
       "spa-lac     898\n",
       "zho-cmn    3331\n",
       "zho-nan      95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre.groupby(['langid']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/dev_feat_BNF_h5_07Nov_Shreyas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_lre = val_lre.iloc[100:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmentid</th>\n",
       "      <th>language_code</th>\n",
       "      <th>data_source</th>\n",
       "      <th>speech_duration</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>uttid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lre17_ntrlosgu.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.697234</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>-0.400756</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>-0.939232</td>\n",
       "      <td>1.500797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.314428</td>\n",
       "      <td>-0.927694</td>\n",
       "      <td>-0.370424</td>\n",
       "      <td>-0.514735</td>\n",
       "      <td>1.290885</td>\n",
       "      <td>0.688205</td>\n",
       "      <td>-0.494330</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>-1.330860</td>\n",
       "      <td>lre17_ntrlosgu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lre17_moxnwuqe.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.648232</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>-0.562867</td>\n",
       "      <td>1.035870</td>\n",
       "      <td>-1.577741</td>\n",
       "      <td>1.593584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929262</td>\n",
       "      <td>-1.301574</td>\n",
       "      <td>2.034934</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>-0.198926</td>\n",
       "      <td>-0.116174</td>\n",
       "      <td>0.347923</td>\n",
       "      <td>-0.870801</td>\n",
       "      <td>-2.599601</td>\n",
       "      <td>lre17_moxnwuqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lre17_meesvkxz.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242829</td>\n",
       "      <td>0.675515</td>\n",
       "      <td>-0.371491</td>\n",
       "      <td>0.534970</td>\n",
       "      <td>-0.246783</td>\n",
       "      <td>0.806262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691336</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>1.058771</td>\n",
       "      <td>1.018635</td>\n",
       "      <td>-1.929319</td>\n",
       "      <td>-0.307404</td>\n",
       "      <td>-0.486431</td>\n",
       "      <td>-2.839053</td>\n",
       "      <td>-2.704527</td>\n",
       "      <td>lre17_meesvkxz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lre17_rqmsmzui.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.226681</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>-0.396915</td>\n",
       "      <td>-0.097507</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>1.087025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049862</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>2.385587</td>\n",
       "      <td>0.680073</td>\n",
       "      <td>1.500978</td>\n",
       "      <td>1.660566</td>\n",
       "      <td>-0.370672</td>\n",
       "      <td>-0.924109</td>\n",
       "      <td>0.096676</td>\n",
       "      <td>lre17_rqmsmzui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lre17_qgszpuyw.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.411728</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>0.136256</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>-1.029447</td>\n",
       "      <td>1.227100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>-1.030222</td>\n",
       "      <td>2.933880</td>\n",
       "      <td>-1.417872</td>\n",
       "      <td>-0.227513</td>\n",
       "      <td>0.748810</td>\n",
       "      <td>-0.671044</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>1.722917</td>\n",
       "      <td>lre17_qgszpuyw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            segmentid language_code data_source  speech_duration         0  \\\n",
       "0  lre17_ntrlosgu.sph       ara-acm       mls14               30  1.697234   \n",
       "1  lre17_moxnwuqe.sph       ara-acm       mls14               10  1.648232   \n",
       "2  lre17_meesvkxz.sph       ara-acm       mls14                3  1.242829   \n",
       "3  lre17_rqmsmzui.sph       ara-acm       mls14               30  1.226681   \n",
       "4  lre17_qgszpuyw.sph       ara-acm       mls14               10  1.411728   \n",
       "\n",
       "          1         2         3         4         5       ...             491  \\\n",
       "0  0.029428 -0.400756  0.513963 -0.939232  1.500797       ...       -1.314428   \n",
       "1 -0.053318 -0.562867  1.035870 -1.577741  1.593584       ...       -0.929262   \n",
       "2  0.675515 -0.371491  0.534970 -0.246783  0.806262       ...        0.691336   \n",
       "3  0.014810 -0.396915 -0.097507 -0.013574  1.087025       ...        1.049862   \n",
       "4 -0.119300  0.136256  0.030535 -1.029447  1.227100       ...        0.155196   \n",
       "\n",
       "        492       493       494       495       496       497       498  \\\n",
       "0 -0.927694 -0.370424 -0.514735  1.290885  0.688205 -0.494330 -0.053206   \n",
       "1 -1.301574  2.034934 -0.226545 -0.198926 -0.116174  0.347923 -0.870801   \n",
       "2  0.257988  1.058771  1.018635 -1.929319 -0.307404 -0.486431 -2.839053   \n",
       "3  0.285627  2.385587  0.680073  1.500978  1.660566 -0.370672 -0.924109   \n",
       "4 -1.030222  2.933880 -1.417872 -0.227513  0.748810 -0.671044  0.595977   \n",
       "\n",
       "        499           uttid  \n",
       "0 -1.330860  lre17_ntrlosgu  \n",
       "1 -2.599601  lre17_moxnwuqe  \n",
       "2 -2.704527  lre17_meesvkxz  \n",
       "3  0.096676  lre17_rqmsmzui  \n",
       "4  1.722917  lre17_qgszpuyw  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_lre.drop(\"langid\",axis=1)\n",
    "y_train = train_lre[\"langid\"]\n",
    "#y_train_uttid = train_lre[\"uttid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val, ignore_index=True)\n",
    "y_train = y_train.append(y_val, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_val=X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = indices_to_one_hot(y_train, 14)\n",
    "#Y_test = indices_to_one_hot(y_test, 14)\n",
    "Y_val = indices_to_one_hot(y_val_labels, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19866, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (19866, 500)\n",
      "19866 train samples\n",
      "3661 val samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_val.shape[0], 'val samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19866, 500)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19866,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 13, 13, 13])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Shuffling the dataset\n",
    "#from sklearn.utils import shuffle\n",
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val,  y_val_labels = shuffle(X_val, y_val_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets('/home/satishk/depy_04_AUG/MNIST_data', one_hot=True)\n",
    "mb_size = 256\n",
    "Z_dim = 100\n",
    "X_dim = 500 #mnist.train.images.shape[1]\n",
    "y_dim = 14 #mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dim, y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z, c):\n",
    "    inputs = torch.cat([z, c], 1)\n",
    "    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim + y_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X, c):\n",
    "    inputs = torch.cat([X, c], 1)\n",
    "    h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "#ones_label = Variable(torch.ones(mb_size))\n",
    "#zeros_label = Variable(torch.zeros(mb_size))\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D1 = D(X,c)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15892"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter-0; D_loss: [ 1.53428566]; G_loss: [ 1.3979311]\n",
      "Iter-256; D_loss: [ 0.87782794]; G_loss: [ 2.44839811]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satishk/miniconda3/envs/lre17/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-512; D_loss: [ 0.5587368]; G_loss: [ 3.41978192]\n",
      "Iter-768; D_loss: [ 0.50642383]; G_loss: [ 4.20574856]\n",
      "Iter-1024; D_loss: [ 0.40034553]; G_loss: [ 4.76548433]\n",
      "Iter-1280; D_loss: [ 0.39834353]; G_loss: [ 5.22049379]\n",
      "Iter-1536; D_loss: [ 0.39750904]; G_loss: [ 5.39756298]\n",
      "Iter-1792; D_loss: [ 0.31037632]; G_loss: [ 5.61820459]\n",
      "Iter-2048; D_loss: [ 0.30467823]; G_loss: [ 5.63906097]\n",
      "Iter-2304; D_loss: [ 0.28693113]; G_loss: [ 5.65569162]\n",
      "Iter-2560; D_loss: [ 0.29550597]; G_loss: [ 5.61976337]\n",
      "Iter-2816; D_loss: [ 0.23633674]; G_loss: [ 5.54236984]\n",
      "Iter-3072; D_loss: [ 0.23121814]; G_loss: [ 5.47022247]\n",
      "Iter-3328; D_loss: [ 0.22784665]; G_loss: [ 5.23691225]\n",
      "Iter-3584; D_loss: [ 0.17359026]; G_loss: [ 5.09036303]\n",
      "Iter-3840; D_loss: [ 0.16058324]; G_loss: [ 4.86038017]\n",
      "Iter-4096; D_loss: [ 0.14604063]; G_loss: [ 4.69766712]\n",
      "Iter-4352; D_loss: [ 0.1613127]; G_loss: [ 4.52107811]\n",
      "Iter-4608; D_loss: [ 0.11031771]; G_loss: [ 4.28152323]\n",
      "Iter-4864; D_loss: [ 0.1343632]; G_loss: [ 4.13043976]\n",
      "Iter-5120; D_loss: [ 0.1418384]; G_loss: [ 3.86312008]\n",
      "Iter-5376; D_loss: [ 0.14369348]; G_loss: [ 3.79124117]\n",
      "Iter-5632; D_loss: [ 0.11480696]; G_loss: [ 3.7263701]\n",
      "Iter-5888; D_loss: [ 0.13409294]; G_loss: [ 3.63535547]\n",
      "Iter-6144; D_loss: [ 0.13162926]; G_loss: [ 3.53799319]\n",
      "Iter-6400; D_loss: [ 0.13309588]; G_loss: [ 3.48844552]\n",
      "Iter-6656; D_loss: [ 0.11462629]; G_loss: [ 3.45158005]\n",
      "Iter-6912; D_loss: [ 0.12879665]; G_loss: [ 3.42580581]\n",
      "Iter-7168; D_loss: [ 0.10268475]; G_loss: [ 3.47559595]\n",
      "Iter-7424; D_loss: [ 0.10639712]; G_loss: [ 3.52753067]\n",
      "Iter-7680; D_loss: [ 0.09760721]; G_loss: [ 3.55968833]\n",
      "Iter-7936; D_loss: [ 0.09872982]; G_loss: [ 3.59739423]\n",
      "Iter-8192; D_loss: [ 0.09083114]; G_loss: [ 3.66868901]\n",
      "Iter-8448; D_loss: [ 0.0982132]; G_loss: [ 3.75428343]\n",
      "Iter-8704; D_loss: [ 0.08383985]; G_loss: [ 3.82237816]\n",
      "Iter-8960; D_loss: [ 0.0875243]; G_loss: [ 3.89693689]\n",
      "Iter-9216; D_loss: [ 0.07239351]; G_loss: [ 3.9293139]\n",
      "Iter-9472; D_loss: [ 0.06801802]; G_loss: [ 3.98895812]\n",
      "Iter-9728; D_loss: [ 0.07224439]; G_loss: [ 4.03441381]\n",
      "Iter-9984; D_loss: [ 0.06399632]; G_loss: [ 4.12523508]\n",
      "Iter-10240; D_loss: [ 0.06198686]; G_loss: [ 4.16135979]\n",
      "Iter-10496; D_loss: [ 0.06549466]; G_loss: [ 4.23794556]\n",
      "Iter-10752; D_loss: [ 0.05176881]; G_loss: [ 4.23272943]\n",
      "Iter-11008; D_loss: [ 0.05867223]; G_loss: [ 4.18582392]\n",
      "Iter-11264; D_loss: [ 0.0671947]; G_loss: [ 4.26560259]\n",
      "Iter-11520; D_loss: [ 0.0757829]; G_loss: [ 4.29087257]\n",
      "Iter-11776; D_loss: [ 0.05626943]; G_loss: [ 4.28220224]\n",
      "Iter-12032; D_loss: [ 0.05452092]; G_loss: [ 4.3070159]\n",
      "Iter-12288; D_loss: [ 0.05695176]; G_loss: [ 4.34591389]\n",
      "Iter-12544; D_loss: [ 0.06227433]; G_loss: [ 4.27928877]\n",
      "Iter-12800; D_loss: [ 0.04905467]; G_loss: [ 4.32003736]\n",
      "Iter-13056; D_loss: [ 0.04439814]; G_loss: [ 4.2693758]\n",
      "Iter-13312; D_loss: [ 0.04722532]; G_loss: [ 4.25109529]\n",
      "Iter-13568; D_loss: [ 0.05302474]; G_loss: [ 4.31215382]\n",
      "Iter-13824; D_loss: [ 0.05002005]; G_loss: [ 4.19736576]\n",
      "Iter-14080; D_loss: [ 0.05246465]; G_loss: [ 4.21866131]\n",
      "Iter-14336; D_loss: [ 0.04613903]; G_loss: [ 4.22759581]\n",
      "Iter-14592; D_loss: [ 0.05091064]; G_loss: [ 4.18944645]\n",
      "Iter-14848; D_loss: [ 0.05418592]; G_loss: [ 4.1834259]\n",
      "Iter-15104; D_loss: [ 0.04717661]; G_loss: [ 4.16188192]\n",
      "Iter-15360; D_loss: [ 0.05194195]; G_loss: [ 4.10864115]\n",
      "Iter-15616; D_loss: [ 0.04681199]; G_loss: [ 4.14998198]\n",
      "epoch: 1\n",
      "Iter-0; D_loss: [ 0.05040395]; G_loss: [ 4.09464264]\n",
      "Iter-256; D_loss: [ 0.04107984]; G_loss: [ 4.07629681]\n",
      "Iter-512; D_loss: [ 0.04269242]; G_loss: [ 4.15127373]\n",
      "Iter-768; D_loss: [ 0.04209531]; G_loss: [ 4.06488657]\n",
      "Iter-1024; D_loss: [ 0.04133533]; G_loss: [ 4.0440855]\n",
      "Iter-1280; D_loss: [ 0.04348055]; G_loss: [ 4.00390291]\n",
      "Iter-1536; D_loss: [ 0.05268409]; G_loss: [ 4.03737736]\n",
      "Iter-1792; D_loss: [ 0.05056098]; G_loss: [ 4.0182786]\n",
      "Iter-2048; D_loss: [ 0.04812378]; G_loss: [ 3.97357273]\n",
      "Iter-2304; D_loss: [ 0.04521015]; G_loss: [ 3.97438812]\n",
      "Iter-2560; D_loss: [ 0.04838464]; G_loss: [ 3.96331382]\n",
      "Iter-2816; D_loss: [ 0.04504541]; G_loss: [ 3.96370673]\n",
      "Iter-3072; D_loss: [ 0.0438248]; G_loss: [ 3.89983821]\n",
      "Iter-3328; D_loss: [ 0.05093407]; G_loss: [ 3.92494297]\n",
      "Iter-3584; D_loss: [ 0.04420289]; G_loss: [ 3.87860966]\n",
      "Iter-3840; D_loss: [ 0.04461212]; G_loss: [ 3.875453]\n",
      "Iter-4096; D_loss: [ 0.04824445]; G_loss: [ 3.82711983]\n",
      "Iter-4352; D_loss: [ 0.04726914]; G_loss: [ 3.82849574]\n",
      "Iter-4608; D_loss: [ 0.03955261]; G_loss: [ 3.79657388]\n",
      "Iter-4864; D_loss: [ 0.04630598]; G_loss: [ 3.76559687]\n",
      "Iter-5120; D_loss: [ 0.05025696]; G_loss: [ 3.73875046]\n",
      "Iter-5376; D_loss: [ 0.05071101]; G_loss: [ 3.70262408]\n",
      "Iter-5632; D_loss: [ 0.05157157]; G_loss: [ 3.70235252]\n",
      "Iter-5888; D_loss: [ 0.05542319]; G_loss: [ 3.62664032]\n",
      "Iter-6144; D_loss: [ 0.0542179]; G_loss: [ 3.63444662]\n",
      "Iter-6400; D_loss: [ 0.05943678]; G_loss: [ 3.58331108]\n",
      "Iter-6656; D_loss: [ 0.05553519]; G_loss: [ 3.55066633]\n",
      "Iter-6912; D_loss: [ 0.06308252]; G_loss: [ 3.50429726]\n",
      "Iter-7168; D_loss: [ 0.05690959]; G_loss: [ 3.47440743]\n",
      "Iter-7424; D_loss: [ 0.06154596]; G_loss: [ 3.44486189]\n",
      "Iter-7680; D_loss: [ 0.0616494]; G_loss: [ 3.36373973]\n",
      "Iter-7936; D_loss: [ 0.07013139]; G_loss: [ 3.35945868]\n",
      "Iter-8192; D_loss: [ 0.07712539]; G_loss: [ 3.27837086]\n",
      "Iter-8448; D_loss: [ 0.07548908]; G_loss: [ 3.27733374]\n",
      "Iter-8704; D_loss: [ 0.07518421]; G_loss: [ 3.22459412]\n",
      "Iter-8960; D_loss: [ 0.07410971]; G_loss: [ 3.22563887]\n",
      "Iter-9216; D_loss: [ 0.0713878]; G_loss: [ 3.18442988]\n",
      "Iter-9472; D_loss: [ 0.0683542]; G_loss: [ 3.15721321]\n",
      "Iter-9728; D_loss: [ 0.07395276]; G_loss: [ 3.12863612]\n",
      "Iter-9984; D_loss: [ 0.07659585]; G_loss: [ 3.09765029]\n",
      "Iter-10240; D_loss: [ 0.08173171]; G_loss: [ 3.06834531]\n",
      "Iter-10496; D_loss: [ 0.08307816]; G_loss: [ 3.05898595]\n",
      "Iter-10752; D_loss: [ 0.07875985]; G_loss: [ 3.07391834]\n",
      "Iter-11008; D_loss: [ 0.08348056]; G_loss: [ 3.02527452]\n",
      "Iter-11264; D_loss: [ 0.08799185]; G_loss: [ 2.98209739]\n",
      "Iter-11520; D_loss: [ 0.10099622]; G_loss: [ 2.99757671]\n",
      "Iter-11776; D_loss: [ 0.09382582]; G_loss: [ 2.94847751]\n",
      "Iter-12032; D_loss: [ 0.09369397]; G_loss: [ 2.89215398]\n",
      "Iter-12288; D_loss: [ 0.10225077]; G_loss: [ 2.8734169]\n",
      "Iter-12544; D_loss: [ 0.09634419]; G_loss: [ 2.85611105]\n",
      "Iter-12800; D_loss: [ 0.10309179]; G_loss: [ 2.81665325]\n",
      "Iter-13056; D_loss: [ 0.10669594]; G_loss: [ 2.75149179]\n",
      "Iter-13312; D_loss: [ 0.11413877]; G_loss: [ 2.7110846]\n",
      "Iter-13568; D_loss: [ 0.11966336]; G_loss: [ 2.64997649]\n",
      "Iter-13824; D_loss: [ 0.11766423]; G_loss: [ 2.62802052]\n",
      "Iter-14080; D_loss: [ 0.14162631]; G_loss: [ 2.57795334]\n",
      "Iter-14336; D_loss: [ 0.14136606]; G_loss: [ 2.56036401]\n",
      "Iter-14592; D_loss: [ 0.14920145]; G_loss: [ 2.43269086]\n",
      "Iter-14848; D_loss: [ 0.15374966]; G_loss: [ 2.36760497]\n",
      "Iter-15104; D_loss: [ 0.1552127]; G_loss: [ 2.32696652]\n",
      "Iter-15360; D_loss: [ 0.15846315]; G_loss: [ 2.29336905]\n",
      "Iter-15616; D_loss: [ 0.1724266]; G_loss: [ 2.23466516]\n",
      "epoch: 2\n",
      "Iter-0; D_loss: [ 0.19194883]; G_loss: [ 2.21476865]\n",
      "Iter-256; D_loss: [ 0.17970429]; G_loss: [ 2.12408495]\n",
      "Iter-512; D_loss: [ 0.20067991]; G_loss: [ 2.06827402]\n",
      "Iter-768; D_loss: [ 0.21555865]; G_loss: [ 2.03016925]\n",
      "Iter-1024; D_loss: [ 0.22536252]; G_loss: [ 1.99336791]\n",
      "Iter-1280; D_loss: [ 0.24093305]; G_loss: [ 1.92234576]\n",
      "Iter-1536; D_loss: [ 0.26392365]; G_loss: [ 1.88574135]\n",
      "Iter-1792; D_loss: [ 0.24716148]; G_loss: [ 1.87635767]\n",
      "Iter-2048; D_loss: [ 0.28163543]; G_loss: [ 1.82706022]\n",
      "Iter-2304; D_loss: [ 0.2661978]; G_loss: [ 1.80189085]\n",
      "Iter-2560; D_loss: [ 0.30075014]; G_loss: [ 1.75162828]\n",
      "Iter-2816; D_loss: [ 0.27840337]; G_loss: [ 1.72544098]\n",
      "Iter-3072; D_loss: [ 0.27449775]; G_loss: [ 1.74972355]\n",
      "Iter-3328; D_loss: [ 0.29347676]; G_loss: [ 1.72097588]\n",
      "Iter-3584; D_loss: [ 0.28849316]; G_loss: [ 1.70195842]\n",
      "Iter-3840; D_loss: [ 0.28803068]; G_loss: [ 1.66021061]\n",
      "Iter-4096; D_loss: [ 0.29473415]; G_loss: [ 1.668589]\n",
      "Iter-4352; D_loss: [ 0.32369971]; G_loss: [ 1.64639843]\n",
      "Iter-4608; D_loss: [ 0.29740009]; G_loss: [ 1.68237984]\n",
      "Iter-4864; D_loss: [ 0.30886823]; G_loss: [ 1.67044139]\n",
      "Iter-5120; D_loss: [ 0.29990613]; G_loss: [ 1.69880903]\n",
      "Iter-5376; D_loss: [ 0.32604861]; G_loss: [ 1.6724304]\n",
      "Iter-5632; D_loss: [ 0.31237873]; G_loss: [ 1.66855693]\n",
      "Iter-5888; D_loss: [ 0.32367176]; G_loss: [ 1.67473996]\n",
      "Iter-6144; D_loss: [ 0.26805505]; G_loss: [ 1.67363656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6400; D_loss: [ 0.29719043]; G_loss: [ 1.67853129]\n",
      "Iter-6656; D_loss: [ 0.31145579]; G_loss: [ 1.66793406]\n",
      "Iter-6912; D_loss: [ 0.32870284]; G_loss: [ 1.67351091]\n",
      "Iter-7168; D_loss: [ 0.31082469]; G_loss: [ 1.70530355]\n",
      "Iter-7424; D_loss: [ 0.29666531]; G_loss: [ 1.67710865]\n",
      "Iter-7680; D_loss: [ 0.33321232]; G_loss: [ 1.66812551]\n",
      "Iter-7936; D_loss: [ 0.29231805]; G_loss: [ 1.63319957]\n",
      "Iter-8192; D_loss: [ 0.33287603]; G_loss: [ 1.67018449]\n",
      "Iter-8448; D_loss: [ 0.3155458]; G_loss: [ 1.64558005]\n",
      "Iter-8704; D_loss: [ 0.34021533]; G_loss: [ 1.63832676]\n",
      "Iter-8960; D_loss: [ 0.30215278]; G_loss: [ 1.63741732]\n",
      "Iter-9216; D_loss: [ 0.28043759]; G_loss: [ 1.61733401]\n",
      "Iter-9472; D_loss: [ 0.28797966]; G_loss: [ 1.63426995]\n",
      "Iter-9728; D_loss: [ 0.29591471]; G_loss: [ 1.63845229]\n",
      "Iter-9984; D_loss: [ 0.28900006]; G_loss: [ 1.6407131]\n",
      "Iter-10240; D_loss: [ 0.26818478]; G_loss: [ 1.66768301]\n",
      "Iter-10496; D_loss: [ 0.27920714]; G_loss: [ 1.66993856]\n",
      "Iter-10752; D_loss: [ 0.25937575]; G_loss: [ 1.71064019]\n",
      "Iter-11008; D_loss: [ 0.27383742]; G_loss: [ 1.72128427]\n",
      "Iter-11264; D_loss: [ 0.24077553]; G_loss: [ 1.74117756]\n",
      "Iter-11520; D_loss: [ 0.27075842]; G_loss: [ 1.76099384]\n",
      "Iter-11776; D_loss: [ 0.27977103]; G_loss: [ 1.7908994]\n",
      "Iter-12032; D_loss: [ 0.22456497]; G_loss: [ 1.82092035]\n",
      "Iter-12288; D_loss: [ 0.23216501]; G_loss: [ 1.83408558]\n",
      "Iter-12544; D_loss: [ 0.2333592]; G_loss: [ 1.85602295]\n",
      "Iter-12800; D_loss: [ 0.22577044]; G_loss: [ 1.89157236]\n",
      "Iter-13056; D_loss: [ 0.21128738]; G_loss: [ 1.90957153]\n",
      "Iter-13312; D_loss: [ 0.19508368]; G_loss: [ 1.94202769]\n",
      "Iter-13568; D_loss: [ 0.19459593]; G_loss: [ 1.95824993]\n",
      "Iter-13824; D_loss: [ 0.2103169]; G_loss: [ 1.9921422]\n",
      "Iter-14080; D_loss: [ 0.19814119]; G_loss: [ 2.00045133]\n",
      "Iter-14336; D_loss: [ 0.18685842]; G_loss: [ 2.03626633]\n",
      "Iter-14592; D_loss: [ 0.18712352]; G_loss: [ 2.05720377]\n",
      "Iter-14848; D_loss: [ 0.18558282]; G_loss: [ 2.0771203]\n",
      "Iter-15104; D_loss: [ 0.1625115]; G_loss: [ 2.10777783]\n",
      "Iter-15360; D_loss: [ 0.16907659]; G_loss: [ 2.12223744]\n",
      "Iter-15616; D_loss: [ 0.16567889]; G_loss: [ 2.14819288]\n",
      "epoch: 3\n",
      "Iter-0; D_loss: [ 0.16081271]; G_loss: [ 2.18071532]\n",
      "Iter-256; D_loss: [ 0.1453346]; G_loss: [ 2.20808673]\n",
      "Iter-512; D_loss: [ 0.14785342]; G_loss: [ 2.24345517]\n",
      "Iter-768; D_loss: [ 0.1444217]; G_loss: [ 2.27134395]\n",
      "Iter-1024; D_loss: [ 0.14400801]; G_loss: [ 2.3092618]\n",
      "Iter-1280; D_loss: [ 0.13343148]; G_loss: [ 2.32830215]\n",
      "Iter-1536; D_loss: [ 0.14107409]; G_loss: [ 2.35292816]\n",
      "Iter-1792; D_loss: [ 0.13726413]; G_loss: [ 2.39593053]\n",
      "Iter-2048; D_loss: [ 0.13415313]; G_loss: [ 2.41939926]\n",
      "Iter-2304; D_loss: [ 0.129429]; G_loss: [ 2.44471407]\n",
      "Iter-2560; D_loss: [ 0.12315237]; G_loss: [ 2.46699452]\n",
      "Iter-2816; D_loss: [ 0.11634886]; G_loss: [ 2.51500273]\n",
      "Iter-3072; D_loss: [ 0.10923026]; G_loss: [ 2.5344913]\n",
      "Iter-3328; D_loss: [ 0.11513852]; G_loss: [ 2.54357886]\n",
      "Iter-3584; D_loss: [ 0.10405473]; G_loss: [ 2.58198357]\n",
      "Iter-3840; D_loss: [ 0.10119326]; G_loss: [ 2.59644675]\n",
      "Iter-4096; D_loss: [ 0.1010849]; G_loss: [ 2.62924623]\n",
      "Iter-4352; D_loss: [ 0.10267672]; G_loss: [ 2.64693189]\n",
      "Iter-4608; D_loss: [ 0.09315318]; G_loss: [ 2.66273475]\n",
      "Iter-4864; D_loss: [ 0.09300026]; G_loss: [ 2.69150686]\n",
      "Iter-5120; D_loss: [ 0.09285163]; G_loss: [ 2.71032691]\n",
      "Iter-5376; D_loss: [ 0.09080128]; G_loss: [ 2.73881388]\n",
      "Iter-5632; D_loss: [ 0.0884354]; G_loss: [ 2.75665903]\n",
      "Iter-5888; D_loss: [ 0.10243772]; G_loss: [ 2.76676679]\n",
      "Iter-6144; D_loss: [ 0.08393876]; G_loss: [ 2.7852056]\n",
      "Iter-6400; D_loss: [ 0.08199129]; G_loss: [ 2.79306936]\n",
      "Iter-6656; D_loss: [ 0.09417688]; G_loss: [ 2.80130172]\n",
      "Iter-6912; D_loss: [ 0.08531006]; G_loss: [ 2.81268215]\n",
      "Iter-7168; D_loss: [ 0.08811398]; G_loss: [ 2.80705881]\n",
      "Iter-7424; D_loss: [ 0.089922]; G_loss: [ 2.7876327]\n",
      "Iter-7680; D_loss: [ 0.08914696]; G_loss: [ 2.77186871]\n",
      "Iter-7936; D_loss: [ 0.08354046]; G_loss: [ 2.76550937]\n",
      "Iter-8192; D_loss: [ 0.08964944]; G_loss: [ 2.76977348]\n",
      "Iter-8448; D_loss: [ 0.08759309]; G_loss: [ 2.74072456]\n",
      "Iter-8704; D_loss: [ 0.09077804]; G_loss: [ 2.6873672]\n",
      "Iter-8960; D_loss: [ 0.10161726]; G_loss: [ 2.65411997]\n",
      "Iter-9216; D_loss: [ 0.0929253]; G_loss: [ 2.61755204]\n",
      "Iter-9472; D_loss: [ 0.10904527]; G_loss: [ 2.58114195]\n",
      "Iter-9728; D_loss: [ 0.10297616]; G_loss: [ 2.56542945]\n",
      "Iter-9984; D_loss: [ 0.11093177]; G_loss: [ 2.50658965]\n",
      "Iter-10240; D_loss: [ 0.1097022]; G_loss: [ 2.45572853]\n",
      "Iter-10496; D_loss: [ 0.12335324]; G_loss: [ 2.40795183]\n",
      "Iter-10752; D_loss: [ 0.1189674]; G_loss: [ 2.37051725]\n",
      "Iter-11008; D_loss: [ 0.13695185]; G_loss: [ 2.34128857]\n",
      "Iter-11264; D_loss: [ 0.1245769]; G_loss: [ 2.34014201]\n",
      "Iter-11520; D_loss: [ 0.13454479]; G_loss: [ 2.32454038]\n",
      "Iter-11776; D_loss: [ 0.13727883]; G_loss: [ 2.29728842]\n",
      "Iter-12032; D_loss: [ 0.12406022]; G_loss: [ 2.29834104]\n",
      "Iter-12288; D_loss: [ 0.13208869]; G_loss: [ 2.27290225]\n",
      "Iter-12544; D_loss: [ 0.13245462]; G_loss: [ 2.28777266]\n",
      "Iter-12800; D_loss: [ 0.12932299]; G_loss: [ 2.28804159]\n",
      "Iter-13056; D_loss: [ 0.1355233]; G_loss: [ 2.30033064]\n",
      "Iter-13312; D_loss: [ 0.12540944]; G_loss: [ 2.29757285]\n",
      "Iter-13568; D_loss: [ 0.12637627]; G_loss: [ 2.30504823]\n",
      "Iter-13824; D_loss: [ 0.1414592]; G_loss: [ 2.31105399]\n",
      "Iter-14080; D_loss: [ 0.12397751]; G_loss: [ 2.32551837]\n",
      "Iter-14336; D_loss: [ 0.1288]; G_loss: [ 2.34195209]\n",
      "Iter-14592; D_loss: [ 0.12507232]; G_loss: [ 2.36063743]\n",
      "Iter-14848; D_loss: [ 0.12869827]; G_loss: [ 2.35884213]\n",
      "Iter-15104; D_loss: [ 0.11537556]; G_loss: [ 2.3698175]\n",
      "Iter-15360; D_loss: [ 0.12070419]; G_loss: [ 2.39232326]\n",
      "Iter-15616; D_loss: [ 0.11569786]; G_loss: [ 2.42499208]\n",
      "epoch: 4\n",
      "Iter-0; D_loss: [ 0.11716945]; G_loss: [ 2.44963765]\n",
      "Iter-256; D_loss: [ 0.10679243]; G_loss: [ 2.47796631]\n",
      "Iter-512; D_loss: [ 0.10857345]; G_loss: [ 2.50985909]\n",
      "Iter-768; D_loss: [ 0.10236351]; G_loss: [ 2.53345799]\n",
      "Iter-1024; D_loss: [ 0.09936547]; G_loss: [ 2.56962538]\n",
      "Iter-1280; D_loss: [ 0.10074134]; G_loss: [ 2.59918475]\n",
      "Iter-1536; D_loss: [ 0.10302867]; G_loss: [ 2.6202476]\n",
      "Iter-1792; D_loss: [ 0.09865505]; G_loss: [ 2.65635133]\n",
      "Iter-2048; D_loss: [ 0.09803364]; G_loss: [ 2.68582797]\n",
      "Iter-2304; D_loss: [ 0.09382097]; G_loss: [ 2.71343255]\n",
      "Iter-2560; D_loss: [ 0.0898701]; G_loss: [ 2.74514532]\n",
      "Iter-2816; D_loss: [ 0.08618217]; G_loss: [ 2.78619576]\n",
      "Iter-3072; D_loss: [ 0.07990188]; G_loss: [ 2.81672263]\n",
      "Iter-3328; D_loss: [ 0.09017907]; G_loss: [ 2.83706999]\n",
      "Iter-3584; D_loss: [ 0.07657427]; G_loss: [ 2.86016989]\n",
      "Iter-3840; D_loss: [ 0.07507452]; G_loss: [ 2.89069343]\n",
      "Iter-4096; D_loss: [ 0.07156538]; G_loss: [ 2.91571641]\n",
      "Iter-4352; D_loss: [ 0.07777847]; G_loss: [ 2.93255663]\n",
      "Iter-4608; D_loss: [ 0.06818846]; G_loss: [ 2.97588134]\n",
      "Iter-4864; D_loss: [ 0.07110576]; G_loss: [ 2.99514818]\n",
      "Iter-5120; D_loss: [ 0.06894217]; G_loss: [ 3.01399684]\n",
      "Iter-5376; D_loss: [ 0.06857075]; G_loss: [ 3.04871845]\n",
      "Iter-5632; D_loss: [ 0.06327096]; G_loss: [ 3.09004807]\n",
      "Iter-5888; D_loss: [ 0.07332757]; G_loss: [ 3.09960032]\n",
      "Iter-6144; D_loss: [ 0.05856099]; G_loss: [ 3.14088655]\n",
      "Iter-6400; D_loss: [ 0.05709495]; G_loss: [ 3.18020368]\n",
      "Iter-6656; D_loss: [ 0.06254566]; G_loss: [ 3.21291828]\n",
      "Iter-6912; D_loss: [ 0.0578114]; G_loss: [ 3.249933]\n",
      "Iter-7168; D_loss: [ 0.05777721]; G_loss: [ 3.27227664]\n",
      "Iter-7424; D_loss: [ 0.05517124]; G_loss: [ 3.29514408]\n",
      "Iter-7680; D_loss: [ 0.05035845]; G_loss: [ 3.34687519]\n",
      "Iter-7936; D_loss: [ 0.05139105]; G_loss: [ 3.35454869]\n",
      "Iter-8192; D_loss: [ 0.05386429]; G_loss: [ 3.38252258]\n",
      "Iter-8448; D_loss: [ 0.04880028]; G_loss: [ 3.36347246]\n",
      "Iter-8704; D_loss: [ 0.04932965]; G_loss: [ 3.39348245]\n",
      "Iter-8960; D_loss: [ 0.05461852]; G_loss: [ 3.39244175]\n",
      "Iter-9216; D_loss: [ 0.04806481]; G_loss: [ 3.37584901]\n",
      "Iter-9472; D_loss: [ 0.05222636]; G_loss: [ 3.39530087]\n",
      "Iter-9728; D_loss: [ 0.04687253]; G_loss: [ 3.37970352]\n",
      "Iter-9984; D_loss: [ 0.05426091]; G_loss: [ 3.3187325]\n",
      "Iter-10240; D_loss: [ 0.04890564]; G_loss: [ 3.34294295]\n",
      "Iter-10496; D_loss: [ 0.05379419]; G_loss: [ 3.27244425]\n",
      "Iter-10752; D_loss: [ 0.04897874]; G_loss: [ 3.29485631]\n",
      "Iter-11008; D_loss: [ 0.05460217]; G_loss: [ 3.26161242]\n",
      "Iter-11264; D_loss: [ 0.05389554]; G_loss: [ 3.26590395]\n",
      "Iter-11520; D_loss: [ 0.05416256]; G_loss: [ 3.26436949]\n",
      "Iter-11776; D_loss: [ 0.05549857]; G_loss: [ 3.23336577]\n",
      "Iter-12032; D_loss: [ 0.05374834]; G_loss: [ 3.20218992]\n",
      "Iter-12288; D_loss: [ 0.0598853]; G_loss: [ 3.21484733]\n",
      "Iter-12544; D_loss: [ 0.05901194]; G_loss: [ 3.18870354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12800; D_loss: [ 0.05439319]; G_loss: [ 3.19247413]\n",
      "Iter-13056; D_loss: [ 0.0570395]; G_loss: [ 3.16871047]\n",
      "Iter-13312; D_loss: [ 0.05439842]; G_loss: [ 3.17887831]\n",
      "Iter-13568; D_loss: [ 0.05872712]; G_loss: [ 3.14997888]\n",
      "Iter-13824; D_loss: [ 0.05925703]; G_loss: [ 3.15794897]\n",
      "Iter-14080; D_loss: [ 0.05528904]; G_loss: [ 3.13938403]\n",
      "Iter-14336; D_loss: [ 0.05686731]; G_loss: [ 3.16066074]\n",
      "Iter-14592; D_loss: [ 0.05717451]; G_loss: [ 3.15876079]\n",
      "Iter-14848; D_loss: [ 0.05709207]; G_loss: [ 3.15559077]\n",
      "Iter-15104; D_loss: [ 0.05133421]; G_loss: [ 3.16030073]\n",
      "Iter-15360; D_loss: [ 0.05581031]; G_loss: [ 3.1865983]\n",
      "Iter-15616; D_loss: [ 0.05353382]; G_loss: [ 3.19653058]\n",
      "epoch: 5\n",
      "Iter-0; D_loss: [ 0.05519488]; G_loss: [ 3.21980619]\n",
      "Iter-256; D_loss: [ 0.04919801]; G_loss: [ 3.26350427]\n",
      "Iter-512; D_loss: [ 0.04888723]; G_loss: [ 3.29118514]\n",
      "Iter-768; D_loss: [ 0.04484622]; G_loss: [ 3.34169269]\n",
      "Iter-1024; D_loss: [ 0.04266229]; G_loss: [ 3.39095592]\n",
      "Iter-1280; D_loss: [ 0.04576667]; G_loss: [ 3.43056035]\n",
      "Iter-1536; D_loss: [ 0.04200075]; G_loss: [ 3.49251199]\n",
      "Iter-1792; D_loss: [ 0.04110219]; G_loss: [ 3.56006122]\n",
      "Iter-2048; D_loss: [ 0.04039622]; G_loss: [ 3.60128498]\n",
      "Iter-2304; D_loss: [ 0.04077708]; G_loss: [ 3.64360118]\n",
      "Iter-2560; D_loss: [ 0.03824084]; G_loss: [ 3.67971897]\n",
      "Iter-2816; D_loss: [ 0.03344651]; G_loss: [ 3.72695971]\n",
      "Iter-3072; D_loss: [ 0.03205834]; G_loss: [ 3.75553179]\n",
      "Iter-3328; D_loss: [ 0.04113366]; G_loss: [ 3.77264738]\n",
      "Iter-3584; D_loss: [ 0.03358519]; G_loss: [ 3.79501653]\n",
      "Iter-3840; D_loss: [ 0.03211562]; G_loss: [ 3.79007936]\n",
      "Iter-4096; D_loss: [ 0.03368101]; G_loss: [ 3.77981448]\n",
      "Iter-4352; D_loss: [ 0.03591596]; G_loss: [ 3.77144837]\n",
      "Iter-4608; D_loss: [ 0.03100315]; G_loss: [ 3.77448964]\n",
      "Iter-4864; D_loss: [ 0.03281988]; G_loss: [ 3.74461436]\n",
      "Iter-5120; D_loss: [ 0.03597051]; G_loss: [ 3.68958759]\n",
      "Iter-5376; D_loss: [ 0.03551895]; G_loss: [ 3.73437953]\n",
      "Iter-5632; D_loss: [ 0.03452327]; G_loss: [ 3.72495365]\n",
      "Iter-5888; D_loss: [ 0.03779401]; G_loss: [ 3.67314363]\n",
      "Iter-6144; D_loss: [ 0.03518978]; G_loss: [ 3.67037511]\n",
      "Iter-6400; D_loss: [ 0.03383501]; G_loss: [ 3.65384746]\n",
      "Iter-6656; D_loss: [ 0.03656602]; G_loss: [ 3.65235686]\n",
      "Iter-6912; D_loss: [ 0.03671816]; G_loss: [ 3.65169668]\n",
      "Iter-7168; D_loss: [ 0.03846505]; G_loss: [ 3.62674665]\n",
      "Iter-7424; D_loss: [ 0.03588077]; G_loss: [ 3.65035391]\n",
      "Iter-7680; D_loss: [ 0.03438309]; G_loss: [ 3.64019799]\n",
      "Iter-7936; D_loss: [ 0.03586861]; G_loss: [ 3.65387678]\n",
      "Iter-8192; D_loss: [ 0.03570488]; G_loss: [ 3.66581464]\n",
      "Iter-8448; D_loss: [ 0.0371448]; G_loss: [ 3.66095948]\n",
      "Iter-8704; D_loss: [ 0.03836763]; G_loss: [ 3.67427278]\n",
      "Iter-8960; D_loss: [ 0.03608504]; G_loss: [ 3.66600966]\n",
      "Iter-9216; D_loss: [ 0.03467935]; G_loss: [ 3.68579197]\n",
      "Iter-9472; D_loss: [ 0.03490214]; G_loss: [ 3.69573116]\n",
      "Iter-9728; D_loss: [ 0.03153688]; G_loss: [ 3.68274045]\n",
      "Iter-9984; D_loss: [ 0.03478768]; G_loss: [ 3.63997602]\n",
      "Iter-10240; D_loss: [ 0.0344079]; G_loss: [ 3.64157963]\n",
      "Iter-10496; D_loss: [ 0.03668769]; G_loss: [ 3.60122895]\n",
      "Iter-10752; D_loss: [ 0.03735806]; G_loss: [ 3.60175633]\n",
      "Iter-11008; D_loss: [ 0.0370383]; G_loss: [ 3.60290837]\n",
      "Iter-11264; D_loss: [ 0.03619657]; G_loss: [ 3.56054235]\n",
      "Iter-11520; D_loss: [ 0.03827615]; G_loss: [ 3.54923677]\n",
      "Iter-11776; D_loss: [ 0.04020354]; G_loss: [ 3.50220537]\n",
      "Iter-12032; D_loss: [ 0.03725863]; G_loss: [ 3.49945211]\n",
      "Iter-12288; D_loss: [ 0.04301351]; G_loss: [ 3.48829818]\n",
      "Iter-12544; D_loss: [ 0.04022578]; G_loss: [ 3.47115302]\n",
      "Iter-12800; D_loss: [ 0.041157]; G_loss: [ 3.45589638]\n",
      "Iter-13056; D_loss: [ 0.04045668]; G_loss: [ 3.45962429]\n",
      "Iter-13312; D_loss: [ 0.03916563]; G_loss: [ 3.45310879]\n",
      "Iter-13568; D_loss: [ 0.03999873]; G_loss: [ 3.46043038]\n",
      "Iter-13824; D_loss: [ 0.04310516]; G_loss: [ 3.44860578]\n",
      "Iter-14080; D_loss: [ 0.03803383]; G_loss: [ 3.4541595]\n",
      "Iter-14336; D_loss: [ 0.03770023]; G_loss: [ 3.4699266]\n",
      "Iter-14592; D_loss: [ 0.03780497]; G_loss: [ 3.47724032]\n",
      "Iter-14848; D_loss: [ 0.03956596]; G_loss: [ 3.46301651]\n",
      "Iter-15104; D_loss: [ 0.03640289]; G_loss: [ 3.47795534]\n",
      "Iter-15360; D_loss: [ 0.0373899]; G_loss: [ 3.48121119]\n",
      "Iter-15616; D_loss: [ 0.03668739]; G_loss: [ 3.49362493]\n",
      "epoch: 6\n",
      "Iter-0; D_loss: [ 0.03625789]; G_loss: [ 3.50182796]\n",
      "Iter-256; D_loss: [ 0.03398271]; G_loss: [ 3.51481271]\n",
      "Iter-512; D_loss: [ 0.03595613]; G_loss: [ 3.51925945]\n",
      "Iter-768; D_loss: [ 0.03416075]; G_loss: [ 3.5299015]\n",
      "Iter-1024; D_loss: [ 0.03334052]; G_loss: [ 3.53867316]\n",
      "Iter-1280; D_loss: [ 0.03633565]; G_loss: [ 3.52491331]\n",
      "Iter-1536; D_loss: [ 0.03633448]; G_loss: [ 3.52379918]\n",
      "Iter-1792; D_loss: [ 0.0375381]; G_loss: [ 3.5456152]\n",
      "Iter-2048; D_loss: [ 0.0364383]; G_loss: [ 3.54385972]\n",
      "Iter-2304; D_loss: [ 0.0365703]; G_loss: [ 3.54559016]\n",
      "Iter-2560; D_loss: [ 0.03537719]; G_loss: [ 3.55273795]\n",
      "Iter-2816; D_loss: [ 0.03438361]; G_loss: [ 3.5666821]\n",
      "Iter-3072; D_loss: [ 0.03317115]; G_loss: [ 3.58374596]\n",
      "Iter-3328; D_loss: [ 0.03716935]; G_loss: [ 3.60602021]\n",
      "Iter-3584; D_loss: [ 0.03177076]; G_loss: [ 3.6283679]\n",
      "Iter-3840; D_loss: [ 0.03112584]; G_loss: [ 3.66086745]\n",
      "Iter-4096; D_loss: [ 0.03081038]; G_loss: [ 3.7072525]\n",
      "Iter-4352; D_loss: [ 0.03040974]; G_loss: [ 3.72557592]\n",
      "Iter-4608; D_loss: [ 0.02803561]; G_loss: [ 3.77935719]\n",
      "Iter-4864; D_loss: [ 0.02695148]; G_loss: [ 3.8200357]\n",
      "Iter-5120; D_loss: [ 0.02772555]; G_loss: [ 3.84363937]\n",
      "Iter-5376; D_loss: [ 0.02637413]; G_loss: [ 3.89671922]\n",
      "Iter-5632; D_loss: [ 0.02529447]; G_loss: [ 3.94413137]\n",
      "Iter-5888; D_loss: [ 0.02682041]; G_loss: [ 3.95741248]\n",
      "Iter-6144; D_loss: [ 0.02396533]; G_loss: [ 3.99176049]\n",
      "Iter-6400; D_loss: [ 0.02342544]; G_loss: [ 4.02323866]\n",
      "Iter-6656; D_loss: [ 0.02327157]; G_loss: [ 4.04156351]\n",
      "Iter-6912; D_loss: [ 0.02337338]; G_loss: [ 4.06616116]\n",
      "Iter-7168; D_loss: [ 0.02338503]; G_loss: [ 4.08861685]\n",
      "Iter-7424; D_loss: [ 0.0230133]; G_loss: [ 4.10020256]\n",
      "Iter-7680; D_loss: [ 0.02053662]; G_loss: [ 4.11298609]\n",
      "Iter-7936; D_loss: [ 0.02188009]; G_loss: [ 4.14506626]\n",
      "Iter-8192; D_loss: [ 0.02245529]; G_loss: [ 4.16707993]\n",
      "Iter-8448; D_loss: [ 0.02199055]; G_loss: [ 4.1791048]\n",
      "Iter-8704; D_loss: [ 0.02140474]; G_loss: [ 4.20561314]\n",
      "Iter-8960; D_loss: [ 0.02223607]; G_loss: [ 4.23130131]\n",
      "Iter-9216; D_loss: [ 0.02105082]; G_loss: [ 4.26943684]\n",
      "Iter-9472; D_loss: [ 0.02002233]; G_loss: [ 4.30040264]\n",
      "Iter-9728; D_loss: [ 0.01813054]; G_loss: [ 4.3362546]\n",
      "Iter-9984; D_loss: [ 0.02009804]; G_loss: [ 4.36921835]\n",
      "Iter-10240; D_loss: [ 0.01810384]; G_loss: [ 4.40523243]\n",
      "Iter-10496; D_loss: [ 0.01901156]; G_loss: [ 4.4168601]\n",
      "Iter-10752; D_loss: [ 0.01863143]; G_loss: [ 4.46475029]\n",
      "Iter-11008; D_loss: [ 0.0186509]; G_loss: [ 4.48502111]\n",
      "Iter-11264; D_loss: [ 0.01793584]; G_loss: [ 4.50429678]\n",
      "Iter-11520; D_loss: [ 0.01736889]; G_loss: [ 4.53501892]\n",
      "Iter-11776; D_loss: [ 0.01819451]; G_loss: [ 4.57741213]\n",
      "Iter-12032; D_loss: [ 0.01516124]; G_loss: [ 4.60619688]\n",
      "Iter-12288; D_loss: [ 0.01647333]; G_loss: [ 4.62479496]\n",
      "Iter-12544; D_loss: [ 0.01852722]; G_loss: [ 4.66262579]\n",
      "Iter-12800; D_loss: [ 0.01545153]; G_loss: [ 4.70394087]\n",
      "Iter-13056; D_loss: [ 0.01547901]; G_loss: [ 4.74727058]\n",
      "Iter-13312; D_loss: [ 0.01492222]; G_loss: [ 4.76273918]\n",
      "Iter-13568; D_loss: [ 0.01405417]; G_loss: [ 4.81677198]\n",
      "Iter-13824; D_loss: [ 0.01706377]; G_loss: [ 4.85265303]\n",
      "Iter-14080; D_loss: [ 0.01487671]; G_loss: [ 4.91003847]\n",
      "Iter-14336; D_loss: [ 0.01201745]; G_loss: [ 4.95061779]\n",
      "Iter-14592; D_loss: [ 0.01342583]; G_loss: [ 5.00166178]\n",
      "Iter-14848; D_loss: [ 0.01223368]; G_loss: [ 5.02639627]\n",
      "Iter-15104; D_loss: [ 0.00924031]; G_loss: [ 5.09551811]\n",
      "Iter-15360; D_loss: [ 0.01070765]; G_loss: [ 5.14206171]\n",
      "Iter-15616; D_loss: [ 0.01253433]; G_loss: [ 5.17594337]\n",
      "epoch: 7\n",
      "Iter-0; D_loss: [ 0.01079438]; G_loss: [ 5.23299789]\n",
      "Iter-256; D_loss: [ 0.01047218]; G_loss: [ 5.27179193]\n",
      "Iter-512; D_loss: [ 0.01307925]; G_loss: [ 5.30537224]\n",
      "Iter-768; D_loss: [ 0.00910558]; G_loss: [ 5.33808041]\n",
      "Iter-1024; D_loss: [ 0.00794411]; G_loss: [ 5.39480257]\n",
      "Iter-1280; D_loss: [ 0.00892287]; G_loss: [ 5.4041543]\n",
      "Iter-1536; D_loss: [ 0.01029234]; G_loss: [ 5.4500556]\n",
      "Iter-1792; D_loss: [ 0.01100995]; G_loss: [ 5.50818872]\n",
      "Iter-2048; D_loss: [ 0.01082828]; G_loss: [ 5.56181335]\n",
      "Iter-2304; D_loss: [ 0.00804805]; G_loss: [ 5.60113096]\n",
      "Iter-2560; D_loss: [ 0.00849557]; G_loss: [ 5.64783239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2816; D_loss: [ 0.00931024]; G_loss: [ 5.69856358]\n",
      "Iter-3072; D_loss: [ 0.00800332]; G_loss: [ 5.75162411]\n",
      "Iter-3328; D_loss: [ 0.01109943]; G_loss: [ 5.78780556]\n",
      "Iter-3584; D_loss: [ 0.00632442]; G_loss: [ 5.81809378]\n",
      "Iter-3840; D_loss: [ 0.00682652]; G_loss: [ 5.84560299]\n",
      "Iter-4096; D_loss: [ 0.00686842]; G_loss: [ 5.88663864]\n",
      "Iter-4352; D_loss: [ 0.00806437]; G_loss: [ 5.90422583]\n",
      "Iter-4608; D_loss: [ 0.00774802]; G_loss: [ 5.94629145]\n",
      "Iter-4864; D_loss: [ 0.00605745]; G_loss: [ 5.96673107]\n",
      "Iter-5120; D_loss: [ 0.00500301]; G_loss: [ 5.97938728]\n",
      "Iter-5376; D_loss: [ 0.00587521]; G_loss: [ 5.99046755]\n",
      "Iter-5632; D_loss: [ 0.00545544]; G_loss: [ 6.03193808]\n",
      "Iter-5888; D_loss: [ 0.00649522]; G_loss: [ 6.0287137]\n",
      "Iter-6144; D_loss: [ 0.00539301]; G_loss: [ 6.03220892]\n",
      "Iter-6400; D_loss: [ 0.00652938]; G_loss: [ 6.02838326]\n",
      "Iter-6656; D_loss: [ 0.00805928]; G_loss: [ 6.005867]\n",
      "Iter-6912; D_loss: [ 0.00624201]; G_loss: [ 5.97249985]\n",
      "Iter-7168; D_loss: [ 0.00555139]; G_loss: [ 5.99444294]\n",
      "Iter-7424; D_loss: [ 0.00697516]; G_loss: [ 5.91232252]\n",
      "Iter-7680; D_loss: [ 0.00523347]; G_loss: [ 5.88389015]\n",
      "Iter-7936; D_loss: [ 0.00547271]; G_loss: [ 5.85076094]\n",
      "Iter-8192; D_loss: [ 0.00628004]; G_loss: [ 5.82951927]\n",
      "Iter-8448; D_loss: [ 0.00714616]; G_loss: [ 5.79954338]\n",
      "Iter-8704; D_loss: [ 0.00643744]; G_loss: [ 5.69530821]\n",
      "Iter-8960; D_loss: [ 0.00846662]; G_loss: [ 5.66114712]\n",
      "Iter-9216; D_loss: [ 0.00706715]; G_loss: [ 5.60385323]\n",
      "Iter-9472; D_loss: [ 0.0069324]; G_loss: [ 5.52856731]\n",
      "Iter-9728; D_loss: [ 0.00712957]; G_loss: [ 5.4961381]\n",
      "Iter-9984; D_loss: [ 0.00892283]; G_loss: [ 5.41231537]\n",
      "Iter-10240; D_loss: [ 0.00769003]; G_loss: [ 5.40492105]\n",
      "Iter-10496; D_loss: [ 0.00938698]; G_loss: [ 5.34692812]\n",
      "Iter-10752; D_loss: [ 0.00782201]; G_loss: [ 5.31226206]\n",
      "Iter-11008; D_loss: [ 0.00806569]; G_loss: [ 5.31834841]\n",
      "Iter-11264; D_loss: [ 0.00893966]; G_loss: [ 5.24954844]\n",
      "Iter-11520; D_loss: [ 0.00821952]; G_loss: [ 5.2563858]\n",
      "Iter-11776; D_loss: [ 0.00892308]; G_loss: [ 5.24467564]\n",
      "Iter-12032; D_loss: [ 0.00734447]; G_loss: [ 5.26052094]\n",
      "Iter-12288; D_loss: [ 0.00737762]; G_loss: [ 5.22902584]\n",
      "Iter-12544; D_loss: [ 0.00949268]; G_loss: [ 5.25209475]\n",
      "Iter-12800; D_loss: [ 0.00899913]; G_loss: [ 5.2749486]\n",
      "Iter-13056; D_loss: [ 0.00802745]; G_loss: [ 5.26925707]\n",
      "Iter-13312; D_loss: [ 0.00844755]; G_loss: [ 5.26838446]\n",
      "Iter-13568; D_loss: [ 0.0081347]; G_loss: [ 5.27491951]\n",
      "Iter-13824; D_loss: [ 0.00866205]; G_loss: [ 5.24952316]\n",
      "Iter-14080; D_loss: [ 0.00862141]; G_loss: [ 5.22855949]\n",
      "Iter-14336; D_loss: [ 0.00840141]; G_loss: [ 5.21782112]\n",
      "Iter-14592; D_loss: [ 0.00888773]; G_loss: [ 5.14567661]\n",
      "Iter-14848; D_loss: [ 0.00874234]; G_loss: [ 5.14566946]\n",
      "Iter-15104; D_loss: [ 0.00826389]; G_loss: [ 5.07515192]\n",
      "Iter-15360; D_loss: [ 0.00886108]; G_loss: [ 5.0155983]\n",
      "Iter-15616; D_loss: [ 0.01042788]; G_loss: [ 5.02388573]\n",
      "epoch: 8\n",
      "Iter-0; D_loss: [ 0.01046049]; G_loss: [ 4.97907829]\n",
      "Iter-256; D_loss: [ 0.01002576]; G_loss: [ 4.94163847]\n",
      "Iter-512; D_loss: [ 0.01171568]; G_loss: [ 4.94844437]\n",
      "Iter-768; D_loss: [ 0.01015222]; G_loss: [ 4.90095472]\n",
      "Iter-1024; D_loss: [ 0.00948793]; G_loss: [ 4.91962147]\n",
      "Iter-1280; D_loss: [ 0.01017791]; G_loss: [ 4.89053011]\n",
      "Iter-1536; D_loss: [ 0.01166481]; G_loss: [ 4.86584759]\n",
      "Iter-1792; D_loss: [ 0.01214601]; G_loss: [ 4.89200258]\n",
      "Iter-2048; D_loss: [ 0.0108985]; G_loss: [ 4.88170481]\n",
      "Iter-2304; D_loss: [ 0.01013029]; G_loss: [ 4.90229654]\n",
      "Iter-2560; D_loss: [ 0.01127295]; G_loss: [ 4.95262671]\n",
      "Iter-2816; D_loss: [ 0.01065895]; G_loss: [ 4.99383974]\n",
      "Iter-3072; D_loss: [ 0.00966384]; G_loss: [ 5.04698801]\n",
      "Iter-3328; D_loss: [ 0.01018685]; G_loss: [ 5.06308508]\n",
      "Iter-3584; D_loss: [ 0.00858129]; G_loss: [ 5.10657215]\n",
      "Iter-3840; D_loss: [ 0.00874267]; G_loss: [ 5.13824511]\n",
      "Iter-4096; D_loss: [ 0.0080545]; G_loss: [ 5.19666529]\n",
      "Iter-4352; D_loss: [ 0.00935128]; G_loss: [ 5.22112322]\n",
      "Iter-4608; D_loss: [ 0.00818079]; G_loss: [ 5.27776003]\n",
      "Iter-4864; D_loss: [ 0.00736731]; G_loss: [ 5.31848526]\n",
      "Iter-5120; D_loss: [ 0.00666932]; G_loss: [ 5.346241]\n",
      "Iter-5376; D_loss: [ 0.00754195]; G_loss: [ 5.39334011]\n",
      "Iter-5632; D_loss: [ 0.00645659]; G_loss: [ 5.44690752]\n",
      "Iter-5888; D_loss: [ 0.00945286]; G_loss: [ 5.45570326]\n",
      "Iter-6144; D_loss: [ 0.00661103]; G_loss: [ 5.48679447]\n",
      "Iter-6400; D_loss: [ 0.00765843]; G_loss: [ 5.51624298]\n",
      "Iter-6656; D_loss: [ 0.00626994]; G_loss: [ 5.52744102]\n",
      "Iter-6912; D_loss: [ 0.00716279]; G_loss: [ 5.55891371]\n",
      "Iter-7168; D_loss: [ 0.00662225]; G_loss: [ 5.58183527]\n",
      "Iter-7424; D_loss: [ 0.0064332]; G_loss: [ 5.60187435]\n",
      "Iter-7680; D_loss: [ 0.00558135]; G_loss: [ 5.61942959]\n",
      "Iter-7936; D_loss: [ 0.00566204]; G_loss: [ 5.64737272]\n",
      "Iter-8192; D_loss: [ 0.00636619]; G_loss: [ 5.66651773]\n",
      "Iter-8448; D_loss: [ 0.00780187]; G_loss: [ 5.67596436]\n",
      "Iter-8704; D_loss: [ 0.00627497]; G_loss: [ 5.69144297]\n",
      "Iter-8960; D_loss: [ 0.00727988]; G_loss: [ 5.7054739]\n",
      "Iter-9216; D_loss: [ 0.00673302]; G_loss: [ 5.72813749]\n",
      "Iter-9472; D_loss: [ 0.00594914]; G_loss: [ 5.74486828]\n",
      "Iter-9728; D_loss: [ 0.00691214]; G_loss: [ 5.75922108]\n",
      "Iter-9984; D_loss: [ 0.00784171]; G_loss: [ 5.75947857]\n",
      "Iter-10240; D_loss: [ 0.00624151]; G_loss: [ 5.77946568]\n",
      "Iter-10496; D_loss: [ 0.0064638]; G_loss: [ 5.77902842]\n",
      "Iter-10752; D_loss: [ 0.00592677]; G_loss: [ 5.80481339]\n",
      "Iter-11008; D_loss: [ 0.00682003]; G_loss: [ 5.8103404]\n",
      "Iter-11264; D_loss: [ 0.00605996]; G_loss: [ 5.81629896]\n",
      "Iter-11520; D_loss: [ 0.00550548]; G_loss: [ 5.82332373]\n",
      "Iter-11776; D_loss: [ 0.00666401]; G_loss: [ 5.83290958]\n",
      "Iter-12032; D_loss: [ 0.00463629]; G_loss: [ 5.84761524]\n",
      "Iter-12288; D_loss: [ 0.00448294]; G_loss: [ 5.84098244]\n",
      "Iter-12544; D_loss: [ 0.0068591]; G_loss: [ 5.85258341]\n",
      "Iter-12800; D_loss: [ 0.00543477]; G_loss: [ 5.86258078]\n",
      "Iter-13056; D_loss: [ 0.00460939]; G_loss: [ 5.87387896]\n",
      "Iter-13312; D_loss: [ 0.00485049]; G_loss: [ 5.86795425]\n",
      "Iter-13568; D_loss: [ 0.00507155]; G_loss: [ 5.88816977]\n",
      "Iter-13824; D_loss: [ 0.00524637]; G_loss: [ 5.8836894]\n",
      "Iter-14080; D_loss: [ 0.00481781]; G_loss: [ 5.89428282]\n",
      "Iter-14336; D_loss: [ 0.00525663]; G_loss: [ 5.91026115]\n",
      "Iter-14592; D_loss: [ 0.00503589]; G_loss: [ 5.91351366]\n",
      "Iter-14848; D_loss: [ 0.00441338]; G_loss: [ 5.90359831]\n",
      "Iter-15104; D_loss: [ 0.00397473]; G_loss: [ 5.91937351]\n",
      "Iter-15360; D_loss: [ 0.00397032]; G_loss: [ 5.91912031]\n",
      "Iter-15616; D_loss: [ 0.00530877]; G_loss: [ 5.91942501]\n",
      "epoch: 9\n",
      "Iter-0; D_loss: [ 0.00402927]; G_loss: [ 5.92849922]\n",
      "Iter-256; D_loss: [ 0.0041545]; G_loss: [ 5.93299341]\n",
      "Iter-512; D_loss: [ 0.00477121]; G_loss: [ 5.92536879]\n",
      "Iter-768; D_loss: [ 0.00432762]; G_loss: [ 5.91847754]\n",
      "Iter-1024; D_loss: [ 0.00375619]; G_loss: [ 5.91527033]\n",
      "Iter-1280; D_loss: [ 0.00409685]; G_loss: [ 5.88392115]\n",
      "Iter-1536; D_loss: [ 0.0054599]; G_loss: [ 5.87803555]\n",
      "Iter-1792; D_loss: [ 0.00503347]; G_loss: [ 5.88673496]\n",
      "Iter-2048; D_loss: [ 0.00446113]; G_loss: [ 5.88750172]\n",
      "Iter-2304; D_loss: [ 0.00411576]; G_loss: [ 5.8716445]\n",
      "Iter-2560; D_loss: [ 0.00480834]; G_loss: [ 5.8858695]\n",
      "Iter-2816; D_loss: [ 0.00453034]; G_loss: [ 5.90212488]\n",
      "Iter-3072; D_loss: [ 0.00429813]; G_loss: [ 5.91950035]\n",
      "Iter-3328; D_loss: [ 0.00464371]; G_loss: [ 5.93441725]\n",
      "Iter-3584; D_loss: [ 0.00399126]; G_loss: [ 5.94776917]\n",
      "Iter-3840; D_loss: [ 0.00399946]; G_loss: [ 5.96095133]\n",
      "Iter-4096; D_loss: [ 0.00359074]; G_loss: [ 5.99732494]\n",
      "Iter-4352; D_loss: [ 0.00450917]; G_loss: [ 6.00051928]\n",
      "Iter-4608; D_loss: [ 0.00389072]; G_loss: [ 6.03947401]\n",
      "Iter-4864; D_loss: [ 0.00331636]; G_loss: [ 6.06421852]\n",
      "Iter-5120; D_loss: [ 0.00344184]; G_loss: [ 6.07308769]\n",
      "Iter-5376; D_loss: [ 0.00363684]; G_loss: [ 6.10656214]\n",
      "Iter-5632; D_loss: [ 0.00330499]; G_loss: [ 6.14483261]\n",
      "Iter-5888; D_loss: [ 0.00383677]; G_loss: [ 6.14282465]\n",
      "Iter-6144; D_loss: [ 0.00332463]; G_loss: [ 6.16613436]\n",
      "Iter-6400; D_loss: [ 0.0037234]; G_loss: [ 6.18480349]\n",
      "Iter-6656; D_loss: [ 0.00318526]; G_loss: [ 6.18982601]\n",
      "Iter-6912; D_loss: [ 0.00346037]; G_loss: [ 6.21546125]\n",
      "Iter-7168; D_loss: [ 0.00343527]; G_loss: [ 6.22791529]\n",
      "Iter-7424; D_loss: [ 0.0031836]; G_loss: [ 6.2372818]\n",
      "Iter-7680; D_loss: [ 0.00316226]; G_loss: [ 6.23523521]\n",
      "Iter-7936; D_loss: [ 0.00304581]; G_loss: [ 6.24266529]\n",
      "Iter-8192; D_loss: [ 0.00321887]; G_loss: [ 6.24273682]\n",
      "Iter-8448; D_loss: [ 0.00358402]; G_loss: [ 6.2246418]\n",
      "Iter-8704; D_loss: [ 0.00354419]; G_loss: [ 6.19331694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8960; D_loss: [ 0.00404237]; G_loss: [ 6.19009304]\n",
      "Iter-9216; D_loss: [ 0.00358747]; G_loss: [ 6.19445515]\n",
      "Iter-9472; D_loss: [ 0.00380308]; G_loss: [ 6.15667582]\n",
      "Iter-9728; D_loss: [ 0.00383856]; G_loss: [ 6.13972759]\n",
      "Iter-9984; D_loss: [ 0.00420452]; G_loss: [ 6.10230398]\n",
      "Iter-10240; D_loss: [ 0.00401718]; G_loss: [ 6.10004711]\n",
      "Iter-10496; D_loss: [ 0.0042268]; G_loss: [ 6.0588522]\n",
      "Iter-10752; D_loss: [ 0.00397515]; G_loss: [ 6.03840685]\n",
      "Iter-11008; D_loss: [ 0.00425]; G_loss: [ 6.01640606]\n",
      "Iter-11264; D_loss: [ 0.00414921]; G_loss: [ 6.00118303]\n",
      "Iter-11520; D_loss: [ 0.00411226]; G_loss: [ 5.9922905]\n",
      "Iter-11776; D_loss: [ 0.00469529]; G_loss: [ 5.99250984]\n",
      "Iter-12032; D_loss: [ 0.00350394]; G_loss: [ 6.01744509]\n",
      "Iter-12288; D_loss: [ 0.00361133]; G_loss: [ 6.02577972]\n",
      "Iter-12544; D_loss: [ 0.00489056]; G_loss: [ 6.06553364]\n",
      "Iter-12800; D_loss: [ 0.00413426]; G_loss: [ 6.1059618]\n",
      "Iter-13056; D_loss: [ 0.00345264]; G_loss: [ 6.15397882]\n",
      "Iter-13312; D_loss: [ 0.00349714]; G_loss: [ 6.18656301]\n",
      "Iter-13568; D_loss: [ 0.00344496]; G_loss: [ 6.24875498]\n",
      "Iter-13824; D_loss: [ 0.00368899]; G_loss: [ 6.28192377]\n",
      "Iter-14080; D_loss: [ 0.00334636]; G_loss: [ 6.33422279]\n",
      "Iter-14336; D_loss: [ 0.00371073]; G_loss: [ 6.39151049]\n",
      "Iter-14592; D_loss: [ 0.00377907]; G_loss: [ 6.42152452]\n",
      "Iter-14848; D_loss: [ 0.00301499]; G_loss: [ 6.45790577]\n",
      "Iter-15104; D_loss: [ 0.00254121]; G_loss: [ 6.50070953]\n",
      "Iter-15360; D_loss: [ 0.00260644]; G_loss: [ 6.53995037]\n",
      "Iter-15616; D_loss: [ 0.00353854]; G_loss: [ 6.57832766]\n"
     ]
    }
   ],
   "source": [
    "batch_size = mb_size\n",
    "# Start training\n",
    "for epoch in range(10):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    while it+batch_size < len(X_train) :\n",
    "        \n",
    "\n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        X = X_train[start:end]\n",
    "\n",
    "        c = Y_train[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z, c)\n",
    "        D_real = D(X, c)\n",
    "        D_fake = D(G_sample, c)\n",
    "\n",
    "        D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "        D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        G_sample = G(z, c)\n",
    "        D_fake = D(G_sample, c)\n",
    "\n",
    "        G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "\n",
    "        #Print and plot every now and then\n",
    "        #if it % 2 == 0:\n",
    "\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "        it+= batch_size\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 14])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.D>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF=pd.DataFrame()\n",
    "samples_per_class = 1000\n",
    "#c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "#c[:, np.random.randint(0, 10)] = 1.\n",
    "for i in range(14):\n",
    "    #print(i)\n",
    "    c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "    c[:, i] = 1.\n",
    "    c_df=pd.DataFrame(c)\n",
    "    df_SF = df_SF.append(c_df,ignore_index = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = df_SF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen = Variable(torch.randn(df_SF.shape[0], Z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14000, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_gen.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = Variable(torch.from_numpy(c_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G(z_gen, c_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14000, 500])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = samples.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = c_gen.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = pd.DataFrame(train_X1)\n",
    "train_y1 = pd.DataFrame(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train.append(train_X1, ignore_index=True)\n",
    "train_y = Y_train.append(train_y1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X,  train_y = shuffle(train_X, train_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.values\n",
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               256512    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7182      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 526,350\n",
      "Trainable params: 526,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch=30"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Checking Baseline Accuracy with only training data\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Baseline ERROR %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#train_X1 and train_y1 are the augmented data alone to check accuracy only on augmented data \n",
    "#feed the model.fit only with these\n",
    "train_X1 = train_X1.values\n",
    "train_y1 = train_y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3974 samples\n",
      "Epoch 1/30\n",
      "Epoch 00000: val_acc improved from -inf to 0.05611, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6537 - acc: 0.0699 - val_loss: 2.8248 - val_acc: 0.0561\n",
      "Epoch 2/30\n",
      "Epoch 00001: val_acc improved from 0.05611 to 0.06241, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6419 - acc: 0.0701 - val_loss: 2.7979 - val_acc: 0.0624\n",
      "Epoch 3/30\n",
      "Epoch 00002: val_acc did not improve\n",
      "1s - loss: 2.6405 - acc: 0.0715 - val_loss: 2.8027 - val_acc: 0.0579\n",
      "Epoch 4/30\n",
      "Epoch 00003: val_acc did not improve\n",
      "1s - loss: 2.6396 - acc: 0.0751 - val_loss: 2.8220 - val_acc: 0.0544\n",
      "Epoch 5/30\n",
      "Epoch 00004: val_acc did not improve\n",
      "1s - loss: 2.6399 - acc: 0.0707 - val_loss: 2.8020 - val_acc: 0.0554\n",
      "Epoch 6/30\n",
      "Epoch 00005: val_acc did not improve\n",
      "1s - loss: 2.6395 - acc: 0.0721 - val_loss: 2.7953 - val_acc: 0.0591\n",
      "Epoch 7/30\n",
      "Epoch 00006: val_acc improved from 0.06241 to 0.06417, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6393 - acc: 0.0709 - val_loss: 2.7839 - val_acc: 0.0642\n",
      "Epoch 8/30\n",
      "Epoch 00007: val_acc improved from 0.06417 to 0.06517, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6394 - acc: 0.0701 - val_loss: 2.7893 - val_acc: 0.0652\n",
      "Epoch 9/30\n",
      "Epoch 00008: val_acc did not improve\n",
      "1s - loss: 2.6394 - acc: 0.0698 - val_loss: 2.8052 - val_acc: 0.0632\n",
      "Epoch 10/30\n",
      "Epoch 00009: val_acc did not improve\n",
      "1s - loss: 2.6391 - acc: 0.0719 - val_loss: 2.8024 - val_acc: 0.0627\n",
      "Epoch 11/30\n",
      "Epoch 00010: val_acc did not improve\n",
      "1s - loss: 2.6393 - acc: 0.0728 - val_loss: 2.8029 - val_acc: 0.0611\n",
      "Epoch 12/30\n",
      "Epoch 00011: val_acc did not improve\n",
      "1s - loss: 2.6391 - acc: 0.0756 - val_loss: 2.8211 - val_acc: 0.0619\n",
      "Epoch 13/30\n",
      "Epoch 00012: val_acc did not improve\n",
      "1s - loss: 2.6394 - acc: 0.0719 - val_loss: 2.8061 - val_acc: 0.0609\n",
      "Epoch 14/30\n",
      "Epoch 00013: val_acc did not improve\n",
      "1s - loss: 2.6394 - acc: 0.0670 - val_loss: 2.8033 - val_acc: 0.0647\n",
      "Epoch 15/30\n",
      "Epoch 00014: val_acc improved from 0.06517 to 0.06543, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6393 - acc: 0.0704 - val_loss: 2.7977 - val_acc: 0.0654\n",
      "Epoch 16/30\n",
      "Epoch 00015: val_acc improved from 0.06543 to 0.06593, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6393 - acc: 0.0689 - val_loss: 2.8080 - val_acc: 0.0659\n",
      "Epoch 17/30\n",
      "Epoch 00016: val_acc did not improve\n",
      "1s - loss: 2.6392 - acc: 0.0688 - val_loss: 2.8211 - val_acc: 0.0617\n",
      "Epoch 18/30\n",
      "Epoch 00017: val_acc did not improve\n",
      "1s - loss: 2.6390 - acc: 0.0721 - val_loss: 2.8260 - val_acc: 0.0652\n",
      "Epoch 19/30\n",
      "Epoch 00018: val_acc did not improve\n",
      "1s - loss: 2.6393 - acc: 0.0686 - val_loss: 2.8416 - val_acc: 0.0639\n",
      "Epoch 20/30\n",
      "Epoch 00019: val_acc did not improve\n",
      "1s - loss: 2.6392 - acc: 0.0724 - val_loss: 2.8462 - val_acc: 0.0652\n",
      "Epoch 21/30\n",
      "Epoch 00020: val_acc did not improve\n",
      "1s - loss: 2.6391 - acc: 0.0721 - val_loss: 2.8605 - val_acc: 0.0614\n",
      "Epoch 22/30\n",
      "Epoch 00021: val_acc did not improve\n",
      "1s - loss: 2.6390 - acc: 0.0766 - val_loss: 2.8786 - val_acc: 0.0652\n",
      "Epoch 23/30\n",
      "Epoch 00022: val_acc improved from 0.06593 to 0.06719, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6390 - acc: 0.0723 - val_loss: 2.8875 - val_acc: 0.0672\n",
      "Epoch 24/30\n",
      "Epoch 00023: val_acc improved from 0.06719 to 0.06744, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6390 - acc: 0.0718 - val_loss: 2.9157 - val_acc: 0.0674\n",
      "Epoch 25/30\n",
      "Epoch 00024: val_acc improved from 0.06744 to 0.07952, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6391 - acc: 0.0694 - val_loss: 2.9346 - val_acc: 0.0795\n",
      "Epoch 26/30\n",
      "Epoch 00025: val_acc improved from 0.07952 to 0.08002, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6391 - acc: 0.0673 - val_loss: 2.9335 - val_acc: 0.0800\n",
      "Epoch 27/30\n",
      "Epoch 00026: val_acc improved from 0.08002 to 0.08379, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6390 - acc: 0.0734 - val_loss: 2.9560 - val_acc: 0.0838\n",
      "Epoch 28/30\n",
      "Epoch 00027: val_acc did not improve\n",
      "1s - loss: 2.6390 - acc: 0.0755 - val_loss: 2.9765 - val_acc: 0.0795\n",
      "Epoch 29/30\n",
      "Epoch 00028: val_acc improved from 0.08379 to 0.08631, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6389 - acc: 0.0699 - val_loss: 3.0218 - val_acc: 0.0863\n",
      "Epoch 30/30\n",
      "Epoch 00029: val_acc improved from 0.08631 to 0.09185, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "1s - loss: 2.6385 - acc: 0.0709 - val_loss: 3.0982 - val_acc: 0.0918\n"
     ]
    }
   ],
   "source": [
    "#Checking Accuracy with training+augmented data train_X and train_y are 'train + augmented' data\n",
    "history = model.fit(train_X, train_y, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR after Data Augmentation %: 0.908152994464\n"
     ]
    }
   ],
   "source": [
    "#Frame label accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('ERROR after Data Augmentation %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
