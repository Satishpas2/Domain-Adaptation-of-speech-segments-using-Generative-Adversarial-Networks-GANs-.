{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_10sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_10sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>ids</th>\n",
       "      <th>year</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314181</td>\n",
       "      <td>0.671920</td>\n",
       "      <td>-0.188068</td>\n",
       "      <td>-0.910752</td>\n",
       "      <td>1.050361</td>\n",
       "      <td>1.966829</td>\n",
       "      <td>0.292740</td>\n",
       "      <td>1.084547</td>\n",
       "      <td>1.287480</td>\n",
       "      <td>1.745248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564911</td>\n",
       "      <td>-1.854116</td>\n",
       "      <td>-3.185948</td>\n",
       "      <td>-2.177057</td>\n",
       "      <td>0.301166</td>\n",
       "      <td>zkllk</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>zkllk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>0.500546</td>\n",
       "      <td>-0.716668</td>\n",
       "      <td>1.337575</td>\n",
       "      <td>-1.027019</td>\n",
       "      <td>0.773720</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>1.728001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886613</td>\n",
       "      <td>6.766799</td>\n",
       "      <td>-1.040380</td>\n",
       "      <td>-0.751316</td>\n",
       "      <td>-1.487938</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.141677</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>-0.595182</td>\n",
       "      <td>-0.595953</td>\n",
       "      <td>0.889385</td>\n",
       "      <td>1.440080</td>\n",
       "      <td>-1.208933</td>\n",
       "      <td>0.129059</td>\n",
       "      <td>-0.930121</td>\n",
       "      <td>0.401362</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.836253</td>\n",
       "      <td>-0.323334</td>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.481039</td>\n",
       "      <td>0.395826</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.708722</td>\n",
       "      <td>-0.663542</td>\n",
       "      <td>0.031733</td>\n",
       "      <td>0.358099</td>\n",
       "      <td>0.594610</td>\n",
       "      <td>1.023025</td>\n",
       "      <td>-1.450633</td>\n",
       "      <td>0.252159</td>\n",
       "      <td>-0.381832</td>\n",
       "      <td>0.087693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384728</td>\n",
       "      <td>0.426863</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>1.655650</td>\n",
       "      <td>-1.029032</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.873292</td>\n",
       "      <td>-0.272493</td>\n",
       "      <td>-0.305948</td>\n",
       "      <td>-0.250047</td>\n",
       "      <td>2.093700</td>\n",
       "      <td>1.741634</td>\n",
       "      <td>-0.750633</td>\n",
       "      <td>-0.651771</td>\n",
       "      <td>-0.793287</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>-0.888710</td>\n",
       "      <td>1.792536</td>\n",
       "      <td>-0.628455</td>\n",
       "      <td>1.912622</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.314181  0.671920 -0.188068 -0.910752  1.050361  1.966829  0.292740   \n",
       "1  0.503734  0.247072  0.451463  0.500546 -0.716668  1.337575 -1.027019   \n",
       "2  2.141677 -0.044947 -0.595182 -0.595953  0.889385  1.440080 -1.208933   \n",
       "3  1.708722 -0.663542  0.031733  0.358099  0.594610  1.023025 -1.450633   \n",
       "4  1.873292 -0.272493 -0.305948 -0.250047  2.093700  1.741634 -0.750633   \n",
       "\n",
       "          7         8         9        ...              495       496  \\\n",
       "0  1.084547  1.287480  1.745248        ...        -0.564911 -1.854116   \n",
       "1  0.773720  0.910362  1.728001        ...         0.886613  6.766799   \n",
       "2  0.129059 -0.930121  0.401362        ...        -2.836253 -0.323334   \n",
       "3  0.252159 -0.381832  0.087693        ...         1.384728  0.426863   \n",
       "4 -0.651771 -0.793287 -0.053527        ...         0.188493 -0.888710   \n",
       "\n",
       "        497       498       499               ids        year  data     lang  \\\n",
       "0 -3.185948 -2.177057  0.301166             zkllk  LDC2017E22  data  eng-usg   \n",
       "1 -1.040380 -0.751316 -1.487938  lid05e1_lid00562  LDC2017E22  data  eng-usg   \n",
       "2  0.055760  0.481039  0.395826        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "3  0.482178  1.655650 -1.029032        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "4  1.792536 -0.628455  1.912622        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "\n",
       "            lang_id  \n",
       "0             zkllk  \n",
       "1  lid05e1_lid00562  \n",
       "2        fla_0240-a  \n",
       "3        fla_0240-a  \n",
       "4        fla_0240-a  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre_10sec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = train_lre_10sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_30sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_30sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>ids</th>\n",
       "      <th>year</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.639420</td>\n",
       "      <td>0.345684</td>\n",
       "      <td>-0.517645</td>\n",
       "      <td>-0.737002</td>\n",
       "      <td>1.313001</td>\n",
       "      <td>1.655732</td>\n",
       "      <td>0.615168</td>\n",
       "      <td>0.799339</td>\n",
       "      <td>1.648419</td>\n",
       "      <td>1.314986</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.322407</td>\n",
       "      <td>-0.717348</td>\n",
       "      <td>-3.843951</td>\n",
       "      <td>-1.471274</td>\n",
       "      <td>0.945421</td>\n",
       "      <td>zkllk</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>zkllk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113610</td>\n",
       "      <td>0.738034</td>\n",
       "      <td>0.584856</td>\n",
       "      <td>-0.248521</td>\n",
       "      <td>0.256616</td>\n",
       "      <td>1.060159</td>\n",
       "      <td>-0.416211</td>\n",
       "      <td>0.133670</td>\n",
       "      <td>0.188327</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.965741</td>\n",
       "      <td>3.525555</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>1.676099</td>\n",
       "      <td>-1.116371</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.061305</td>\n",
       "      <td>-0.140605</td>\n",
       "      <td>-0.627104</td>\n",
       "      <td>-0.682908</td>\n",
       "      <td>1.337613</td>\n",
       "      <td>1.261543</td>\n",
       "      <td>-0.651291</td>\n",
       "      <td>0.307040</td>\n",
       "      <td>-0.980717</td>\n",
       "      <td>0.335530</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.018432</td>\n",
       "      <td>-1.841361</td>\n",
       "      <td>0.814595</td>\n",
       "      <td>-0.200731</td>\n",
       "      <td>1.180795</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.958049</td>\n",
       "      <td>-0.608315</td>\n",
       "      <td>-0.113532</td>\n",
       "      <td>0.167272</td>\n",
       "      <td>0.911100</td>\n",
       "      <td>1.116094</td>\n",
       "      <td>-0.847214</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>-0.542335</td>\n",
       "      <td>0.199105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548767</td>\n",
       "      <td>-1.254447</td>\n",
       "      <td>1.644647</td>\n",
       "      <td>0.555434</td>\n",
       "      <td>1.159140</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.842436</td>\n",
       "      <td>-0.417598</td>\n",
       "      <td>-0.427428</td>\n",
       "      <td>-0.485898</td>\n",
       "      <td>1.204330</td>\n",
       "      <td>1.439188</td>\n",
       "      <td>-1.056642</td>\n",
       "      <td>0.111603</td>\n",
       "      <td>-0.404313</td>\n",
       "      <td>-0.307075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297026</td>\n",
       "      <td>-1.858708</td>\n",
       "      <td>0.209784</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>1.398789</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.639420  0.345684 -0.517645 -0.737002  1.313001  1.655732  0.615168   \n",
       "1  0.113610  0.738034  0.584856 -0.248521  0.256616  1.060159 -0.416211   \n",
       "2  2.061305 -0.140605 -0.627104 -0.682908  1.337613  1.261543 -0.651291   \n",
       "3  1.958049 -0.608315 -0.113532  0.167272  0.911100  1.116094 -0.847214   \n",
       "4  1.842436 -0.417598 -0.427428 -0.485898  1.204330  1.439188 -1.056642   \n",
       "\n",
       "          7         8         9        ...              495       496  \\\n",
       "0  0.799339  1.648419  1.314986        ...        -1.322407 -0.717348   \n",
       "1  0.133670  0.188327  0.805241        ...         1.965741  3.525555   \n",
       "2  0.307040 -0.980717  0.335530        ...        -3.018432 -1.841361   \n",
       "3 -0.041357 -0.542335  0.199105        ...        -0.548767 -1.254447   \n",
       "4  0.111603 -0.404313 -0.307075        ...         0.297026 -1.858708   \n",
       "\n",
       "        497       498       499               ids        year  data     lang  \\\n",
       "0 -3.843951 -1.471274  0.945421             zkllk  LDC2017E22  data  eng-usg   \n",
       "1  0.006925  1.676099 -1.116371  lid05e1_lid00562  LDC2017E22  data  eng-usg   \n",
       "2  0.814595 -0.200731  1.180795        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "3  1.644647  0.555434  1.159140        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "4  0.209784  0.583939  1.398789        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "\n",
       "            lang_id  \n",
       "0             zkllk  \n",
       "1  lid05e1_lid00562  \n",
       "2        fla_0240-a  \n",
       "3        fla_0240-a  \n",
       "4        fla_0240-a  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre_30sec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec = train_lre_30sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels = train_lre_30sec[\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    eng-usg\n",
       "1    eng-usg\n",
       "2    ara-apc\n",
       "3    ara-apc\n",
       "4    ara-apc\n",
       "Name: lang, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels=le.transform(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train_labels = np_utils.to_categorical(y_30sec_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = X_train_10sec.values\n",
    "X_train_30sec = X_train_30sec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_10sec shape: (114276, 500)\n",
      "114276 train 10sec\n",
      "114276  train 30sec\n"
     ]
    }
   ],
   "source": [
    "X_train_10sec = X_train_10sec.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_train_30sec = X_train_30sec.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train_10sec shape:', X_train_10sec.shape)\n",
    "print(X_train_10sec.shape[0], 'train 10sec')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_train_30sec.shape[0], ' train 30sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the Dataset\n",
    "X_train_10sec_F,  X_train_30sec_F, Y_train_labels = shuffle(X_train_10sec, X_train_30sec, Y_train_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(FC_Network, self).__init__()\n",
    "\n",
    "        D_in =  114\n",
    "        D_out =500      \n",
    "        num_nodes_fnn = 4096\n",
    "        self.layer_1 = torch.nn.Linear(D_in, num_nodes_fnn)\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_2 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_2 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_3 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_3 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_4 = torch.nn.Linear(num_nodes_fnn,num_nodes_fnn)\n",
    "        self.bn_4 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.output_layer = torch.nn.Linear(num_nodes_fnn, D_out)\n",
    "        self.Lrelu = torch.nn.LeakyReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        out = torch.cat([x, labels], 1)\n",
    "        #out = x.view(x.size(0), -1)\n",
    "        out = self.dropout((self.Lrelu(self.bn_1(self.layer_1(out)))))\n",
    "        out = self.dropout((self.Lrelu(self.bn_2(self.layer_2(out)))))\n",
    "        out = self.dropout((self.Lrelu(self.bn_3(self.layer_3(out)))))\n",
    "        out = self.dropout((self.Lrelu(self.bn_4(self.layer_4(out)))))\n",
    "        out = self.sigmoid(self.output_layer(out))\n",
    "        #out = (self.relu(self.layer_1(out)))\n",
    "        #out = (self.relu(self.layer_2(out)))\n",
    "        #out = (self.relu(self.layer_3(out)))\n",
    "        #out = (self.relu(self.layer_4(out)))\n",
    "        #out = (self.output_layer(out))\n",
    "        #out = out.view(x.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_encoder = FC_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=114, out_features=4096)\n",
       "  (bn_1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=4096, out_features=500)\n",
       "  (Lrelu): LeakyReLU(0.01)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "#betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "#criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizers\n",
    "S_solver = optim.RMSprop(S_encoder.parameters(), lr=lr)\n",
    "#S_solver = torch.optim.Adam(S_encoder.parameters(), lr=learning_rate, betas=betas)\n",
    "#T_solver = torch.optim.Adam(T_encoder.parameters(), lr=learning_rate/2, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_10sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(X_train_30sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 256\n",
    "batch_size = mb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        D_in =  514\n",
    "        D_out = 1     \n",
    "        num_nodes_fnn = 512\n",
    "        self.layer_1 = torch.nn.Linear(D_in, num_nodes_fnn)\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_2 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_2 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_3 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_3 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.output_layer = torch.nn.Linear(num_nodes_fnn, D_out)\n",
    "        self.Lrelu = torch.nn.LeakyReLU()\n",
    "        #self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, labels ):\n",
    "        out = torch.cat([x, labels], 1)\n",
    "        out = self.Lrelu(self.bn_1(self.layer_1(out)))\n",
    "        out = self.Lrelu(self.bn_2(self.layer_2(out)))\n",
    "        out = self.Lrelu(self.bn_3(self.layer_3(out)))\n",
    "        out = (self.output_layer(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (layer_1): Linear(in_features=514, out_features=512)\n",
       "  (bn_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=512, out_features=512)\n",
       "  (bn_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=512, out_features=512)\n",
       "  (bn_3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=1)\n",
       "  (Lrelu): LeakyReLU(0.01)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Adding a Tanh() layer at the end of S_encoder\n",
    "S_encoder.tanh = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=114, out_features=4096)\n",
       "  (bn_1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=4096, out_features=500)\n",
       "  (Lrelu): LeakyReLU(0.01)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_label = Variable(torch.ones(mb_size, 1))\n",
    "zeros_label = Variable(torch.zeros(mb_size,1))\n",
    "#ones_label_fake = Variable(torch.ones(mb_size*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_label = ones_label.cuda()\n",
    "zeros_label = zeros_label.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "#T_solver = torch.optim.Adam(T_encoder.parameters(), lr=learning_rate, betas=betas)\n",
    "D_solver = optim.RMSprop(D.parameters(), lr=lr)\n",
    "#D_solver = torch.optim.SGD(D.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "S_loss: [ 0.01473243] D_loss: [-0.01931946]\n",
      "epoch: 1\n",
      "S_loss: [ 0.0146924] D_loss: [-0.01976759]\n",
      "epoch: 2\n",
      "S_loss: [ 0.01521194] D_loss: [-0.02061071]\n",
      "epoch: 3\n",
      "S_loss: [ 0.01486644] D_loss: [-0.01921497]\n",
      "epoch: 4\n",
      "S_loss: [ 0.01481787] D_loss: [-0.02098371]\n",
      "epoch: 5\n",
      "S_loss: [ 0.0158569] D_loss: [-0.02109142]\n",
      "epoch: 6\n",
      "S_loss: [ 0.01608185] D_loss: [-0.02155595]\n",
      "epoch: 7\n",
      "S_loss: [ 0.01600083] D_loss: [-0.0211454]\n",
      "epoch: 8\n",
      "S_loss: [ 0.01597703] D_loss: [-0.02096293]\n",
      "epoch: 9\n",
      "S_loss: [ 0.01620176] D_loss: [-0.02089455]\n",
      "epoch: 10\n",
      "S_loss: [ 0.01586161] D_loss: [-0.02155988]\n",
      "epoch: 11\n",
      "S_loss: [ 0.01555221] D_loss: [-0.02103772]\n",
      "epoch: 12\n",
      "S_loss: [ 0.01546431] D_loss: [-0.02114221]\n",
      "epoch: 13\n",
      "S_loss: [ 0.01572232] D_loss: [-0.02109876]\n",
      "epoch: 14\n",
      "S_loss: [ 0.01539858] D_loss: [-0.02072738]\n",
      "epoch: 15\n",
      "S_loss: [ 0.0160129] D_loss: [-0.02131653]\n",
      "epoch: 16\n",
      "S_loss: [ 0.01526293] D_loss: [-0.02120884]\n",
      "epoch: 17\n",
      "S_loss: [ 0.01574639] D_loss: [-0.02116806]\n",
      "epoch: 18\n",
      "S_loss: [ 0.01622157] D_loss: [-0.02140116]\n",
      "epoch: 19\n",
      "S_loss: [ 0.01540799] D_loss: [-0.02101407]\n",
      "epoch: 20\n",
      "S_loss: [ 0.01543306] D_loss: [-0.02053312]\n",
      "epoch: 21\n",
      "S_loss: [ 0.01575497] D_loss: [-0.02114363]\n",
      "epoch: 22\n",
      "S_loss: [ 0.0154802] D_loss: [-0.02103217]\n",
      "epoch: 23\n",
      "S_loss: [ 0.01614294] D_loss: [-0.02050982]\n",
      "epoch: 24\n",
      "S_loss: [ 0.01592646] D_loss: [-0.02085787]\n",
      "epoch: 25\n",
      "S_loss: [ 0.01520637] D_loss: [-0.02010555]\n",
      "epoch: 26\n",
      "S_loss: [ 0.01521278] D_loss: [-0.02099018]\n",
      "epoch: 27\n",
      "S_loss: [ 0.01597668] D_loss: [-0.02121461]\n",
      "epoch: 28\n",
      "S_loss: [ 0.01576545] D_loss: [-0.02040954]\n",
      "epoch: 29\n",
      "S_loss: [ 0.01588606] D_loss: [-0.02095279]\n",
      "epoch: 30\n",
      "S_loss: [ 0.01487588] D_loss: [-0.02038137]\n",
      "epoch: 31\n",
      "S_loss: [ 0.01502971] D_loss: [-0.02080666]\n",
      "epoch: 32\n",
      "S_loss: [ 0.01530729] D_loss: [-0.01998566]\n",
      "epoch: 33\n",
      "S_loss: [ 0.01610024] D_loss: [-0.02036135]\n",
      "epoch: 34\n",
      "S_loss: [ 0.01508157] D_loss: [-0.02012975]\n",
      "epoch: 35\n",
      "S_loss: [ 0.0153562] D_loss: [-0.01977197]\n",
      "epoch: 36\n",
      "S_loss: [ 0.01544124] D_loss: [-0.02043266]\n",
      "epoch: 37\n",
      "S_loss: [ 0.01533633] D_loss: [-0.02038565]\n",
      "epoch: 38\n",
      "S_loss: [ 0.01561623] D_loss: [-0.02112834]\n",
      "epoch: 39\n",
      "S_loss: [ 0.01515439] D_loss: [-0.01976055]\n",
      "epoch: 40\n",
      "S_loss: [ 0.01505635] D_loss: [-0.0202655]\n",
      "epoch: 41\n",
      "S_loss: [ 0.01452812] D_loss: [-0.02069384]\n",
      "epoch: 42\n",
      "S_loss: [ 0.01542595] D_loss: [-0.02019677]\n",
      "epoch: 43\n",
      "S_loss: [ 0.01592835] D_loss: [-0.02040496]\n",
      "epoch: 44\n",
      "S_loss: [ 0.01563572] D_loss: [-0.02004635]\n",
      "epoch: 45\n",
      "S_loss: [ 0.01551655] D_loss: [-0.01987853]\n",
      "epoch: 46\n",
      "S_loss: [ 0.01539695] D_loss: [-0.02040531]\n",
      "epoch: 47\n",
      "S_loss: [ 0.01481505] D_loss: [-0.0202611]\n",
      "epoch: 48\n",
      "S_loss: [ 0.01536583] D_loss: [-0.01993068]\n",
      "epoch: 49\n",
      "S_loss: [ 0.01491294] D_loss: [-0.02012257]\n",
      "epoch: 50\n",
      "S_loss: [ 0.01498422] D_loss: [-0.0200577]\n",
      "epoch: 51\n",
      "S_loss: [ 0.01486362] D_loss: [-0.02062917]\n",
      "epoch: 52\n",
      "S_loss: [ 0.01497962] D_loss: [-0.02033146]\n",
      "epoch: 53\n",
      "S_loss: [ 0.01485062] D_loss: [-0.02020494]\n",
      "epoch: 54\n",
      "S_loss: [ 0.01519358] D_loss: [-0.01940284]\n",
      "epoch: 55\n",
      "S_loss: [ 0.01492094] D_loss: [-0.02056426]\n",
      "epoch: 56\n",
      "S_loss: [ 0.01542961] D_loss: [-0.01961933]\n",
      "epoch: 57\n",
      "S_loss: [ 0.0152798] D_loss: [-0.02018731]\n",
      "epoch: 58\n",
      "S_loss: [ 0.01574652] D_loss: [-0.02069175]\n",
      "epoch: 59\n",
      "S_loss: [ 0.01497033] D_loss: [-0.01986397]\n",
      "epoch: 60\n",
      "S_loss: [ 0.01597576] D_loss: [-0.02138291]\n",
      "epoch: 61\n",
      "S_loss: [ 0.01513861] D_loss: [-0.02071842]\n",
      "epoch: 62\n",
      "S_loss: [ 0.01595756] D_loss: [-0.0207345]\n",
      "epoch: 63\n",
      "S_loss: [ 0.01463411] D_loss: [-0.02023916]\n",
      "epoch: 64\n",
      "S_loss: [ 0.01536875] D_loss: [-0.02005788]\n",
      "epoch: 65\n",
      "S_loss: [ 0.01543037] D_loss: [-0.02019338]\n",
      "epoch: 66\n",
      "S_loss: [ 0.01570971] D_loss: [-0.01984424]\n",
      "epoch: 67\n",
      "S_loss: [ 0.01522658] D_loss: [-0.02114682]\n",
      "epoch: 68\n",
      "S_loss: [ 0.01500214] D_loss: [-0.02060408]\n",
      "epoch: 69\n",
      "S_loss: [ 0.01502705] D_loss: [-0.02011147]\n",
      "epoch: 70\n",
      "S_loss: [ 0.0141204] D_loss: [-0.02038289]\n",
      "epoch: 71\n",
      "S_loss: [ 0.01561806] D_loss: [-0.0205409]\n",
      "epoch: 72\n",
      "S_loss: [ 0.01572179] D_loss: [-0.01984411]\n",
      "epoch: 73\n",
      "S_loss: [ 0.0141756] D_loss: [-0.02008907]\n",
      "epoch: 74\n",
      "S_loss: [ 0.01463797] D_loss: [-0.02019856]\n",
      "epoch: 75\n",
      "S_loss: [ 0.01478309] D_loss: [-0.02033957]\n",
      "epoch: 76\n",
      "S_loss: [ 0.01549652] D_loss: [-0.02078357]\n",
      "epoch: 77\n",
      "S_loss: [ 0.01548503] D_loss: [-0.01951143]\n",
      "epoch: 78\n",
      "S_loss: [ 0.01501317] D_loss: [-0.01953419]\n",
      "epoch: 79\n",
      "S_loss: [ 0.01554913] D_loss: [-0.02067117]\n",
      "epoch: 80\n",
      "S_loss: [ 0.01519633] D_loss: [-0.01976043]\n",
      "epoch: 81\n",
      "S_loss: [ 0.01514527] D_loss: [-0.01945164]\n",
      "epoch: 82\n",
      "S_loss: [ 0.01507776] D_loss: [-0.01925662]\n",
      "epoch: 83\n",
      "S_loss: [ 0.01536703] D_loss: [-0.01997678]\n",
      "epoch: 84\n",
      "S_loss: [ 0.01467986] D_loss: [-0.02004307]\n",
      "epoch: 85\n",
      "S_loss: [ 0.01515761] D_loss: [-0.01937572]\n",
      "epoch: 86\n",
      "S_loss: [ 0.01596187] D_loss: [-0.02066567]\n",
      "epoch: 87\n",
      "S_loss: [ 0.01488518] D_loss: [-0.02040651]\n",
      "epoch: 88\n",
      "S_loss: [ 0.01537127] D_loss: [-0.02004933]\n",
      "epoch: 89\n",
      "S_loss: [ 0.01543932] D_loss: [-0.02026887]\n",
      "epoch: 90\n",
      "S_loss: [ 0.01505066] D_loss: [-0.02006567]\n",
      "epoch: 91\n",
      "S_loss: [ 0.01561677] D_loss: [-0.02011305]\n",
      "epoch: 92\n",
      "S_loss: [ 0.01555709] D_loss: [-0.01996667]\n",
      "epoch: 93\n",
      "S_loss: [ 0.01592448] D_loss: [-0.02023516]\n",
      "epoch: 94\n",
      "S_loss: [ 0.0157227] D_loss: [-0.01998928]\n",
      "epoch: 95\n",
      "S_loss: [ 0.01564262] D_loss: [-0.01922019]\n",
      "epoch: 96\n",
      "S_loss: [ 0.01478041] D_loss: [-0.02015942]\n",
      "epoch: 97\n",
      "S_loss: [ 0.01429823] D_loss: [-0.02008519]\n",
      "epoch: 98\n",
      "S_loss: [ 0.01466818] D_loss: [-0.02008106]\n",
      "epoch: 99\n",
      "S_loss: [ 0.01447587] D_loss: [-0.0200697]\n"
     ]
    }
   ],
   "source": [
    "D_iter = 5\n",
    "mb_size = 256\n",
    "Z_dim = 100\n",
    "batch_size = mb_size\n",
    "k = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    j = 0\n",
    "    while it+batch_size < len(X_train_10sec_F) :\n",
    "        \n",
    "        \n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "        for p in D.parameters(): # reset requires_grad\n",
    "                p.requires_grad = True # they are set to False below in netG update\n",
    "\n",
    "        \n",
    "        while j < D_iter and it < len(X_train_10sec_F)-batch_size:\n",
    "            \n",
    "            \n",
    "            # Weight clipping\n",
    "            for p in D.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "                \n",
    "            # Housekeeping - reset gradient\n",
    "            D.zero_grad()    \n",
    "            #start= it\n",
    "            #end= it + batch_size\n",
    "            #for p in D.parameters(): # reset requires_grad\n",
    "                #p.requires_grad = True # they are set to False below in netG update\n",
    "            z = np.random.randn(mb_size, Z_dim)\n",
    "            z = Variable(torch.from_numpy(z.astype('float32')))\n",
    "            r = np.random.randint(X_train_30sec_F.shape[0], size=256)\n",
    "            X_D = X_train_10sec_F[r, :]\n",
    "            #c_D = X_train_30sec_F[r, :]\n",
    "            \n",
    "            #X = X_train_10sec_F[start:end]\n",
    "\n",
    "            labels_D = Y_train_labels[r, :]\n",
    "\n",
    "            #c = X_train_30sec_F[start:end]\n",
    "            X = Variable(torch.from_numpy(X_D))\n",
    "            #c = Variable(torch.from_numpy(c_D.astype('float32')))\n",
    "            labels = Variable(torch.from_numpy(labels_D.astype('float32')))\n",
    "            X = X.cuda()\n",
    "            z = z.cuda()\n",
    "            #c = c.cuda()\n",
    "            labels = labels.cuda()\n",
    "            # Dicriminator forward-loss-backward-update\n",
    "            S_sample = S_encoder(z, labels)\n",
    "            #T_sample = T_encoder(c)\n",
    "            D_real = D(X, labels)\n",
    "            D_fake = D(S_sample, labels)\n",
    "\n",
    "            D_loss = -(torch.mean(D_real) - torch.mean(D_fake))\n",
    "\n",
    "            D_loss.backward()\n",
    "            D_solver.step()\n",
    "            \n",
    "            j += 1\n",
    "            #print('j=',j)\n",
    "            \n",
    "            \n",
    "        # Generator forward-loss-backward-update\n",
    "        #start= it\n",
    "        #end= it + batch_size\n",
    "\n",
    "        X = X_train_10sec_F[start:end]\n",
    "        labels = Y_train_labels[start:end]\n",
    "\n",
    "        #c = X_train_30sec_F[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        #c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "        labels = Variable(torch.from_numpy(labels.astype('float32')))\n",
    "        X = X.cuda()\n",
    "        #c = c.cuda()\n",
    "        labels = labels.cuda()\n",
    "        #z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        #G_sample = G(z, c)\n",
    "        \n",
    "        # Housekeeping - reset gradient\n",
    "        D.zero_grad()\n",
    "        S_encoder.zero_grad()\n",
    "\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False # to avoid computation\n",
    "            \n",
    "        S_sample = S_encoder(z, labels)\n",
    "        D_fake = D(S_sample, labels)\n",
    "        #D_fake = D(G_sample, c)\n",
    "        #T_loss = criterion(T_sample, c)\n",
    "        S_loss = -torch.mean(D_fake)\n",
    "        #S_loss = binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "        S_loss.backward()\n",
    "        S_solver.step()\n",
    "        k = k+1\n",
    "        #print('k=',k)\n",
    "        #S_encoder.zero_grad()\n",
    "        # Housekeeping - reset gradient\n",
    "        #D.zero_grad()\n",
    "\n",
    "        \n",
    "        j = 0\n",
    "        it+= batch_size\n",
    "    print('S_loss: {}'.format(S_loss.cpu().data.numpy()),'D_loss: {}'.format(D_loss.cpu().data.numpy()))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=114, out_features=4096)\n",
       "  (bn_1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=4096, out_features=500)\n",
       "  (Lrelu): LeakyReLU(0.01)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF=pd.DataFrame()\n",
    "y_dim = 14\n",
    "samples_per_class = 5000\n",
    "#c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "#c[:, np.random.randint(0, 10)] = 1.\n",
    "for i in range(14):\n",
    "    #print(i)\n",
    "    c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "    c[:, i] = 1.\n",
    "    c_df=pd.DataFrame(c)\n",
    "    df_SF = df_SF.append(c_df,ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = df_SF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen = Variable(torch.randn(df_SF.shape[0], Z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 100])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_gen.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = Variable(torch.from_numpy(c_gen))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "z_gen = z_gen.cuda()\n",
    "c_gen = c_gen.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=114, out_features=4096)\n",
       "  (bn_1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=4096, out_features=4096)\n",
       "  (bn_4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=4096, out_features=500)\n",
       "  (Lrelu): LeakyReLU(0.01)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_encoder.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = S_encoder(z_gen, c_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70000, 500])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = samples.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = c_gen.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = pd.DataFrame(train_X1)\n",
    "train_y1 = pd.DataFrame(train_y1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_X = X_train.append(train_X1, ignore_index=True)\n",
    "train_y = Y_train.append(train_y1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1,  train_y1 = shuffle(train_X1, train_y1, random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_X = train_X.values\n",
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/dev_feat_BNF_h5_05Jan_10sec.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>uttid</th>\n",
       "      <th>language_code</th>\n",
       "      <th>data_source</th>\n",
       "      <th>speech_duration</th>\n",
       "      <th>segmentid1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.195398</td>\n",
       "      <td>-0.390386</td>\n",
       "      <td>-0.624269</td>\n",
       "      <td>1.535433</td>\n",
       "      <td>0.388117</td>\n",
       "      <td>1.727448</td>\n",
       "      <td>0.463109</td>\n",
       "      <td>2.059767</td>\n",
       "      <td>0.165206</td>\n",
       "      <td>0.619942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616712</td>\n",
       "      <td>-2.654504</td>\n",
       "      <td>0.482690</td>\n",
       "      <td>0.401316</td>\n",
       "      <td>-1.639292</td>\n",
       "      <td>lre17_zpuysjrb</td>\n",
       "      <td>zho-nan</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>lre17_zpuysjrb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.629280</td>\n",
       "      <td>-0.063858</td>\n",
       "      <td>0.397267</td>\n",
       "      <td>-0.205915</td>\n",
       "      <td>0.102730</td>\n",
       "      <td>2.412635</td>\n",
       "      <td>1.007062</td>\n",
       "      <td>1.123458</td>\n",
       "      <td>2.397956</td>\n",
       "      <td>1.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626052</td>\n",
       "      <td>1.390082</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>1.559527</td>\n",
       "      <td>-1.124127</td>\n",
       "      <td>lre17_ljfobgxa</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>lre17_ljfobgxa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896452</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>-0.547790</td>\n",
       "      <td>1.955862</td>\n",
       "      <td>-0.198707</td>\n",
       "      <td>1.430271</td>\n",
       "      <td>0.535072</td>\n",
       "      <td>1.199097</td>\n",
       "      <td>2.253311</td>\n",
       "      <td>0.050932</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.859781</td>\n",
       "      <td>-0.889882</td>\n",
       "      <td>-1.823634</td>\n",
       "      <td>-1.507139</td>\n",
       "      <td>-0.811382</td>\n",
       "      <td>lre17_guhfzbxl</td>\n",
       "      <td>zho-cmn</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>lre17_guhfzbxl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323422</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>1.585811</td>\n",
       "      <td>-0.071801</td>\n",
       "      <td>-0.398092</td>\n",
       "      <td>1.788636</td>\n",
       "      <td>1.529049</td>\n",
       "      <td>1.042687</td>\n",
       "      <td>-0.557043</td>\n",
       "      <td>1.131491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519515</td>\n",
       "      <td>1.404486</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>0.367571</td>\n",
       "      <td>1.274410</td>\n",
       "      <td>lre17_tbywroez</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>lre17_tbywroez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.384084</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>1.261965</td>\n",
       "      <td>1.078853</td>\n",
       "      <td>-1.601087</td>\n",
       "      <td>0.756707</td>\n",
       "      <td>1.157398</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>-0.566307</td>\n",
       "      <td>-0.446297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850699</td>\n",
       "      <td>0.355410</td>\n",
       "      <td>-1.455804</td>\n",
       "      <td>2.629600</td>\n",
       "      <td>-0.044268</td>\n",
       "      <td>lre17_phsyjibn</td>\n",
       "      <td>spa-lac</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>lre17_phsyjibn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.195398 -0.390386 -0.624269  1.535433  0.388117  1.727448  0.463109   \n",
       "1 -0.629280 -0.063858  0.397267 -0.205915  0.102730  2.412635  1.007062   \n",
       "2  0.896452  0.746032 -0.547790  1.955862 -0.198707  1.430271  0.535072   \n",
       "3  0.323422  0.577406  1.585811 -0.071801 -0.398092  1.788636  1.529049   \n",
       "4  1.384084  0.814175  1.261965  1.078853 -1.601087  0.756707  1.157398   \n",
       "\n",
       "          7         8         9       ...             495       496       497  \\\n",
       "0  2.059767  0.165206  0.619942       ...        0.616712 -2.654504  0.482690   \n",
       "1  1.123458  2.397956  1.009312       ...       -0.626052  1.390082  0.393644   \n",
       "2  1.199097  2.253311  0.050932       ...       -1.859781 -0.889882 -1.823634   \n",
       "3  1.042687 -0.557043  1.131491       ...        0.519515  1.404486 -0.052511   \n",
       "4  0.146018 -0.566307 -0.446297       ...       -0.850699  0.355410 -1.455804   \n",
       "\n",
       "        498       499           uttid  language_code  data_source  \\\n",
       "0  0.401316 -1.639292  lre17_zpuysjrb        zho-nan        mls14   \n",
       "1  1.559527 -1.124127  lre17_ljfobgxa        eng-usg        mls14   \n",
       "2 -1.507139 -0.811382  lre17_guhfzbxl        zho-cmn        mls14   \n",
       "3  0.367571  1.274410  lre17_tbywroez        eng-usg        mls14   \n",
       "4  2.629600 -0.044268  lre17_phsyjibn        spa-lac        mls14   \n",
       "\n",
       "   speech_duration      segmentid1  \n",
       "0               10  lre17_zpuysjrb  \n",
       "1               10  lre17_ljfobgxa  \n",
       "2               10  lre17_guhfzbxl  \n",
       "3               10  lre17_tbywroez  \n",
       "4               10  lre17_phsyjibn  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.values\n",
    "#X_eval = X_eval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  5, 12,  5, 11, 11, 11, 12, 10,  0, 11,  0,  2, 13, 12,  6, 13,\n",
       "        4,  6,  0, 11,  2,  4,  3, 10])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)\n",
    "#Y_eval = np_utils.to_categorical(y_eval_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 500)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               256512    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7182      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 526,350\n",
      "Trainable params: 526,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch=20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Checking Baseline Accuracy with only training data\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                        validation_data=(X_ , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Baseline ERROR %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X1 and train_y1 are the augmented data alone to check accuracy only on augmented data \n",
    "#feed the model.fit only with these\n",
    "train_X1 = train_X1.values\n",
    "train_y1 = train_y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 928 samples\n",
      "Epoch 1/20\n",
      "Epoch 00000: val_acc did not improve\n",
      "5s - loss: 1.1415 - acc: 0.5846 - val_loss: 8.5920 - val_acc: 0.2532\n",
      "Epoch 2/20\n",
      "Epoch 00001: val_acc did not improve\n",
      "5s - loss: 1.1304 - acc: 0.5877 - val_loss: 8.5887 - val_acc: 0.2597\n",
      "Epoch 3/20\n",
      "Epoch 00002: val_acc did not improve\n",
      "5s - loss: 1.1289 - acc: 0.5907 - val_loss: 8.5455 - val_acc: 0.2597\n",
      "Epoch 4/20\n",
      "Epoch 00003: val_acc did not improve\n",
      "5s - loss: 1.1213 - acc: 0.5933 - val_loss: 8.4052 - val_acc: 0.2489\n",
      "Epoch 5/20\n",
      "Epoch 00004: val_acc improved from 0.25970 to 0.26293, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "5s - loss: 1.1227 - acc: 0.5911 - val_loss: 8.3442 - val_acc: 0.2629\n",
      "Epoch 6/20\n",
      "Epoch 00005: val_acc did not improve\n",
      "5s - loss: 1.1244 - acc: 0.5905 - val_loss: 8.5293 - val_acc: 0.2565\n",
      "Epoch 7/20\n",
      "Epoch 00006: val_acc did not improve\n",
      "5s - loss: 1.1346 - acc: 0.5887 - val_loss: 8.2910 - val_acc: 0.2629\n",
      "Epoch 8/20\n",
      "Epoch 00007: val_acc improved from 0.26293 to 0.26616, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "5s - loss: 1.1162 - acc: 0.5946 - val_loss: 8.2085 - val_acc: 0.2662\n",
      "Epoch 9/20\n",
      "Epoch 00008: val_acc did not improve\n",
      "5s - loss: 1.1160 - acc: 0.5935 - val_loss: 8.4151 - val_acc: 0.2629\n",
      "Epoch 10/20\n",
      "Epoch 00009: val_acc improved from 0.26616 to 0.26724, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "5s - loss: 1.1214 - acc: 0.5928 - val_loss: 8.3840 - val_acc: 0.2672\n",
      "Epoch 11/20\n",
      "Epoch 00010: val_acc did not improve\n",
      "5s - loss: 1.1235 - acc: 0.5916 - val_loss: 8.2375 - val_acc: 0.2597\n",
      "Epoch 12/20\n",
      "Epoch 00011: val_acc did not improve\n",
      "5s - loss: 1.1131 - acc: 0.5959 - val_loss: 7.9625 - val_acc: 0.2575\n",
      "Epoch 13/20\n",
      "Epoch 00012: val_acc did not improve\n",
      "5s - loss: 1.1098 - acc: 0.5969 - val_loss: 8.1682 - val_acc: 0.2575\n",
      "Epoch 14/20\n",
      "Epoch 00013: val_acc did not improve\n",
      "5s - loss: 1.1064 - acc: 0.5973 - val_loss: 8.1051 - val_acc: 0.2489\n",
      "Epoch 15/20\n",
      "Epoch 00014: val_acc did not improve\n",
      "5s - loss: 1.1050 - acc: 0.5975 - val_loss: 8.1686 - val_acc: 0.2619\n",
      "Epoch 16/20\n",
      "Epoch 00015: val_acc did not improve\n",
      "5s - loss: 1.1173 - acc: 0.5949 - val_loss: 8.2061 - val_acc: 0.2565\n",
      "Epoch 17/20\n",
      "Epoch 00016: val_acc did not improve\n",
      "5s - loss: 1.1104 - acc: 0.5958 - val_loss: 8.1065 - val_acc: 0.2511\n",
      "Epoch 18/20\n",
      "Epoch 00017: val_acc did not improve\n",
      "5s - loss: 1.1070 - acc: 0.6006 - val_loss: 8.0488 - val_acc: 0.2489\n",
      "Epoch 19/20\n",
      "Epoch 00018: val_acc did not improve\n",
      "5s - loss: 1.1089 - acc: 0.6001 - val_loss: 8.0160 - val_acc: 0.2489\n",
      "Epoch 20/20\n",
      "Epoch 00019: val_acc did not improve\n",
      "5s - loss: 1.1039 - acc: 0.5998 - val_loss: 8.1278 - val_acc: 0.2522\n"
     ]
    }
   ],
   "source": [
    "#Checking Accuracy with training+augmented data train_X and train_y are 'train + augmented' data\n",
    "history = model.fit(train_X1, train_y1, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_val , Y_val),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR after Data Augmentation %: 0.747844827586\n"
     ]
    }
   ],
   "source": [
    "#Frame label accuracy\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('ERROR after Data Augmentation %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec_gen = Variable(torch.from_numpy(X_train_10sec_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples = S_encoder(X_train_30sec_gen.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_gen = gen_samples.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_10sec)\n",
    "#Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/dev_feat_BNF_h5_05Jan_10sec.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eval_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/eval_feat_BNF_h5_03Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_eval = eval_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_eval = eval_lre[\"language_code\"]\n",
    "y_eval_segmentid = eval_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.values\n",
    "#X_eval = X_eval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels[0:25]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_eval)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_eval_labels = le.transform(y_eval)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_eval_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)\n",
    "#Y_eval = np_utils.to_categorical(y_eval_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_10sec_gen = Variable(torch.from_numpy(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples_val = S_encoder(X_val_10sec_gen.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples_val.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_gen = gen_samples_val.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X_gen\n",
    "#Checking Accuracy with augmented data \n",
    "history = model.fit(train_X_gen, Y_train_labels , batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_val_gen , Y_val),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Use This to Check Accuracy with original data \n",
    "history = model.fit(X_train_10sec_F, Y_train_labels , batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_val , Y_val),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val_gen, Y_val, verbose=0)\n",
    "print('Acc %:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = SVC(C=1, kernel='rbf', gamma='auto', coef0=1, shrinking=True, random_state=0,\n",
    "                      probability=False, tol=1e-3, cache_size=1e4, class_weight='balanced')\n",
    "classif.fit(X_train_10sec_F, y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_val_labels, classif.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
