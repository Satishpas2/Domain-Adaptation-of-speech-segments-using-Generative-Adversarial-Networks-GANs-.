{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_10sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_10sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>ids</th>\n",
       "      <th>year</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314181</td>\n",
       "      <td>0.671920</td>\n",
       "      <td>-0.188068</td>\n",
       "      <td>-0.910752</td>\n",
       "      <td>1.050361</td>\n",
       "      <td>1.966829</td>\n",
       "      <td>0.292740</td>\n",
       "      <td>1.084547</td>\n",
       "      <td>1.287480</td>\n",
       "      <td>1.745248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564911</td>\n",
       "      <td>-1.854116</td>\n",
       "      <td>-3.185948</td>\n",
       "      <td>-2.177057</td>\n",
       "      <td>0.301166</td>\n",
       "      <td>zkllk</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>zkllk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>0.500546</td>\n",
       "      <td>-0.716668</td>\n",
       "      <td>1.337575</td>\n",
       "      <td>-1.027019</td>\n",
       "      <td>0.773720</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>1.728001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886613</td>\n",
       "      <td>6.766799</td>\n",
       "      <td>-1.040380</td>\n",
       "      <td>-0.751316</td>\n",
       "      <td>-1.487938</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.141677</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>-0.595182</td>\n",
       "      <td>-0.595953</td>\n",
       "      <td>0.889385</td>\n",
       "      <td>1.440080</td>\n",
       "      <td>-1.208933</td>\n",
       "      <td>0.129059</td>\n",
       "      <td>-0.930121</td>\n",
       "      <td>0.401362</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.836253</td>\n",
       "      <td>-0.323334</td>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.481039</td>\n",
       "      <td>0.395826</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.708722</td>\n",
       "      <td>-0.663542</td>\n",
       "      <td>0.031733</td>\n",
       "      <td>0.358099</td>\n",
       "      <td>0.594610</td>\n",
       "      <td>1.023025</td>\n",
       "      <td>-1.450633</td>\n",
       "      <td>0.252159</td>\n",
       "      <td>-0.381832</td>\n",
       "      <td>0.087693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384728</td>\n",
       "      <td>0.426863</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>1.655650</td>\n",
       "      <td>-1.029032</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.873292</td>\n",
       "      <td>-0.272493</td>\n",
       "      <td>-0.305948</td>\n",
       "      <td>-0.250047</td>\n",
       "      <td>2.093700</td>\n",
       "      <td>1.741634</td>\n",
       "      <td>-0.750633</td>\n",
       "      <td>-0.651771</td>\n",
       "      <td>-0.793287</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>-0.888710</td>\n",
       "      <td>1.792536</td>\n",
       "      <td>-0.628455</td>\n",
       "      <td>1.912622</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.314181  0.671920 -0.188068 -0.910752  1.050361  1.966829  0.292740   \n",
       "1  0.503734  0.247072  0.451463  0.500546 -0.716668  1.337575 -1.027019   \n",
       "2  2.141677 -0.044947 -0.595182 -0.595953  0.889385  1.440080 -1.208933   \n",
       "3  1.708722 -0.663542  0.031733  0.358099  0.594610  1.023025 -1.450633   \n",
       "4  1.873292 -0.272493 -0.305948 -0.250047  2.093700  1.741634 -0.750633   \n",
       "\n",
       "          7         8         9        ...              495       496  \\\n",
       "0  1.084547  1.287480  1.745248        ...        -0.564911 -1.854116   \n",
       "1  0.773720  0.910362  1.728001        ...         0.886613  6.766799   \n",
       "2  0.129059 -0.930121  0.401362        ...        -2.836253 -0.323334   \n",
       "3  0.252159 -0.381832  0.087693        ...         1.384728  0.426863   \n",
       "4 -0.651771 -0.793287 -0.053527        ...         0.188493 -0.888710   \n",
       "\n",
       "        497       498       499               ids        year  data     lang  \\\n",
       "0 -3.185948 -2.177057  0.301166             zkllk  LDC2017E22  data  eng-usg   \n",
       "1 -1.040380 -0.751316 -1.487938  lid05e1_lid00562  LDC2017E22  data  eng-usg   \n",
       "2  0.055760  0.481039  0.395826        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "3  0.482178  1.655650 -1.029032        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "4  1.792536 -0.628455  1.912622        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "\n",
       "            lang_id  \n",
       "0             zkllk  \n",
       "1  lid05e1_lid00562  \n",
       "2        fla_0240-a  \n",
       "3        fla_0240-a  \n",
       "4        fla_0240-a  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre_10sec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = train_lre_10sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_30sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_30sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec = train_lre_30sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels = train_lre_30sec[\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    eng-usg\n",
       "1    eng-usg\n",
       "2    ara-apc\n",
       "3    ara-apc\n",
       "4    ara-apc\n",
       "Name: lang, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels=le.transform(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train_labels = np_utils.to_categorical(y_30sec_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = X_train_10sec.values\n",
    "X_train_30sec = X_train_30sec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_10sec shape: (114276, 500)\n",
      "114276 train 10sec\n",
      "114276  train 30sec\n"
     ]
    }
   ],
   "source": [
    "X_train_10sec = X_train_10sec.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_train_30sec = X_train_30sec.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train_10sec shape:', X_train_10sec.shape)\n",
    "print(X_train_10sec.shape[0], 'train 10sec')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_train_30sec.shape[0], ' train 30sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the Dataset\n",
    "X_train_10sec_F,  X_train_30sec_F, Y_train_labels = shuffle(X_train_10sec, X_train_30sec, Y_train_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(FC_Network, self).__init__()\n",
    "\n",
    "        D_in = D_out = 500        # param['patch_length'] * param['n_channels'] * (param['n_fft'] / 2 + 1)\n",
    "        num_nodes_fnn = 512\n",
    "        self.layer_1 = torch.nn.Linear(D_in, num_nodes_fnn)\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_2 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_2 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_3 = torch.nn.Linear(num_nodes_fnn, num_nodes_fnn)\n",
    "        self.bn_3 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.layer_4 = torch.nn.Linear(num_nodes_fnn,num_nodes_fnn)\n",
    "        self.bn_4 = torch.nn.BatchNorm1d(num_nodes_fnn)\n",
    "        self.output_layer = torch.nn.Linear(num_nodes_fnn, D_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        #out = x.view(x.size(0), -1)\n",
    "        out = self.bn_1(self.relu(self.layer_1(out)))\n",
    "        out = self.bn_2(self.relu(self.layer_2(out)))\n",
    "        out = self.bn_3(self.relu(self.layer_3(out)))\n",
    "        out = self.bn_4(self.relu(self.layer_4(out)))\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        #out = (self.relu(self.layer_1(out)))\n",
    "        #out = (self.relu(self.layer_2(out)))\n",
    "        #out = (self.relu(self.layer_3(out)))\n",
    "        #out = (self.relu(self.layer_4(out)))\n",
    "        #out = (self.output_layer(out))\n",
    "        #out = out.view(x.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FC_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=500, out_features=512)\n",
       "  (bn_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=512, out_features=512)\n",
       "  (bn_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=512, out_features=512)\n",
       "  (bn_3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=512, out_features=512)\n",
       "  (bn_4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=500)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizers\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=betas)\n",
    "#D_solver = torch.optim.Adam(D.parameters(), lr=learning_rate/2, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_10sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_30sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "G_loss: [ 1.39575434]\n",
      "epoch: 1\n",
      "G_loss: [ 1.21824062]\n",
      "epoch: 2\n",
      "G_loss: [ 1.12576222]\n",
      "epoch: 3\n",
      "G_loss: [ 1.0726788]\n",
      "epoch: 4\n",
      "G_loss: [ 1.03719783]\n",
      "epoch: 5\n",
      "G_loss: [ 1.01474988]\n",
      "epoch: 6\n",
      "G_loss: [ 0.99861449]\n",
      "epoch: 7\n",
      "G_loss: [ 0.98635882]\n",
      "epoch: 8\n",
      "G_loss: [ 0.97749579]\n",
      "epoch: 9\n",
      "G_loss: [ 0.96898323]\n",
      "epoch: 10\n",
      "G_loss: [ 0.96207982]\n",
      "epoch: 11\n",
      "G_loss: [ 0.9553588]\n",
      "epoch: 12\n",
      "G_loss: [ 0.949938]\n",
      "epoch: 13\n",
      "G_loss: [ 0.94575167]\n",
      "epoch: 14\n",
      "G_loss: [ 0.94152647]\n",
      "epoch: 15\n",
      "G_loss: [ 0.93721324]\n",
      "epoch: 16\n",
      "G_loss: [ 0.93365419]\n",
      "epoch: 17\n",
      "G_loss: [ 0.93029028]\n",
      "epoch: 18\n",
      "G_loss: [ 0.9270243]\n",
      "epoch: 19\n",
      "G_loss: [ 0.92456096]\n",
      "epoch: 20\n",
      "G_loss: [ 0.92238057]\n",
      "epoch: 21\n",
      "G_loss: [ 0.92039901]\n",
      "epoch: 22\n",
      "G_loss: [ 0.91849715]\n",
      "epoch: 23\n",
      "G_loss: [ 0.91630656]\n",
      "epoch: 24\n",
      "G_loss: [ 0.9140873]\n",
      "epoch: 25\n",
      "G_loss: [ 0.91188252]\n",
      "epoch: 26\n",
      "G_loss: [ 0.91060203]\n",
      "epoch: 27\n",
      "G_loss: [ 0.90911067]\n",
      "epoch: 28\n",
      "G_loss: [ 0.9070338]\n",
      "epoch: 29\n",
      "G_loss: [ 0.90493083]\n",
      "epoch: 30\n",
      "G_loss: [ 0.90339434]\n",
      "epoch: 31\n",
      "G_loss: [ 0.90210462]\n",
      "epoch: 32\n",
      "G_loss: [ 0.90095556]\n",
      "epoch: 33\n",
      "G_loss: [ 0.89951551]\n",
      "epoch: 34\n",
      "G_loss: [ 0.89823282]\n",
      "epoch: 35\n",
      "G_loss: [ 0.89706606]\n",
      "epoch: 36\n",
      "G_loss: [ 0.89606738]\n",
      "epoch: 37\n",
      "G_loss: [ 0.89477021]\n",
      "epoch: 38\n",
      "G_loss: [ 0.89347166]\n",
      "epoch: 39\n",
      "G_loss: [ 0.89179927]\n",
      "epoch: 40\n",
      "G_loss: [ 0.89093381]\n",
      "epoch: 41\n",
      "G_loss: [ 0.8900255]\n",
      "epoch: 42\n",
      "G_loss: [ 0.88879687]\n",
      "epoch: 43\n",
      "G_loss: [ 0.88786232]\n",
      "epoch: 44\n",
      "G_loss: [ 0.88710576]\n",
      "epoch: 45\n",
      "G_loss: [ 0.88640851]\n",
      "epoch: 46\n",
      "G_loss: [ 0.88577521]\n",
      "epoch: 47\n",
      "G_loss: [ 0.88505119]\n",
      "epoch: 48\n",
      "G_loss: [ 0.88398916]\n",
      "epoch: 49\n",
      "G_loss: [ 0.88259184]\n",
      "epoch: 50\n",
      "G_loss: [ 0.88155168]\n",
      "epoch: 51\n",
      "G_loss: [ 0.88062865]\n",
      "epoch: 52\n",
      "G_loss: [ 0.87960196]\n",
      "epoch: 53\n",
      "G_loss: [ 0.87888253]\n",
      "epoch: 54\n",
      "G_loss: [ 0.87792593]\n",
      "epoch: 55\n",
      "G_loss: [ 0.87689704]\n",
      "epoch: 56\n",
      "G_loss: [ 0.87619942]\n",
      "epoch: 57\n",
      "G_loss: [ 0.87551451]\n",
      "epoch: 58\n",
      "G_loss: [ 0.87490231]\n",
      "epoch: 59\n",
      "G_loss: [ 0.87405437]\n",
      "epoch: 60\n",
      "G_loss: [ 0.87354743]\n",
      "epoch: 61\n",
      "G_loss: [ 0.87308031]\n",
      "epoch: 62\n",
      "G_loss: [ 0.8723889]\n",
      "epoch: 63\n",
      "G_loss: [ 0.87169743]\n",
      "epoch: 64\n",
      "G_loss: [ 0.87099093]\n",
      "epoch: 65\n",
      "G_loss: [ 0.87041867]\n",
      "epoch: 66\n",
      "G_loss: [ 0.86991847]\n",
      "epoch: 67\n",
      "G_loss: [ 0.86929125]\n",
      "epoch: 68\n",
      "G_loss: [ 0.86848593]\n",
      "epoch: 69\n",
      "G_loss: [ 0.8680433]\n",
      "epoch: 70\n",
      "G_loss: [ 0.86772257]\n",
      "epoch: 71\n",
      "G_loss: [ 0.86727959]\n",
      "epoch: 72\n",
      "G_loss: [ 0.8668018]\n",
      "epoch: 73\n",
      "G_loss: [ 0.86635476]\n",
      "epoch: 74\n",
      "G_loss: [ 0.86590487]\n",
      "epoch: 75\n",
      "G_loss: [ 0.86533755]\n",
      "epoch: 76\n",
      "G_loss: [ 0.86469895]\n",
      "epoch: 77\n",
      "G_loss: [ 0.86409032]\n",
      "epoch: 78\n",
      "G_loss: [ 0.86354297]\n",
      "epoch: 79\n",
      "G_loss: [ 0.86309969]\n",
      "epoch: 80\n",
      "G_loss: [ 0.86270374]\n",
      "epoch: 81\n",
      "G_loss: [ 0.86229402]\n",
      "epoch: 82\n",
      "G_loss: [ 0.86171377]\n",
      "epoch: 83\n",
      "G_loss: [ 0.86088932]\n",
      "epoch: 84\n",
      "G_loss: [ 0.86023235]\n",
      "epoch: 85\n",
      "G_loss: [ 0.85969794]\n",
      "epoch: 86\n",
      "G_loss: [ 0.85920745]\n",
      "epoch: 87\n",
      "G_loss: [ 0.858908]\n",
      "epoch: 88\n",
      "G_loss: [ 0.85845411]\n",
      "epoch: 89\n",
      "G_loss: [ 0.85781538]\n",
      "epoch: 90\n",
      "G_loss: [ 0.85732925]\n",
      "epoch: 91\n",
      "G_loss: [ 0.85692698]\n",
      "epoch: 92\n",
      "G_loss: [ 0.85649419]\n",
      "epoch: 93\n",
      "G_loss: [ 0.8561092]\n",
      "epoch: 94\n",
      "G_loss: [ 0.85583562]\n",
      "epoch: 95\n",
      "G_loss: [ 0.8555156]\n",
      "epoch: 96\n",
      "G_loss: [ 0.85507411]\n",
      "epoch: 97\n",
      "G_loss: [ 0.85462785]\n",
      "epoch: 98\n",
      "G_loss: [ 0.85425878]\n",
      "epoch: 99\n",
      "G_loss: [ 0.8538807]\n",
      "epoch: 100\n",
      "G_loss: [ 0.85360914]\n",
      "epoch: 101\n",
      "G_loss: [ 0.85338485]\n",
      "epoch: 102\n",
      "G_loss: [ 0.85304946]\n",
      "epoch: 103\n",
      "G_loss: [ 0.85274291]\n",
      "epoch: 104\n",
      "G_loss: [ 0.85242432]\n",
      "epoch: 105\n",
      "G_loss: [ 0.85200357]\n",
      "epoch: 106\n",
      "G_loss: [ 0.85167807]\n",
      "epoch: 107\n",
      "G_loss: [ 0.85136282]\n",
      "epoch: 108\n",
      "G_loss: [ 0.8509981]\n",
      "epoch: 109\n",
      "G_loss: [ 0.85077226]\n",
      "epoch: 110\n",
      "G_loss: [ 0.85040057]\n",
      "epoch: 111\n",
      "G_loss: [ 0.84992772]\n",
      "epoch: 112\n",
      "G_loss: [ 0.84958607]\n",
      "epoch: 113\n",
      "G_loss: [ 0.84924752]\n",
      "epoch: 114\n",
      "G_loss: [ 0.84897017]\n",
      "epoch: 115\n",
      "G_loss: [ 0.84840053]\n",
      "epoch: 116\n",
      "G_loss: [ 0.84786534]\n",
      "epoch: 117\n",
      "G_loss: [ 0.84745836]\n",
      "epoch: 118\n",
      "G_loss: [ 0.84709644]\n",
      "epoch: 119\n",
      "G_loss: [ 0.8467896]\n",
      "epoch: 120\n",
      "G_loss: [ 0.84630996]\n",
      "epoch: 121\n",
      "G_loss: [ 0.84593475]\n",
      "epoch: 122\n",
      "G_loss: [ 0.84555644]\n",
      "epoch: 123\n",
      "G_loss: [ 0.84519249]\n",
      "epoch: 124\n",
      "G_loss: [ 0.8448593]\n",
      "epoch: 125\n",
      "G_loss: [ 0.84447932]\n",
      "epoch: 126\n",
      "G_loss: [ 0.84414357]\n",
      "epoch: 127\n",
      "G_loss: [ 0.84377486]\n",
      "epoch: 128\n",
      "G_loss: [ 0.84343499]\n",
      "epoch: 129\n",
      "G_loss: [ 0.84318191]\n",
      "epoch: 130\n",
      "G_loss: [ 0.84300047]\n",
      "epoch: 131\n",
      "G_loss: [ 0.84269273]\n",
      "epoch: 132\n",
      "G_loss: [ 0.8424052]\n",
      "epoch: 133\n",
      "G_loss: [ 0.84212351]\n",
      "epoch: 134\n",
      "G_loss: [ 0.84172881]\n",
      "epoch: 135\n",
      "G_loss: [ 0.84142542]\n",
      "epoch: 136\n",
      "G_loss: [ 0.84121591]\n",
      "epoch: 137\n",
      "G_loss: [ 0.84102327]\n",
      "epoch: 138\n",
      "G_loss: [ 0.84082764]\n",
      "epoch: 139\n",
      "G_loss: [ 0.8405937]\n",
      "epoch: 140\n",
      "G_loss: [ 0.8403666]\n",
      "epoch: 141\n",
      "G_loss: [ 0.84014785]\n",
      "epoch: 142\n",
      "G_loss: [ 0.8398633]\n",
      "epoch: 143\n",
      "G_loss: [ 0.83954769]\n",
      "epoch: 144\n",
      "G_loss: [ 0.83925086]\n",
      "epoch: 145\n",
      "G_loss: [ 0.83905196]\n",
      "epoch: 146\n",
      "G_loss: [ 0.8387863]\n",
      "epoch: 147\n",
      "G_loss: [ 0.83856922]\n",
      "epoch: 148\n",
      "G_loss: [ 0.83830684]\n",
      "epoch: 149\n",
      "G_loss: [ 0.83795893]\n",
      "epoch: 150\n",
      "G_loss: [ 0.83759695]\n",
      "epoch: 151\n",
      "G_loss: [ 0.8373341]\n",
      "epoch: 152\n",
      "G_loss: [ 0.83721101]\n",
      "epoch: 153\n",
      "G_loss: [ 0.83700782]\n",
      "epoch: 154\n",
      "G_loss: [ 0.83680445]\n",
      "epoch: 155\n",
      "G_loss: [ 0.83661228]\n",
      "epoch: 156\n",
      "G_loss: [ 0.83639973]\n",
      "epoch: 157\n",
      "G_loss: [ 0.83629555]\n",
      "epoch: 158\n",
      "G_loss: [ 0.83588165]\n",
      "epoch: 159\n",
      "G_loss: [ 0.83560491]\n",
      "epoch: 160\n",
      "G_loss: [ 0.83536428]\n",
      "epoch: 161\n",
      "G_loss: [ 0.83521849]\n",
      "epoch: 162\n",
      "G_loss: [ 0.83471137]\n",
      "epoch: 163\n",
      "G_loss: [ 0.83437759]\n",
      "epoch: 164\n",
      "G_loss: [ 0.83412462]\n",
      "epoch: 165\n",
      "G_loss: [ 0.83390957]\n",
      "epoch: 166\n",
      "G_loss: [ 0.83360422]\n",
      "epoch: 167\n",
      "G_loss: [ 0.83340895]\n",
      "epoch: 168\n",
      "G_loss: [ 0.83306831]\n",
      "epoch: 169\n",
      "G_loss: [ 0.83288425]\n",
      "epoch: 170\n",
      "G_loss: [ 0.83263391]\n",
      "epoch: 171\n",
      "G_loss: [ 0.83237565]\n",
      "epoch: 172\n",
      "G_loss: [ 0.83198637]\n",
      "epoch: 173\n",
      "G_loss: [ 0.8315767]\n",
      "epoch: 174\n",
      "G_loss: [ 0.83114123]\n",
      "epoch: 175\n",
      "G_loss: [ 0.83082265]\n",
      "epoch: 176\n",
      "G_loss: [ 0.83049601]\n",
      "epoch: 177\n",
      "G_loss: [ 0.83019203]\n",
      "epoch: 178\n",
      "G_loss: [ 0.82995993]\n",
      "epoch: 179\n",
      "G_loss: [ 0.82963318]\n",
      "epoch: 180\n",
      "G_loss: [ 0.82942814]\n",
      "epoch: 181\n",
      "G_loss: [ 0.82917619]\n",
      "epoch: 182\n",
      "G_loss: [ 0.82896906]\n",
      "epoch: 183\n",
      "G_loss: [ 0.82874906]\n",
      "epoch: 184\n",
      "G_loss: [ 0.82855755]\n",
      "epoch: 185\n",
      "G_loss: [ 0.82833976]\n",
      "epoch: 186\n",
      "G_loss: [ 0.8281703]\n",
      "epoch: 187\n",
      "G_loss: [ 0.82781565]\n",
      "epoch: 188\n",
      "G_loss: [ 0.8275345]\n",
      "epoch: 189\n",
      "G_loss: [ 0.82725209]\n",
      "epoch: 190\n",
      "G_loss: [ 0.82702774]\n",
      "epoch: 191\n",
      "G_loss: [ 0.82693583]\n",
      "epoch: 192\n",
      "G_loss: [ 0.82669538]\n",
      "epoch: 193\n",
      "G_loss: [ 0.82651812]\n",
      "epoch: 194\n",
      "G_loss: [ 0.82622045]\n",
      "epoch: 195\n",
      "G_loss: [ 0.82589346]\n",
      "epoch: 196\n",
      "G_loss: [ 0.8256011]\n",
      "epoch: 197\n",
      "G_loss: [ 0.82534254]\n",
      "epoch: 198\n",
      "G_loss: [ 0.82513618]\n",
      "epoch: 199\n",
      "G_loss: [ 0.82494676]\n",
      "epoch: 200\n",
      "G_loss: [ 0.82476515]\n",
      "epoch: 201\n",
      "G_loss: [ 0.82455468]\n",
      "epoch: 202\n",
      "G_loss: [ 0.82428956]\n",
      "epoch: 203\n",
      "G_loss: [ 0.82410777]\n",
      "epoch: 204\n",
      "G_loss: [ 0.82395273]\n",
      "epoch: 205\n",
      "G_loss: [ 0.82385421]\n",
      "epoch: 206\n",
      "G_loss: [ 0.8237443]\n",
      "epoch: 207\n",
      "G_loss: [ 0.82364029]\n",
      "epoch: 208\n",
      "G_loss: [ 0.82361317]\n",
      "epoch: 209\n",
      "G_loss: [ 0.82342112]\n",
      "epoch: 210\n",
      "G_loss: [ 0.82330841]\n",
      "epoch: 211\n",
      "G_loss: [ 0.82320899]\n",
      "epoch: 212\n",
      "G_loss: [ 0.82303655]\n",
      "epoch: 213\n",
      "G_loss: [ 0.82298553]\n",
      "epoch: 214\n",
      "G_loss: [ 0.82275838]\n",
      "epoch: 215\n",
      "G_loss: [ 0.82259482]\n",
      "epoch: 216\n",
      "G_loss: [ 0.82237542]\n",
      "epoch: 217\n",
      "G_loss: [ 0.82223445]\n",
      "epoch: 218\n",
      "G_loss: [ 0.82210821]\n",
      "epoch: 219\n",
      "G_loss: [ 0.82195175]\n",
      "epoch: 220\n",
      "G_loss: [ 0.82184041]\n",
      "epoch: 221\n",
      "G_loss: [ 0.82178199]\n",
      "epoch: 222\n",
      "G_loss: [ 0.82148206]\n",
      "epoch: 223\n",
      "G_loss: [ 0.82124162]\n",
      "epoch: 224\n",
      "G_loss: [ 0.82109618]\n",
      "epoch: 225\n",
      "G_loss: [ 0.82086998]\n",
      "epoch: 226\n",
      "G_loss: [ 0.82066441]\n",
      "epoch: 227\n",
      "G_loss: [ 0.82049727]\n",
      "epoch: 228\n",
      "G_loss: [ 0.82023847]\n",
      "epoch: 229\n",
      "G_loss: [ 0.81996262]\n",
      "epoch: 230\n",
      "G_loss: [ 0.81975335]\n",
      "epoch: 231\n",
      "G_loss: [ 0.81949323]\n",
      "epoch: 232\n",
      "G_loss: [ 0.81925148]\n",
      "epoch: 233\n",
      "G_loss: [ 0.81908458]\n",
      "epoch: 234\n",
      "G_loss: [ 0.81897771]\n",
      "epoch: 235\n",
      "G_loss: [ 0.81880075]\n",
      "epoch: 236\n",
      "G_loss: [ 0.81867123]\n",
      "epoch: 237\n",
      "G_loss: [ 0.81857306]\n",
      "epoch: 238\n",
      "G_loss: [ 0.81851792]\n",
      "epoch: 239\n",
      "G_loss: [ 0.81835711]\n",
      "epoch: 240\n",
      "G_loss: [ 0.8182655]\n",
      "epoch: 241\n",
      "G_loss: [ 0.81807721]\n",
      "epoch: 242\n",
      "G_loss: [ 0.81796551]\n",
      "epoch: 243\n",
      "G_loss: [ 0.81785846]\n",
      "epoch: 244\n",
      "G_loss: [ 0.81773257]\n",
      "epoch: 245\n",
      "G_loss: [ 0.81764072]\n",
      "epoch: 246\n",
      "G_loss: [ 0.81749058]\n",
      "epoch: 247\n",
      "G_loss: [ 0.8173331]\n",
      "epoch: 248\n",
      "G_loss: [ 0.81723469]\n",
      "epoch: 249\n",
      "G_loss: [ 0.81695157]\n",
      "epoch: 250\n",
      "G_loss: [ 0.81670606]\n",
      "epoch: 251\n",
      "G_loss: [ 0.81657797]\n",
      "epoch: 252\n",
      "G_loss: [ 0.81629831]\n",
      "epoch: 253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_loss: [ 0.81610757]\n",
      "epoch: 254\n",
      "G_loss: [ 0.81595218]\n",
      "epoch: 255\n",
      "G_loss: [ 0.81584346]\n",
      "epoch: 256\n",
      "G_loss: [ 0.81564808]\n",
      "epoch: 257\n",
      "G_loss: [ 0.81549418]\n",
      "epoch: 258\n",
      "G_loss: [ 0.81532127]\n",
      "epoch: 259\n",
      "G_loss: [ 0.81508744]\n",
      "epoch: 260\n",
      "G_loss: [ 0.81482673]\n",
      "epoch: 261\n",
      "G_loss: [ 0.81450963]\n",
      "epoch: 262\n",
      "G_loss: [ 0.81425071]\n",
      "epoch: 263\n",
      "G_loss: [ 0.81403387]\n",
      "epoch: 264\n",
      "G_loss: [ 0.81392699]\n",
      "epoch: 265\n",
      "G_loss: [ 0.81372947]\n",
      "epoch: 266\n",
      "G_loss: [ 0.81352717]\n",
      "epoch: 267\n",
      "G_loss: [ 0.81338]\n",
      "epoch: 268\n",
      "G_loss: [ 0.81326288]\n",
      "epoch: 269\n",
      "G_loss: [ 0.81312895]\n",
      "epoch: 270\n",
      "G_loss: [ 0.81300336]\n",
      "epoch: 271\n",
      "G_loss: [ 0.81284672]\n",
      "epoch: 272\n",
      "G_loss: [ 0.81277156]\n",
      "epoch: 273\n",
      "G_loss: [ 0.81258732]\n",
      "epoch: 274\n",
      "G_loss: [ 0.81244743]\n",
      "epoch: 275\n",
      "G_loss: [ 0.81237257]\n",
      "epoch: 276\n",
      "G_loss: [ 0.81231421]\n",
      "epoch: 277\n",
      "G_loss: [ 0.81211603]\n",
      "epoch: 278\n",
      "G_loss: [ 0.8120212]\n",
      "epoch: 279\n",
      "G_loss: [ 0.81186163]\n",
      "epoch: 280\n",
      "G_loss: [ 0.81173748]\n",
      "epoch: 281\n",
      "G_loss: [ 0.8115893]\n",
      "epoch: 282\n",
      "G_loss: [ 0.81148601]\n",
      "epoch: 283\n",
      "G_loss: [ 0.811279]\n",
      "epoch: 284\n",
      "G_loss: [ 0.81117058]\n",
      "epoch: 285\n",
      "G_loss: [ 0.81088269]\n",
      "epoch: 286\n",
      "G_loss: [ 0.81073844]\n",
      "epoch: 287\n",
      "G_loss: [ 0.8105588]\n",
      "epoch: 288\n",
      "G_loss: [ 0.81029177]\n",
      "epoch: 289\n",
      "G_loss: [ 0.81003737]\n",
      "epoch: 290\n",
      "G_loss: [ 0.80987716]\n",
      "epoch: 291\n",
      "G_loss: [ 0.80960661]\n",
      "epoch: 292\n",
      "G_loss: [ 0.8094787]\n",
      "epoch: 293\n",
      "G_loss: [ 0.80933809]\n",
      "epoch: 294\n",
      "G_loss: [ 0.809196]\n",
      "epoch: 295\n",
      "G_loss: [ 0.80908495]\n",
      "epoch: 296\n",
      "G_loss: [ 0.80890507]\n",
      "epoch: 297\n",
      "G_loss: [ 0.80879635]\n",
      "epoch: 298\n",
      "G_loss: [ 0.8086856]\n",
      "epoch: 299\n",
      "G_loss: [ 0.80859923]\n",
      "epoch: 300\n",
      "G_loss: [ 0.80849773]\n",
      "epoch: 301\n",
      "G_loss: [ 0.80840528]\n",
      "epoch: 302\n",
      "G_loss: [ 0.80830681]\n",
      "epoch: 303\n",
      "G_loss: [ 0.8082462]\n",
      "epoch: 304\n",
      "G_loss: [ 0.80814344]\n",
      "epoch: 305\n",
      "G_loss: [ 0.808074]\n",
      "epoch: 306\n",
      "G_loss: [ 0.80801731]\n",
      "epoch: 307\n",
      "G_loss: [ 0.80786777]\n",
      "epoch: 308\n",
      "G_loss: [ 0.80774671]\n",
      "epoch: 309\n",
      "G_loss: [ 0.807652]\n",
      "epoch: 310\n",
      "G_loss: [ 0.80751085]\n",
      "epoch: 311\n",
      "G_loss: [ 0.80738324]\n",
      "epoch: 312\n",
      "G_loss: [ 0.80718899]\n",
      "epoch: 313\n",
      "G_loss: [ 0.80700219]\n",
      "epoch: 314\n",
      "G_loss: [ 0.80684704]\n",
      "epoch: 315\n",
      "G_loss: [ 0.80678523]\n",
      "epoch: 316\n",
      "G_loss: [ 0.80657196]\n",
      "epoch: 317\n",
      "G_loss: [ 0.8064394]\n",
      "epoch: 318\n",
      "G_loss: [ 0.80627137]\n",
      "epoch: 319\n",
      "G_loss: [ 0.8061254]\n",
      "epoch: 320\n",
      "G_loss: [ 0.80594909]\n",
      "epoch: 321\n",
      "G_loss: [ 0.80580246]\n",
      "epoch: 322\n",
      "G_loss: [ 0.80563092]\n",
      "epoch: 323\n",
      "G_loss: [ 0.80545735]\n",
      "epoch: 324\n",
      "G_loss: [ 0.805309]\n",
      "epoch: 325\n",
      "G_loss: [ 0.80516094]\n",
      "epoch: 326\n",
      "G_loss: [ 0.80499345]\n",
      "epoch: 327\n",
      "G_loss: [ 0.80484223]\n",
      "epoch: 328\n",
      "G_loss: [ 0.80473888]\n",
      "epoch: 329\n",
      "G_loss: [ 0.80461389]\n",
      "epoch: 330\n",
      "G_loss: [ 0.80449462]\n",
      "epoch: 331\n",
      "G_loss: [ 0.80439854]\n",
      "epoch: 332\n",
      "G_loss: [ 0.80434299]\n",
      "epoch: 333\n",
      "G_loss: [ 0.80423307]\n",
      "epoch: 334\n",
      "G_loss: [ 0.80413169]\n",
      "epoch: 335\n",
      "G_loss: [ 0.80402619]\n",
      "epoch: 336\n",
      "G_loss: [ 0.8040154]\n",
      "epoch: 337\n",
      "G_loss: [ 0.8038491]\n",
      "epoch: 338\n",
      "G_loss: [ 0.80376172]\n",
      "epoch: 339\n",
      "G_loss: [ 0.80365783]\n",
      "epoch: 340\n",
      "G_loss: [ 0.80359483]\n",
      "epoch: 341\n",
      "G_loss: [ 0.80350828]\n",
      "epoch: 342\n",
      "G_loss: [ 0.80344427]\n",
      "epoch: 343\n",
      "G_loss: [ 0.80334216]\n",
      "epoch: 344\n",
      "G_loss: [ 0.80326593]\n",
      "epoch: 345\n",
      "G_loss: [ 0.8032372]\n",
      "epoch: 346\n",
      "G_loss: [ 0.80312538]\n",
      "epoch: 347\n",
      "G_loss: [ 0.80304819]\n",
      "epoch: 348\n",
      "G_loss: [ 0.80295986]\n",
      "epoch: 349\n",
      "G_loss: [ 0.80287415]\n",
      "epoch: 350\n",
      "G_loss: [ 0.8027699]\n",
      "epoch: 351\n",
      "G_loss: [ 0.80268598]\n",
      "epoch: 352\n",
      "G_loss: [ 0.80250591]\n",
      "epoch: 353\n",
      "G_loss: [ 0.80233592]\n",
      "epoch: 354\n",
      "G_loss: [ 0.80217928]\n",
      "epoch: 355\n",
      "G_loss: [ 0.80201101]\n",
      "epoch: 356\n",
      "G_loss: [ 0.8019163]\n",
      "epoch: 357\n",
      "G_loss: [ 0.8017512]\n",
      "epoch: 358\n",
      "G_loss: [ 0.80165243]\n",
      "epoch: 359\n",
      "G_loss: [ 0.80150104]\n",
      "epoch: 360\n",
      "G_loss: [ 0.80137676]\n",
      "epoch: 361\n",
      "G_loss: [ 0.801229]\n",
      "epoch: 362\n",
      "G_loss: [ 0.80105287]\n",
      "epoch: 363\n",
      "G_loss: [ 0.80085385]\n",
      "epoch: 364\n",
      "G_loss: [ 0.8006959]\n",
      "epoch: 365\n",
      "G_loss: [ 0.80052811]\n",
      "epoch: 366\n",
      "G_loss: [ 0.80036443]\n",
      "epoch: 367\n",
      "G_loss: [ 0.80023801]\n",
      "epoch: 368\n",
      "G_loss: [ 0.80011606]\n",
      "epoch: 369\n",
      "G_loss: [ 0.80008841]\n",
      "epoch: 370\n",
      "G_loss: [ 0.79987931]\n",
      "epoch: 371\n",
      "G_loss: [ 0.7997579]\n",
      "epoch: 372\n",
      "G_loss: [ 0.79963762]\n",
      "epoch: 373\n",
      "G_loss: [ 0.79949933]\n",
      "epoch: 374\n",
      "G_loss: [ 0.79934305]\n",
      "epoch: 375\n",
      "G_loss: [ 0.7992354]\n",
      "epoch: 376\n",
      "G_loss: [ 0.79911625]\n",
      "epoch: 377\n",
      "G_loss: [ 0.79901922]\n",
      "epoch: 378\n",
      "G_loss: [ 0.79888815]\n",
      "epoch: 379\n",
      "G_loss: [ 0.79878139]\n",
      "epoch: 380\n",
      "G_loss: [ 0.79869151]\n",
      "epoch: 381\n",
      "G_loss: [ 0.79861015]\n",
      "epoch: 382\n",
      "G_loss: [ 0.79852122]\n",
      "epoch: 383\n",
      "G_loss: [ 0.79844189]\n",
      "epoch: 384\n",
      "G_loss: [ 0.79838812]\n",
      "epoch: 385\n",
      "G_loss: [ 0.79845387]\n",
      "epoch: 386\n",
      "G_loss: [ 0.79831624]\n",
      "epoch: 387\n",
      "G_loss: [ 0.79813772]\n",
      "epoch: 388\n",
      "G_loss: [ 0.79806328]\n",
      "epoch: 389\n",
      "G_loss: [ 0.7979852]\n",
      "epoch: 390\n",
      "G_loss: [ 0.79792035]\n",
      "epoch: 391\n",
      "G_loss: [ 0.79785687]\n",
      "epoch: 392\n",
      "G_loss: [ 0.79780734]\n",
      "epoch: 393\n",
      "G_loss: [ 0.79772943]\n",
      "epoch: 394\n",
      "G_loss: [ 0.79765916]\n",
      "epoch: 395\n",
      "G_loss: [ 0.79761845]\n",
      "epoch: 396\n",
      "G_loss: [ 0.79754704]\n",
      "epoch: 397\n",
      "G_loss: [ 0.79749185]\n",
      "epoch: 398\n",
      "G_loss: [ 0.79744291]\n",
      "epoch: 399\n",
      "G_loss: [ 0.79739016]\n",
      "epoch: 400\n",
      "G_loss: [ 0.79730332]\n",
      "epoch: 401\n",
      "G_loss: [ 0.79727417]\n",
      "epoch: 402\n",
      "G_loss: [ 0.79720783]\n",
      "epoch: 403\n",
      "G_loss: [ 0.79721689]\n",
      "epoch: 404\n",
      "G_loss: [ 0.79709429]\n",
      "epoch: 405\n",
      "G_loss: [ 0.79702926]\n",
      "epoch: 406\n",
      "G_loss: [ 0.79692]\n",
      "epoch: 407\n",
      "G_loss: [ 0.79684561]\n",
      "epoch: 408\n",
      "G_loss: [ 0.79676348]\n",
      "epoch: 409\n",
      "G_loss: [ 0.79668158]\n",
      "epoch: 410\n",
      "G_loss: [ 0.79655457]\n",
      "epoch: 411\n",
      "G_loss: [ 0.79655892]\n",
      "epoch: 412\n",
      "G_loss: [ 0.79634023]\n",
      "epoch: 413\n",
      "G_loss: [ 0.79629582]\n",
      "epoch: 414\n",
      "G_loss: [ 0.79615486]\n",
      "epoch: 415\n",
      "G_loss: [ 0.79598993]\n",
      "epoch: 416\n",
      "G_loss: [ 0.79590338]\n",
      "epoch: 417\n",
      "G_loss: [ 0.79565221]\n",
      "epoch: 418\n",
      "G_loss: [ 0.79553252]\n",
      "epoch: 419\n",
      "G_loss: [ 0.79541779]\n",
      "epoch: 420\n",
      "G_loss: [ 0.79539829]\n",
      "epoch: 421\n",
      "G_loss: [ 0.79528642]\n",
      "epoch: 422\n",
      "G_loss: [ 0.79516166]\n",
      "epoch: 423\n",
      "G_loss: [ 0.79505765]\n",
      "epoch: 424\n",
      "G_loss: [ 0.79495859]\n",
      "epoch: 425\n",
      "G_loss: [ 0.79486245]\n",
      "epoch: 426\n",
      "G_loss: [ 0.79475731]\n",
      "epoch: 427\n",
      "G_loss: [ 0.79469395]\n",
      "epoch: 428\n",
      "G_loss: [ 0.79458541]\n",
      "epoch: 429\n",
      "G_loss: [ 0.79440427]\n",
      "epoch: 430\n",
      "G_loss: [ 0.79427367]\n",
      "epoch: 431\n",
      "G_loss: [ 0.79416788]\n",
      "epoch: 432\n",
      "G_loss: [ 0.79409754]\n",
      "epoch: 433\n",
      "G_loss: [ 0.79400849]\n",
      "epoch: 434\n",
      "G_loss: [ 0.79391187]\n",
      "epoch: 435\n",
      "G_loss: [ 0.7938633]\n",
      "epoch: 436\n",
      "G_loss: [ 0.79378486]\n",
      "epoch: 437\n",
      "G_loss: [ 0.79370731]\n",
      "epoch: 438\n",
      "G_loss: [ 0.79361635]\n",
      "epoch: 439\n",
      "G_loss: [ 0.79356492]\n",
      "epoch: 440\n",
      "G_loss: [ 0.79346353]\n",
      "epoch: 441\n",
      "G_loss: [ 0.79341978]\n",
      "epoch: 442\n",
      "G_loss: [ 0.79332507]\n",
      "epoch: 443\n",
      "G_loss: [ 0.79325587]\n",
      "epoch: 444\n",
      "G_loss: [ 0.79318738]\n",
      "epoch: 445\n",
      "G_loss: [ 0.79311615]\n",
      "epoch: 446\n",
      "G_loss: [ 0.79307586]\n",
      "epoch: 447\n",
      "G_loss: [ 0.79299915]\n",
      "epoch: 448\n",
      "G_loss: [ 0.79291296]\n",
      "epoch: 449\n",
      "G_loss: [ 0.79284716]\n",
      "epoch: 450\n",
      "G_loss: [ 0.79277837]\n",
      "epoch: 451\n",
      "G_loss: [ 0.79268426]\n",
      "epoch: 452\n",
      "G_loss: [ 0.79258627]\n",
      "epoch: 453\n",
      "G_loss: [ 0.79261029]\n",
      "epoch: 454\n",
      "G_loss: [ 0.79245007]\n",
      "epoch: 455\n",
      "G_loss: [ 0.7923485]\n",
      "epoch: 456\n",
      "G_loss: [ 0.79228264]\n",
      "epoch: 457\n",
      "G_loss: [ 0.79219717]\n",
      "epoch: 458\n",
      "G_loss: [ 0.7920953]\n",
      "epoch: 459\n",
      "G_loss: [ 0.79205471]\n",
      "epoch: 460\n",
      "G_loss: [ 0.79195839]\n",
      "epoch: 461\n",
      "G_loss: [ 0.79181945]\n",
      "epoch: 462\n",
      "G_loss: [ 0.7917704]\n",
      "epoch: 463\n",
      "G_loss: [ 0.79164922]\n",
      "epoch: 464\n",
      "G_loss: [ 0.79162294]\n",
      "epoch: 465\n",
      "G_loss: [ 0.79145753]\n",
      "epoch: 466\n",
      "G_loss: [ 0.79134309]\n",
      "epoch: 467\n",
      "G_loss: [ 0.79129195]\n",
      "epoch: 468\n",
      "G_loss: [ 0.79119682]\n",
      "epoch: 469\n",
      "G_loss: [ 0.79103827]\n",
      "epoch: 470\n",
      "G_loss: [ 0.79100204]\n",
      "epoch: 471\n",
      "G_loss: [ 0.79090822]\n",
      "epoch: 472\n",
      "G_loss: [ 0.79066604]\n",
      "epoch: 473\n",
      "G_loss: [ 0.79056162]\n",
      "epoch: 474\n",
      "G_loss: [ 0.79041529]\n",
      "epoch: 475\n",
      "G_loss: [ 0.79030073]\n",
      "epoch: 476\n",
      "G_loss: [ 0.7902779]\n",
      "epoch: 477\n",
      "G_loss: [ 0.7900719]\n",
      "epoch: 478\n",
      "G_loss: [ 0.78998816]\n",
      "epoch: 479\n",
      "G_loss: [ 0.78982997]\n",
      "epoch: 480\n",
      "G_loss: [ 0.78973174]\n",
      "epoch: 481\n",
      "G_loss: [ 0.78957373]\n",
      "epoch: 482\n",
      "G_loss: [ 0.78946543]\n",
      "epoch: 483\n",
      "G_loss: [ 0.78931421]\n",
      "epoch: 484\n",
      "G_loss: [ 0.78914994]\n",
      "epoch: 485\n",
      "G_loss: [ 0.78901011]\n",
      "epoch: 486\n",
      "G_loss: [ 0.78895152]\n",
      "epoch: 487\n",
      "G_loss: [ 0.78869694]\n",
      "epoch: 488\n",
      "G_loss: [ 0.78855288]\n",
      "epoch: 489\n",
      "G_loss: [ 0.78848767]\n",
      "epoch: 490\n",
      "G_loss: [ 0.78848237]\n",
      "epoch: 491\n",
      "G_loss: [ 0.78828067]\n",
      "epoch: 492\n",
      "G_loss: [ 0.78821123]\n",
      "epoch: 493\n",
      "G_loss: [ 0.78811044]\n",
      "epoch: 494\n",
      "G_loss: [ 0.78801876]\n",
      "epoch: 495\n",
      "G_loss: [ 0.78796929]\n",
      "epoch: 496\n",
      "G_loss: [ 0.7878921]\n",
      "epoch: 497\n",
      "G_loss: [ 0.78783506]\n",
      "epoch: 498\n",
      "G_loss: [ 0.78775263]\n",
      "epoch: 499\n",
      "G_loss: [ 0.78769833]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mb_size = 256\n",
    "batch_size = mb_size\n",
    "# Start training\n",
    "for epoch in range(500):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    while it+batch_size < len(X_train_10sec_F) :\n",
    "        \n",
    "\n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "\n",
    "\n",
    "        #z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        X = X_train_10sec_F[start:end]\n",
    "\n",
    "        c = X_train_30sec_F[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "        X = X.cuda()\n",
    "        c = c.cuda()\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(X)\n",
    "        #D_real = D(X, c)\n",
    "        #D_fake = D(G_sample, c)\n",
    "\n",
    "        #D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "        #D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "        #D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        #D_loss.backward()\n",
    "        #D_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        #D.zero_grad()\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        #z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        #G_sample = G(z, c)\n",
    "        #D_fake = D(G_sample, c)\n",
    "        G_loss = criterion(G_sample, c)\n",
    "        #G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "        \n",
    "        G_solver.zero_grad()\n",
    "        # Housekeeping - reset gradient\n",
    "        #D.zero_grad()\n",
    "\n",
    "        #Print and plot every now and then\n",
    "        #if it % 2 == 0:\n",
    "\n",
    "        #print('Iter-{}; G_loss: {}'.format(it, G_loss.data.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "        it+= batch_size\n",
    "    print('G_loss: {}'.format(G_loss.cpu().data.numpy()))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec_gen = Variable(torch.from_numpy(X_train_10sec_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_Network(\n",
       "  (layer_1): Linear(in_features=500, out_features=512)\n",
       "  (bn_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_2): Linear(in_features=512, out_features=512)\n",
       "  (bn_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_3): Linear(in_features=512, out_features=512)\n",
       "  (bn_3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (layer_4): Linear(in_features=512, out_features=512)\n",
       "  (bn_4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=500)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples = G(X_train_30sec_gen.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114276, 500])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_gen = gen_samples.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_10sec)\n",
    "#Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_30sec_labels.head()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_30sec_labels)\n",
    "\n",
    "le.classes_\n",
    "\n",
    "y_30sec_labels=le.transform(y_30sec_labels)\n",
    "\n",
    "y_30sec_labels.shape\n",
    "\n",
    "nb_classes = 14\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train_labels = np_utils.to_categorical(y_30sec_labels, nb_classes)\n",
    "\n",
    "Y_train_labels.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/dev_feat_BNF_h5_03Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/eval_feat_BNF_h5_03Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = eval_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_eval = eval_lre[\"language_code\"]\n",
    "y_eval_segmentid = eval_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.values\n",
    "X_eval = X_eval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_labels = le.transform(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  2,  5,  3,  3,  1, 12, 13,  6,  5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)\n",
    "Y_eval = np_utils.to_categorical(y_eval_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               256512    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7182      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 526,350\n",
      "Trainable params: 526,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114276 samples, validate on 3661 samples\n",
      "Epoch 1/50\n",
      "Epoch 00000: val_acc improved from -inf to 0.62251, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.5178 - acc: 0.8336 - val_loss: 1.6123 - val_acc: 0.6225\n",
      "Epoch 2/50\n",
      "Epoch 00001: val_acc improved from 0.62251 to 0.65146, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.1062 - acc: 0.9647 - val_loss: 1.6558 - val_acc: 0.6515\n",
      "Epoch 3/50\n",
      "Epoch 00002: val_acc improved from 0.65146 to 0.67632, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.0782 - acc: 0.9731 - val_loss: 1.5722 - val_acc: 0.6763\n",
      "Epoch 4/50\n",
      "Epoch 00003: val_acc improved from 0.67632 to 0.68561, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.0607 - acc: 0.9788 - val_loss: 1.5672 - val_acc: 0.6856\n",
      "Epoch 5/50\n",
      "Epoch 00004: val_acc improved from 0.68561 to 0.69680, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.0520 - acc: 0.9818 - val_loss: 1.5837 - val_acc: 0.6968\n",
      "Epoch 6/50\n",
      "Epoch 00005: val_acc did not improve\n",
      "8s - loss: 0.0439 - acc: 0.9851 - val_loss: 1.6039 - val_acc: 0.6938\n",
      "Epoch 7/50\n",
      "Epoch 00006: val_acc improved from 0.69680 to 0.70254, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "8s - loss: 0.0392 - acc: 0.9865 - val_loss: 1.6902 - val_acc: 0.7025\n",
      "Epoch 8/50\n",
      "Epoch 00007: val_acc did not improve\n",
      "8s - loss: 0.0373 - acc: 0.9873 - val_loss: 1.8341 - val_acc: 0.6881\n",
      "Epoch 9/50\n",
      "Epoch 00008: val_acc did not improve\n",
      "8s - loss: 0.0332 - acc: 0.9887 - val_loss: 1.9369 - val_acc: 0.6796\n",
      "Epoch 10/50\n",
      "Epoch 00009: val_acc did not improve\n",
      "8s - loss: 0.0305 - acc: 0.9898 - val_loss: 1.9381 - val_acc: 0.6815\n",
      "Epoch 11/50\n",
      "Epoch 00010: val_acc did not improve\n",
      "8s - loss: 0.0295 - acc: 0.9904 - val_loss: 1.9281 - val_acc: 0.6894\n",
      "Epoch 12/50\n",
      "Epoch 00011: val_acc did not improve\n",
      "8s - loss: 0.0285 - acc: 0.9908 - val_loss: 2.1439 - val_acc: 0.6706\n",
      "Epoch 13/50\n",
      "Epoch 00012: val_acc did not improve\n",
      "8s - loss: 0.0275 - acc: 0.9909 - val_loss: 2.1102 - val_acc: 0.6812\n",
      "Epoch 14/50\n",
      "Epoch 00013: val_acc did not improve\n",
      "8s - loss: 0.0250 - acc: 0.9918 - val_loss: 1.9718 - val_acc: 0.6872\n",
      "Epoch 15/50\n",
      "Epoch 00014: val_acc did not improve\n",
      "8s - loss: 0.0245 - acc: 0.9923 - val_loss: 2.0060 - val_acc: 0.6883\n",
      "Epoch 16/50\n",
      "Epoch 00015: val_acc did not improve\n",
      "8s - loss: 0.0240 - acc: 0.9919 - val_loss: 2.0426 - val_acc: 0.6739\n",
      "Epoch 17/50\n",
      "Epoch 00016: val_acc did not improve\n",
      "8s - loss: 0.0260 - acc: 0.9917 - val_loss: 2.0582 - val_acc: 0.6788\n",
      "Epoch 18/50\n",
      "Epoch 00017: val_acc did not improve\n",
      "8s - loss: 0.0242 - acc: 0.9924 - val_loss: 2.0061 - val_acc: 0.6845\n",
      "Epoch 19/50\n",
      "Epoch 00018: val_acc did not improve\n",
      "8s - loss: 0.0229 - acc: 0.9928 - val_loss: 2.0422 - val_acc: 0.6807\n",
      "Epoch 20/50\n",
      "Epoch 00019: val_acc did not improve\n",
      "8s - loss: 0.0221 - acc: 0.9931 - val_loss: 2.1125 - val_acc: 0.6810\n",
      "Epoch 21/50\n",
      "Epoch 00020: val_acc did not improve\n",
      "8s - loss: 0.0217 - acc: 0.9932 - val_loss: 2.0299 - val_acc: 0.6851\n",
      "Epoch 22/50\n",
      "Epoch 00021: val_acc did not improve\n",
      "8s - loss: 0.0217 - acc: 0.9934 - val_loss: 2.1281 - val_acc: 0.6790\n",
      "Epoch 23/50\n",
      "Epoch 00022: val_acc did not improve\n",
      "8s - loss: 0.0220 - acc: 0.9931 - val_loss: 2.0500 - val_acc: 0.6870\n",
      "Epoch 24/50\n",
      "Epoch 00023: val_acc did not improve\n",
      "8s - loss: 0.0212 - acc: 0.9936 - val_loss: 2.1205 - val_acc: 0.6845\n",
      "Epoch 25/50\n",
      "Epoch 00024: val_acc did not improve\n",
      "8s - loss: 0.0221 - acc: 0.9933 - val_loss: 2.1775 - val_acc: 0.6730\n",
      "Epoch 26/50\n",
      "Epoch 00025: val_acc did not improve\n",
      "8s - loss: 0.0199 - acc: 0.9941 - val_loss: 2.1446 - val_acc: 0.6747\n",
      "Epoch 27/50\n",
      "Epoch 00026: val_acc did not improve\n",
      "8s - loss: 0.0192 - acc: 0.9944 - val_loss: 2.1614 - val_acc: 0.6692\n",
      "Epoch 28/50\n",
      "Epoch 00027: val_acc did not improve\n",
      "8s - loss: 0.0193 - acc: 0.9944 - val_loss: 2.1086 - val_acc: 0.6826\n",
      "Epoch 29/50\n",
      "Epoch 00028: val_acc did not improve\n",
      "8s - loss: 0.0189 - acc: 0.9942 - val_loss: 2.1243 - val_acc: 0.6862\n",
      "Epoch 30/50\n",
      "Epoch 00029: val_acc did not improve\n",
      "8s - loss: 0.0191 - acc: 0.9943 - val_loss: 2.3249 - val_acc: 0.6580\n",
      "Epoch 31/50\n",
      "Epoch 00030: val_acc did not improve\n",
      "8s - loss: 0.0192 - acc: 0.9945 - val_loss: 2.2170 - val_acc: 0.6730\n",
      "Epoch 32/50\n",
      "Epoch 00031: val_acc did not improve\n",
      "8s - loss: 0.0207 - acc: 0.9944 - val_loss: 2.0901 - val_acc: 0.6801\n",
      "Epoch 33/50\n",
      "Epoch 00032: val_acc did not improve\n",
      "8s - loss: 0.0182 - acc: 0.9946 - val_loss: 2.2847 - val_acc: 0.6733\n",
      "Epoch 34/50\n",
      "Epoch 00033: val_acc did not improve\n",
      "8s - loss: 0.0201 - acc: 0.9942 - val_loss: 2.2007 - val_acc: 0.6782\n",
      "Epoch 35/50\n",
      "Epoch 00034: val_acc did not improve\n",
      "8s - loss: 0.0183 - acc: 0.9947 - val_loss: 2.2915 - val_acc: 0.6790\n",
      "Epoch 36/50\n",
      "Epoch 00035: val_acc did not improve\n",
      "8s - loss: 0.0204 - acc: 0.9943 - val_loss: 2.0800 - val_acc: 0.6892\n",
      "Epoch 37/50\n",
      "Epoch 00036: val_acc did not improve\n",
      "8s - loss: 0.0183 - acc: 0.9949 - val_loss: 2.0850 - val_acc: 0.6864\n",
      "Epoch 38/50\n",
      "Epoch 00037: val_acc did not improve\n",
      "8s - loss: 0.0181 - acc: 0.9948 - val_loss: 1.9527 - val_acc: 0.6897\n",
      "Epoch 39/50\n",
      "Epoch 00038: val_acc did not improve\n",
      "8s - loss: 0.0183 - acc: 0.9949 - val_loss: 2.3111 - val_acc: 0.6728\n",
      "Epoch 40/50\n",
      "Epoch 00039: val_acc did not improve\n",
      "8s - loss: 0.0213 - acc: 0.9943 - val_loss: 2.1928 - val_acc: 0.6706\n",
      "Epoch 41/50\n",
      "Epoch 00040: val_acc did not improve\n",
      "8s - loss: 0.0183 - acc: 0.9950 - val_loss: 2.1972 - val_acc: 0.6750\n",
      "Epoch 42/50\n",
      "Epoch 00041: val_acc did not improve\n",
      "8s - loss: 0.0167 - acc: 0.9953 - val_loss: 2.1718 - val_acc: 0.6747\n",
      "Epoch 43/50\n",
      "Epoch 00042: val_acc did not improve\n",
      "8s - loss: 0.0160 - acc: 0.9955 - val_loss: 2.2574 - val_acc: 0.6725\n",
      "Epoch 44/50\n",
      "Epoch 00043: val_acc did not improve\n",
      "8s - loss: 0.0176 - acc: 0.9952 - val_loss: 2.3499 - val_acc: 0.6782\n",
      "Epoch 45/50\n",
      "Epoch 00044: val_acc did not improve\n",
      "8s - loss: 0.0174 - acc: 0.9951 - val_loss: 2.3820 - val_acc: 0.6780\n",
      "Epoch 46/50\n",
      "Epoch 00045: val_acc did not improve\n",
      "8s - loss: 0.0202 - acc: 0.9946 - val_loss: 2.2231 - val_acc: 0.6763\n",
      "Epoch 47/50\n",
      "Epoch 00046: val_acc did not improve\n",
      "8s - loss: 0.0172 - acc: 0.9953 - val_loss: 2.1499 - val_acc: 0.6872\n",
      "Epoch 48/50\n",
      "Epoch 00047: val_acc did not improve\n",
      "8s - loss: 0.0171 - acc: 0.9955 - val_loss: 2.4368 - val_acc: 0.6717\n",
      "Epoch 49/50\n",
      "Epoch 00048: val_acc did not improve\n",
      "8s - loss: 0.0177 - acc: 0.9954 - val_loss: 2.2955 - val_acc: 0.6821\n",
      "Epoch 50/50\n",
      "Epoch 00049: val_acc did not improve\n",
      "8s - loss: 0.0176 - acc: 0.9953 - val_loss: 2.2502 - val_acc: 0.6810\n"
     ]
    }
   ],
   "source": [
    "#train_X_gen\n",
    "#Checking Accuracy with augmented data \n",
    "history = model.fit(train_X_gen,Y_train_labels , batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_val , Y_val),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc %: 0.682527209154\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_eval, Y_eval, verbose=0)\n",
    "print('Acc %:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
