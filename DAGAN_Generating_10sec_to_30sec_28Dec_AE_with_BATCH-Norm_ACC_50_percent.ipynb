{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_10sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_10sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>ids</th>\n",
       "      <th>year</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314181</td>\n",
       "      <td>0.671920</td>\n",
       "      <td>-0.188068</td>\n",
       "      <td>-0.910752</td>\n",
       "      <td>1.050361</td>\n",
       "      <td>1.966829</td>\n",
       "      <td>0.292740</td>\n",
       "      <td>1.084547</td>\n",
       "      <td>1.287480</td>\n",
       "      <td>1.745248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564911</td>\n",
       "      <td>-1.854116</td>\n",
       "      <td>-3.185948</td>\n",
       "      <td>-2.177057</td>\n",
       "      <td>0.301166</td>\n",
       "      <td>zkllk</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>zkllk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>0.500546</td>\n",
       "      <td>-0.716668</td>\n",
       "      <td>1.337575</td>\n",
       "      <td>-1.027019</td>\n",
       "      <td>0.773720</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>1.728001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886613</td>\n",
       "      <td>6.766799</td>\n",
       "      <td>-1.040380</td>\n",
       "      <td>-0.751316</td>\n",
       "      <td>-1.487938</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>eng-usg</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.141677</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>-0.595182</td>\n",
       "      <td>-0.595953</td>\n",
       "      <td>0.889385</td>\n",
       "      <td>1.440080</td>\n",
       "      <td>-1.208933</td>\n",
       "      <td>0.129059</td>\n",
       "      <td>-0.930121</td>\n",
       "      <td>0.401362</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.836253</td>\n",
       "      <td>-0.323334</td>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.481039</td>\n",
       "      <td>0.395826</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.708722</td>\n",
       "      <td>-0.663542</td>\n",
       "      <td>0.031733</td>\n",
       "      <td>0.358099</td>\n",
       "      <td>0.594610</td>\n",
       "      <td>1.023025</td>\n",
       "      <td>-1.450633</td>\n",
       "      <td>0.252159</td>\n",
       "      <td>-0.381832</td>\n",
       "      <td>0.087693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384728</td>\n",
       "      <td>0.426863</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>1.655650</td>\n",
       "      <td>-1.029032</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.873292</td>\n",
       "      <td>-0.272493</td>\n",
       "      <td>-0.305948</td>\n",
       "      <td>-0.250047</td>\n",
       "      <td>2.093700</td>\n",
       "      <td>1.741634</td>\n",
       "      <td>-0.750633</td>\n",
       "      <td>-0.651771</td>\n",
       "      <td>-0.793287</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>-0.888710</td>\n",
       "      <td>1.792536</td>\n",
       "      <td>-0.628455</td>\n",
       "      <td>1.912622</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "      <td>fla_0240-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.314181  0.671920 -0.188068 -0.910752  1.050361  1.966829  0.292740   \n",
       "1  0.503734  0.247072  0.451463  0.500546 -0.716668  1.337575 -1.027019   \n",
       "2  2.141677 -0.044947 -0.595182 -0.595953  0.889385  1.440080 -1.208933   \n",
       "3  1.708722 -0.663542  0.031733  0.358099  0.594610  1.023025 -1.450633   \n",
       "4  1.873292 -0.272493 -0.305948 -0.250047  2.093700  1.741634 -0.750633   \n",
       "\n",
       "          7         8         9        ...              495       496  \\\n",
       "0  1.084547  1.287480  1.745248        ...        -0.564911 -1.854116   \n",
       "1  0.773720  0.910362  1.728001        ...         0.886613  6.766799   \n",
       "2  0.129059 -0.930121  0.401362        ...        -2.836253 -0.323334   \n",
       "3  0.252159 -0.381832  0.087693        ...         1.384728  0.426863   \n",
       "4 -0.651771 -0.793287 -0.053527        ...         0.188493 -0.888710   \n",
       "\n",
       "        497       498       499               ids        year  data     lang  \\\n",
       "0 -3.185948 -2.177057  0.301166             zkllk  LDC2017E22  data  eng-usg   \n",
       "1 -1.040380 -0.751316 -1.487938  lid05e1_lid00562  LDC2017E22  data  eng-usg   \n",
       "2  0.055760  0.481039  0.395826        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "3  0.482178  1.655650 -1.029032        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "4  1.792536 -0.628455  1.912622        fla_0240-a  LDC2017E22  data  ara-apc   \n",
       "\n",
       "            lang_id  \n",
       "0             zkllk  \n",
       "1  lid05e1_lid00562  \n",
       "2        fla_0240-a  \n",
       "3        fla_0240-a  \n",
       "4        fla_0240-a  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre_10sec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = train_lre_10sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre_30sec = pd.read_csv('/home/satishk/GAN_lre/gan_csv/GAN_30sec_ivectors_X_train_04Jan_labels_ids_combined_extraction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec = train_lre_30sec.drop(['ids','year','data','lang','lang_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels = train_lre_30sec[\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    eng-usg\n",
       "1    eng-usg\n",
       "2    ara-apc\n",
       "3    ara-apc\n",
       "4    ara-apc\n",
       "Name: lang, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10sec = X_train_10sec.values\n",
    "X_train_30sec = X_train_30sec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_10sec shape: (114276, 500)\n",
      "114276 train 10sec\n",
      "114276  train 30sec\n"
     ]
    }
   ],
   "source": [
    "X_train_10sec = X_train_10sec.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_train_30sec = X_train_30sec.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train_10sec shape:', X_train_10sec.shape)\n",
    "print(X_train_10sec.shape[0], 'train 10sec')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_train_30sec.shape[0], ' train 30sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the Dataset\n",
    "#X_train_10sec_F,  X_train_30sec_F = shuffle(X_train_10sec, X_train_30sec, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Generator as Encoder-Decoder pair inspired from DAGAN base paper\n",
    "\n",
    "#Encoder should be able to take a batch of input(of dim 500-ivector) and be able to produce \n",
    "#its representation r\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(500, 512)\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn_2 = torch.nn.BatchNorm1d(256)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "    def forward(self, x):\n",
    "        return self.fc3(self.bn_2(F.relu(self.fc2(self.bn_1(F.relu(self.fc1(x)))))))\n",
    "    \n",
    "#We will use Decoder as Generator    \n",
    "#Decoder should be able to take input of dim 128(r) and 100(z),concatenate r and z and \n",
    "#produce an output od dim 500-ivector    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(128,256 )\n",
    "        self.bn_1 = torch.nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn_2 = torch.nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,500)\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs #torch.cat([z, x], 1)\n",
    "        return (self.fc3(self.bn_2(F.relu(self.fc2(self.bn_1(F.relu(self.fc1(inputs))))))))\n",
    "\n",
    "#input to Generator alias Decoder is inputs = torch.cat([z, r], 1)\n",
    "#Where r is the output of encoder given x i.e., representation of x encoded by encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we defined the Encoder and Decoder we now Implement the Generator \n",
    "\n",
    "class Generator(nn.Module):\n",
    "                                \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = Encoder()\n",
    "        self.fc2 = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x   #torch.cat([z, x], 1)\n",
    "        return self.fc2(self.fc1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (fc1): Encoder(\n",
       "    (fc1): Linear(in_features=500, out_features=512)\n",
       "    (bn_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256)\n",
       "    (bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (fc3): Linear(in_features=256, out_features=128)\n",
       "  )\n",
       "  (fc2): Decoder(\n",
       "    (fc1): Linear(in_features=128, out_features=256)\n",
       "    (bn_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (fc2): Linear(in_features=256, out_features=512)\n",
       "    (bn_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (fc3): Linear(in_features=512, out_features=500)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizers\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=betas)\n",
    "#D_solver = torch.optim.Adam(D.parameters(), lr=learning_rate/2, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_10sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114276"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_30sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "G_loss: [ 1.56981432]\n",
      "epoch: 1\n",
      "G_loss: [ 1.48842525]\n",
      "epoch: 2\n",
      "G_loss: [ 1.45837951]\n",
      "epoch: 3\n",
      "G_loss: [ 1.44716787]\n",
      "epoch: 4\n",
      "G_loss: [ 1.44149923]\n",
      "epoch: 5\n",
      "G_loss: [ 1.43748081]\n",
      "epoch: 6\n",
      "G_loss: [ 1.43446875]\n",
      "epoch: 7\n",
      "G_loss: [ 1.43198037]\n",
      "epoch: 8\n",
      "G_loss: [ 1.42990685]\n",
      "epoch: 9\n",
      "G_loss: [ 1.42809391]\n",
      "epoch: 10\n",
      "G_loss: [ 1.42652392]\n",
      "epoch: 11\n",
      "G_loss: [ 1.42498887]\n",
      "epoch: 12\n",
      "G_loss: [ 1.42354906]\n",
      "epoch: 13\n",
      "G_loss: [ 1.42217588]\n",
      "epoch: 14\n",
      "G_loss: [ 1.42079389]\n",
      "epoch: 15\n",
      "G_loss: [ 1.41930628]\n",
      "epoch: 16\n",
      "G_loss: [ 1.41789043]\n",
      "epoch: 17\n",
      "G_loss: [ 1.41641748]\n",
      "epoch: 18\n",
      "G_loss: [ 1.41502798]\n",
      "epoch: 19\n",
      "G_loss: [ 1.41341376]\n",
      "epoch: 20\n",
      "G_loss: [ 1.41176403]\n",
      "epoch: 21\n",
      "G_loss: [ 1.41001999]\n",
      "epoch: 22\n",
      "G_loss: [ 1.40831685]\n",
      "epoch: 23\n",
      "G_loss: [ 1.40647137]\n",
      "epoch: 24\n",
      "G_loss: [ 1.4046942]\n",
      "epoch: 25\n",
      "G_loss: [ 1.40297377]\n",
      "epoch: 26\n",
      "G_loss: [ 1.40122342]\n",
      "epoch: 27\n",
      "G_loss: [ 1.39950621]\n",
      "epoch: 28\n",
      "G_loss: [ 1.39791954]\n",
      "epoch: 29\n",
      "G_loss: [ 1.39639461]\n",
      "epoch: 30\n",
      "G_loss: [ 1.39487183]\n",
      "epoch: 31\n",
      "G_loss: [ 1.39336681]\n",
      "epoch: 32\n",
      "G_loss: [ 1.39195943]\n",
      "epoch: 33\n",
      "G_loss: [ 1.39058697]\n",
      "epoch: 34\n",
      "G_loss: [ 1.3892101]\n",
      "epoch: 35\n",
      "G_loss: [ 1.38794029]\n",
      "epoch: 36\n",
      "G_loss: [ 1.38667977]\n",
      "epoch: 37\n",
      "G_loss: [ 1.38546789]\n",
      "epoch: 38\n",
      "G_loss: [ 1.38425016]\n",
      "epoch: 39\n",
      "G_loss: [ 1.38302517]\n",
      "epoch: 40\n",
      "G_loss: [ 1.38185906]\n",
      "epoch: 41\n",
      "G_loss: [ 1.38052404]\n",
      "epoch: 42\n",
      "G_loss: [ 1.37934995]\n",
      "epoch: 43\n",
      "G_loss: [ 1.37811339]\n",
      "epoch: 44\n",
      "G_loss: [ 1.37701571]\n",
      "epoch: 45\n",
      "G_loss: [ 1.37593043]\n",
      "epoch: 46\n",
      "G_loss: [ 1.37487757]\n",
      "epoch: 47\n",
      "G_loss: [ 1.37378502]\n",
      "epoch: 48\n",
      "G_loss: [ 1.37279999]\n",
      "epoch: 49\n",
      "G_loss: [ 1.37175846]\n",
      "epoch: 50\n",
      "G_loss: [ 1.37080121]\n",
      "epoch: 51\n",
      "G_loss: [ 1.36978745]\n",
      "epoch: 52\n",
      "G_loss: [ 1.36882246]\n",
      "epoch: 53\n",
      "G_loss: [ 1.3679769]\n",
      "epoch: 54\n",
      "G_loss: [ 1.36714172]\n",
      "epoch: 55\n",
      "G_loss: [ 1.36624455]\n",
      "epoch: 56\n",
      "G_loss: [ 1.36531687]\n",
      "epoch: 57\n",
      "G_loss: [ 1.36454141]\n",
      "epoch: 58\n",
      "G_loss: [ 1.36376524]\n",
      "epoch: 59\n",
      "G_loss: [ 1.36306381]\n",
      "epoch: 60\n",
      "G_loss: [ 1.36221409]\n",
      "epoch: 61\n",
      "G_loss: [ 1.36133051]\n",
      "epoch: 62\n",
      "G_loss: [ 1.36056507]\n",
      "epoch: 63\n",
      "G_loss: [ 1.35989523]\n",
      "epoch: 64\n",
      "G_loss: [ 1.35911942]\n",
      "epoch: 65\n",
      "G_loss: [ 1.35839689]\n",
      "epoch: 66\n",
      "G_loss: [ 1.35769856]\n",
      "epoch: 67\n",
      "G_loss: [ 1.35694015]\n",
      "epoch: 68\n",
      "G_loss: [ 1.35619986]\n",
      "epoch: 69\n",
      "G_loss: [ 1.35543156]\n",
      "epoch: 70\n",
      "G_loss: [ 1.35467172]\n",
      "epoch: 71\n",
      "G_loss: [ 1.35399282]\n",
      "epoch: 72\n",
      "G_loss: [ 1.35330856]\n",
      "epoch: 73\n",
      "G_loss: [ 1.3525877]\n",
      "epoch: 74\n",
      "G_loss: [ 1.35186899]\n",
      "epoch: 75\n",
      "G_loss: [ 1.35125685]\n",
      "epoch: 76\n",
      "G_loss: [ 1.35052037]\n",
      "epoch: 77\n",
      "G_loss: [ 1.34978318]\n",
      "epoch: 78\n",
      "G_loss: [ 1.34917474]\n",
      "epoch: 79\n",
      "G_loss: [ 1.34853888]\n",
      "epoch: 80\n",
      "G_loss: [ 1.34771061]\n",
      "epoch: 81\n",
      "G_loss: [ 1.347188]\n",
      "epoch: 82\n",
      "G_loss: [ 1.34653914]\n",
      "epoch: 83\n",
      "G_loss: [ 1.34587741]\n",
      "epoch: 84\n",
      "G_loss: [ 1.34519899]\n",
      "epoch: 85\n",
      "G_loss: [ 1.34450293]\n",
      "epoch: 86\n",
      "G_loss: [ 1.3438586]\n",
      "epoch: 87\n",
      "G_loss: [ 1.34330142]\n",
      "epoch: 88\n",
      "G_loss: [ 1.34267247]\n",
      "epoch: 89\n",
      "G_loss: [ 1.34200132]\n",
      "epoch: 90\n",
      "G_loss: [ 1.34133613]\n",
      "epoch: 91\n",
      "G_loss: [ 1.34070635]\n",
      "epoch: 92\n",
      "G_loss: [ 1.34008896]\n",
      "epoch: 93\n",
      "G_loss: [ 1.33944142]\n",
      "epoch: 94\n",
      "G_loss: [ 1.33883893]\n",
      "epoch: 95\n",
      "G_loss: [ 1.33817422]\n",
      "epoch: 96\n",
      "G_loss: [ 1.33756673]\n",
      "epoch: 97\n",
      "G_loss: [ 1.33691907]\n",
      "epoch: 98\n",
      "G_loss: [ 1.33623004]\n",
      "epoch: 99\n",
      "G_loss: [ 1.33568668]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mb_size = 256\n",
    "batch_size = mb_size\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    while it+batch_size < len(X_train_10sec) :\n",
    "        \n",
    "\n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "\n",
    "\n",
    "        #z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        X = X_train_10sec[start:end]\n",
    "\n",
    "        c = X_train_30sec[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "        X = X.cuda()\n",
    "        c = c.cuda()\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(X)\n",
    "        #D_real = D(X, c)\n",
    "        #D_fake = D(G_sample, c)\n",
    "\n",
    "        #D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "        #D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "        #D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        #D_loss.backward()\n",
    "        #D_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        #D.zero_grad()\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        #z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        #G_sample = G(z, c)\n",
    "        #D_fake = D(G_sample, c)\n",
    "        G_loss = criterion(G_sample, c)\n",
    "        #G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "        \n",
    "        G_solver.zero_grad()\n",
    "        # Housekeeping - reset gradient\n",
    "        #D.zero_grad()\n",
    "\n",
    "        #Print and plot every now and then\n",
    "        #if it % 2 == 0:\n",
    "\n",
    "        #print('Iter-{}; G_loss: {}'.format(it, G_loss.data.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "        it+= batch_size\n",
    "    print('G_loss: {}'.format(G_loss.cpu().data.numpy()))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30sec_gen = Variable(torch.from_numpy(X_train_10sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_samples = G(X_train_30sec_gen.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114276, 500])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_gen = gen_samples.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_10sec)\n",
    "#Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    eng-usg\n",
       "1    eng-usg\n",
       "2    ara-apc\n",
       "3    ara-apc\n",
       "4    ara-apc\n",
       "Name: lang, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_30sec_labels=le.transform(y_30sec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_30sec_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train_labels = np_utils.to_categorical(y_30sec_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114276, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/dev_feat_BNF_h5_03Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lre = pd.read_csv('/home/satishk/GAN_lre/gan_csv/eval_feat_BNF_h5_03Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = eval_lre.drop([\"language_code\",\"uttid\",\"segmentid1\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_eval = eval_lre[\"language_code\"]\n",
    "y_eval_segmentid = eval_lre[\"segmentid1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.values\n",
    "X_eval = X_eval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_labels = le.transform(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  2,  5,  3,  3,  1, 12, 13,  6,  5])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)\n",
    "Y_eval = np_utils.to_categorical(y_eval_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               256512    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                7182      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 526,350\n",
      "Trainable params: 526,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114276 samples, validate on 3661 samples\n",
      "Epoch 1/25\n",
      "Epoch 00000: val_acc improved from -inf to 0.42884, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.3259 - acc: 0.9009 - val_loss: 3.5983 - val_acc: 0.4288\n",
      "Epoch 2/25\n",
      "Epoch 00001: val_acc improved from 0.42884 to 0.48948, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.1224 - acc: 0.9598 - val_loss: 3.2403 - val_acc: 0.4895\n",
      "Epoch 3/25\n",
      "Epoch 00002: val_acc did not improve\n",
      "9s - loss: 0.1024 - acc: 0.9662 - val_loss: 3.3638 - val_acc: 0.4865\n",
      "Epoch 4/25\n",
      "Epoch 00003: val_acc improved from 0.48948 to 0.51352, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.0898 - acc: 0.9702 - val_loss: 3.1103 - val_acc: 0.5135\n",
      "Epoch 5/25\n",
      "Epoch 00004: val_acc did not improve\n",
      "9s - loss: 0.0816 - acc: 0.9723 - val_loss: 3.5352 - val_acc: 0.5007\n",
      "Epoch 6/25\n",
      "Epoch 00005: val_acc did not improve\n",
      "9s - loss: 0.0754 - acc: 0.9741 - val_loss: 3.5787 - val_acc: 0.5040\n",
      "Epoch 7/25\n",
      "Epoch 00006: val_acc did not improve\n",
      "9s - loss: 0.0690 - acc: 0.9770 - val_loss: 3.9155 - val_acc: 0.4928\n",
      "Epoch 8/25\n",
      "Epoch 00007: val_acc did not improve\n",
      "9s - loss: 0.0650 - acc: 0.9776 - val_loss: 3.6685 - val_acc: 0.5048\n",
      "Epoch 9/25\n",
      "Epoch 00008: val_acc improved from 0.51352 to 0.52390, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.0620 - acc: 0.9792 - val_loss: 3.5357 - val_acc: 0.5239\n",
      "Epoch 10/25\n",
      "Epoch 00009: val_acc did not improve\n",
      "9s - loss: 0.0586 - acc: 0.9799 - val_loss: 3.9202 - val_acc: 0.5010\n",
      "Epoch 11/25\n",
      "Epoch 00010: val_acc did not improve\n",
      "9s - loss: 0.0554 - acc: 0.9806 - val_loss: 3.7766 - val_acc: 0.5122\n",
      "Epoch 12/25\n",
      "Epoch 00011: val_acc did not improve\n",
      "9s - loss: 0.0531 - acc: 0.9820 - val_loss: 3.6711 - val_acc: 0.5173\n",
      "Epoch 13/25\n",
      "Epoch 00012: val_acc did not improve\n",
      "9s - loss: 0.0501 - acc: 0.9827 - val_loss: 3.9057 - val_acc: 0.5141\n",
      "Epoch 14/25\n",
      "Epoch 00013: val_acc did not improve\n",
      "9s - loss: 0.0481 - acc: 0.9834 - val_loss: 3.8088 - val_acc: 0.5165\n",
      "Epoch 15/25\n",
      "Epoch 00014: val_acc improved from 0.52390 to 0.52445, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.0460 - acc: 0.9842 - val_loss: 3.8222 - val_acc: 0.5244\n",
      "Epoch 16/25\n",
      "Epoch 00015: val_acc did not improve\n",
      "9s - loss: 0.0466 - acc: 0.9838 - val_loss: 3.9456 - val_acc: 0.5149\n",
      "Epoch 17/25\n",
      "Epoch 00016: val_acc did not improve\n",
      "8s - loss: 0.0441 - acc: 0.9853 - val_loss: 3.8163 - val_acc: 0.5190\n",
      "Epoch 18/25\n",
      "Epoch 00017: val_acc did not improve\n",
      "8s - loss: 0.0429 - acc: 0.9852 - val_loss: 3.9694 - val_acc: 0.5053\n",
      "Epoch 19/25\n",
      "Epoch 00018: val_acc did not improve\n",
      "8s - loss: 0.0413 - acc: 0.9859 - val_loss: 4.0181 - val_acc: 0.5111\n",
      "Epoch 20/25\n",
      "Epoch 00019: val_acc did not improve\n",
      "8s - loss: 0.0425 - acc: 0.9857 - val_loss: 4.0296 - val_acc: 0.5111\n",
      "Epoch 21/25\n",
      "Epoch 00020: val_acc did not improve\n",
      "8s - loss: 0.0405 - acc: 0.9864 - val_loss: 4.1931 - val_acc: 0.5007\n",
      "Epoch 22/25\n",
      "Epoch 00021: val_acc did not improve\n",
      "8s - loss: 0.0401 - acc: 0.9866 - val_loss: 4.1474 - val_acc: 0.5198\n",
      "Epoch 23/25\n",
      "Epoch 00022: val_acc did not improve\n",
      "8s - loss: 0.0399 - acc: 0.9869 - val_loss: 4.1144 - val_acc: 0.5195\n",
      "Epoch 24/25\n",
      "Epoch 00023: val_acc did not improve\n",
      "9s - loss: 0.0372 - acc: 0.9879 - val_loss: 4.0663 - val_acc: 0.5127\n",
      "Epoch 25/25\n",
      "Epoch 00024: val_acc improved from 0.52445 to 0.52527, saving model to /home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5\n",
      "9s - loss: 0.0350 - acc: 0.9885 - val_loss: 3.9667 - val_acc: 0.5253\n"
     ]
    }
   ],
   "source": [
    "#train_X_gen\n",
    "#Checking Accuracy with training+augmented data train_X and train_y are 'train + augmented' data\n",
    "history = model.fit(train_X_gen,Y_train_labels , batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_val , Y_val),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc %: 0.526108993759\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_eval, Y_eval, verbose=0)\n",
    "print('Acc %:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
