{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/train_feat_BNF_h5_07Nov_Shreyas.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>langid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.141175</td>\n",
       "      <td>-1.160019</td>\n",
       "      <td>0.891814</td>\n",
       "      <td>1.898842</td>\n",
       "      <td>0.393065</td>\n",
       "      <td>0.983582</td>\n",
       "      <td>-0.559143</td>\n",
       "      <td>-0.761900</td>\n",
       "      <td>0.525598</td>\n",
       "      <td>0.344597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587687</td>\n",
       "      <td>-0.609223</td>\n",
       "      <td>1.529694</td>\n",
       "      <td>1.677775</td>\n",
       "      <td>-0.388426</td>\n",
       "      <td>1.044584</td>\n",
       "      <td>-1.365691</td>\n",
       "      <td>-0.354752</td>\n",
       "      <td>-0.815562</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971834</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>0.785385</td>\n",
       "      <td>1.328749</td>\n",
       "      <td>-0.043342</td>\n",
       "      <td>1.219254</td>\n",
       "      <td>0.761090</td>\n",
       "      <td>1.069464</td>\n",
       "      <td>0.879541</td>\n",
       "      <td>0.898939</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208031</td>\n",
       "      <td>0.527433</td>\n",
       "      <td>-0.709180</td>\n",
       "      <td>-1.117489</td>\n",
       "      <td>0.566520</td>\n",
       "      <td>1.642208</td>\n",
       "      <td>-0.703815</td>\n",
       "      <td>0.376027</td>\n",
       "      <td>-1.425985</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.315703</td>\n",
       "      <td>-0.868423</td>\n",
       "      <td>0.619893</td>\n",
       "      <td>1.717784</td>\n",
       "      <td>-0.846024</td>\n",
       "      <td>1.177214</td>\n",
       "      <td>-0.191977</td>\n",
       "      <td>-0.658569</td>\n",
       "      <td>0.529625</td>\n",
       "      <td>0.313590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896515</td>\n",
       "      <td>-0.128051</td>\n",
       "      <td>-0.075781</td>\n",
       "      <td>1.307904</td>\n",
       "      <td>-1.443047</td>\n",
       "      <td>2.551083</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>-0.623076</td>\n",
       "      <td>0.194851</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247949</td>\n",
       "      <td>-0.279720</td>\n",
       "      <td>1.320115</td>\n",
       "      <td>1.772152</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>-0.290516</td>\n",
       "      <td>0.406225</td>\n",
       "      <td>-0.833366</td>\n",
       "      <td>1.567592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.398762</td>\n",
       "      <td>-0.078148</td>\n",
       "      <td>0.168076</td>\n",
       "      <td>-0.272796</td>\n",
       "      <td>-1.102862</td>\n",
       "      <td>0.358274</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>-0.490244</td>\n",
       "      <td>1.819196</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.986578</td>\n",
       "      <td>-0.357548</td>\n",
       "      <td>1.550832</td>\n",
       "      <td>1.400735</td>\n",
       "      <td>0.444350</td>\n",
       "      <td>0.465660</td>\n",
       "      <td>0.209248</td>\n",
       "      <td>1.175847</td>\n",
       "      <td>-1.079963</td>\n",
       "      <td>0.270915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947946</td>\n",
       "      <td>0.917957</td>\n",
       "      <td>-1.043352</td>\n",
       "      <td>0.414811</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>-0.485602</td>\n",
       "      <td>-0.433002</td>\n",
       "      <td>-0.432070</td>\n",
       "      <td>0.778250</td>\n",
       "      <td>spa-eur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.141175 -1.160019  0.891814  1.898842  0.393065  0.983582 -0.559143   \n",
       "1  0.971834  0.035743  0.785385  1.328749 -0.043342  1.219254  0.761090   \n",
       "2 -0.315703 -0.868423  0.619893  1.717784 -0.846024  1.177214 -0.191977   \n",
       "3  0.247949 -0.279720  1.320115  1.772152 -0.130394  0.517343 -0.290516   \n",
       "4 -0.986578 -0.357548  1.550832  1.400735  0.444350  0.465660  0.209248   \n",
       "\n",
       "          7         8         9   ...          491       492       493  \\\n",
       "0 -0.761900  0.525598  0.344597   ...     1.587687 -0.609223  1.529694   \n",
       "1  1.069464  0.879541  0.898939   ...    -1.208031  0.527433 -0.709180   \n",
       "2 -0.658569  0.529625  0.313590   ...    -0.896515 -0.128051 -0.075781   \n",
       "3  0.406225 -0.833366  1.567592   ...    -0.398762 -0.078148  0.168076   \n",
       "4  1.175847 -1.079963  0.270915   ...     0.947946  0.917957 -1.043352   \n",
       "\n",
       "        494       495       496       497       498       499   langid  \n",
       "0  1.677775 -0.388426  1.044584 -1.365691 -0.354752 -0.815562  spa-eur  \n",
       "1 -1.117489  0.566520  1.642208 -0.703815  0.376027 -1.425985  spa-eur  \n",
       "2  1.307904 -1.443047  2.551083  0.436309 -0.623076  0.194851  spa-eur  \n",
       "3 -0.272796 -1.102862  0.358274  0.090417 -0.490244  1.819196  spa-eur  \n",
       "4  0.414811  0.016396 -0.485602 -0.433002 -0.432070  0.778250  spa-eur  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langid\n",
       "ara-acm    1406\n",
       "ara-apc    3509\n",
       "ara-ary     919\n",
       "ara-arz     440\n",
       "eng-gbr      98\n",
       "eng-usg    2448\n",
       "por-brz     444\n",
       "qsl-pol     587\n",
       "qsl-rus    1221\n",
       "spa-car     688\n",
       "spa-eur     121\n",
       "spa-lac     898\n",
       "zho-cmn    3331\n",
       "zho-nan      95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre.groupby(['langid']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a single class\n",
    "train_lre = train_lre.loc[train_lre['langid'] == 'ara-acm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/dev_feat_BNF_h5_07Nov_Shreyas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_lre = val_lre.iloc[100:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmentid</th>\n",
       "      <th>language_code</th>\n",
       "      <th>data_source</th>\n",
       "      <th>speech_duration</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>uttid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lre17_ntrlosgu.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.697234</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>-0.400756</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>-0.939232</td>\n",
       "      <td>1.500797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.314428</td>\n",
       "      <td>-0.927694</td>\n",
       "      <td>-0.370424</td>\n",
       "      <td>-0.514735</td>\n",
       "      <td>1.290885</td>\n",
       "      <td>0.688205</td>\n",
       "      <td>-0.494330</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>-1.330860</td>\n",
       "      <td>lre17_ntrlosgu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lre17_moxnwuqe.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.648232</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>-0.562867</td>\n",
       "      <td>1.035870</td>\n",
       "      <td>-1.577741</td>\n",
       "      <td>1.593584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929262</td>\n",
       "      <td>-1.301574</td>\n",
       "      <td>2.034934</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>-0.198926</td>\n",
       "      <td>-0.116174</td>\n",
       "      <td>0.347923</td>\n",
       "      <td>-0.870801</td>\n",
       "      <td>-2.599601</td>\n",
       "      <td>lre17_moxnwuqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lre17_meesvkxz.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242829</td>\n",
       "      <td>0.675515</td>\n",
       "      <td>-0.371491</td>\n",
       "      <td>0.534970</td>\n",
       "      <td>-0.246783</td>\n",
       "      <td>0.806262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691336</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>1.058771</td>\n",
       "      <td>1.018635</td>\n",
       "      <td>-1.929319</td>\n",
       "      <td>-0.307404</td>\n",
       "      <td>-0.486431</td>\n",
       "      <td>-2.839053</td>\n",
       "      <td>-2.704527</td>\n",
       "      <td>lre17_meesvkxz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lre17_rqmsmzui.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.226681</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>-0.396915</td>\n",
       "      <td>-0.097507</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>1.087025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049862</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>2.385587</td>\n",
       "      <td>0.680073</td>\n",
       "      <td>1.500978</td>\n",
       "      <td>1.660566</td>\n",
       "      <td>-0.370672</td>\n",
       "      <td>-0.924109</td>\n",
       "      <td>0.096676</td>\n",
       "      <td>lre17_rqmsmzui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lre17_qgszpuyw.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.411728</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>0.136256</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>-1.029447</td>\n",
       "      <td>1.227100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>-1.030222</td>\n",
       "      <td>2.933880</td>\n",
       "      <td>-1.417872</td>\n",
       "      <td>-0.227513</td>\n",
       "      <td>0.748810</td>\n",
       "      <td>-0.671044</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>1.722917</td>\n",
       "      <td>lre17_qgszpuyw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            segmentid language_code data_source  speech_duration         0  \\\n",
       "0  lre17_ntrlosgu.sph       ara-acm       mls14               30  1.697234   \n",
       "1  lre17_moxnwuqe.sph       ara-acm       mls14               10  1.648232   \n",
       "2  lre17_meesvkxz.sph       ara-acm       mls14                3  1.242829   \n",
       "3  lre17_rqmsmzui.sph       ara-acm       mls14               30  1.226681   \n",
       "4  lre17_qgszpuyw.sph       ara-acm       mls14               10  1.411728   \n",
       "\n",
       "          1         2         3         4         5       ...             491  \\\n",
       "0  0.029428 -0.400756  0.513963 -0.939232  1.500797       ...       -1.314428   \n",
       "1 -0.053318 -0.562867  1.035870 -1.577741  1.593584       ...       -0.929262   \n",
       "2  0.675515 -0.371491  0.534970 -0.246783  0.806262       ...        0.691336   \n",
       "3  0.014810 -0.396915 -0.097507 -0.013574  1.087025       ...        1.049862   \n",
       "4 -0.119300  0.136256  0.030535 -1.029447  1.227100       ...        0.155196   \n",
       "\n",
       "        492       493       494       495       496       497       498  \\\n",
       "0 -0.927694 -0.370424 -0.514735  1.290885  0.688205 -0.494330 -0.053206   \n",
       "1 -1.301574  2.034934 -0.226545 -0.198926 -0.116174  0.347923 -0.870801   \n",
       "2  0.257988  1.058771  1.018635 -1.929319 -0.307404 -0.486431 -2.839053   \n",
       "3  0.285627  2.385587  0.680073  1.500978  1.660566 -0.370672 -0.924109   \n",
       "4 -1.030222  2.933880 -1.417872 -0.227513  0.748810 -0.671044  0.595977   \n",
       "\n",
       "        499           uttid  \n",
       "0 -1.330860  lre17_ntrlosgu  \n",
       "1 -2.599601  lre17_moxnwuqe  \n",
       "2 -2.704527  lre17_meesvkxz  \n",
       "3  0.096676  lre17_rqmsmzui  \n",
       "4  1.722917  lre17_qgszpuyw  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_lre.drop(\"langid\",axis=1)\n",
    "y_train = train_lre[\"langid\"]\n",
    "#y_train_uttid = train_lre[\"uttid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val, ignore_index=True)\n",
    "y_train = y_train.append(y_val, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_val=X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = indices_to_one_hot(y_train, 14)\n",
    "#Y_test = indices_to_one_hot(y_test, 14)\n",
    "Y_val = indices_to_one_hot(y_val_labels, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5067, 500)\n",
      "5067 train samples\n",
      "3661 val samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_val.shape[0], 'val samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067, 500)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 13, 13, 13])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Shuffling the dataset\n",
    "#from sklearn.utils import shuffle\n",
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val,  y_val_labels = shuffle(X_val, y_val_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets('/home/satishk/depy_04_AUG/MNIST_data', one_hot=True)\n",
    "mb_size = 256\n",
    "Z_dim = 100\n",
    "X_dim = 500 #mnist.train.images.shape[1]\n",
    "y_dim = 14 #mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dim, y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Generator as Encoder-Decoder pair inspired from DAGAN base paper\n",
    "\n",
    "#Encoder should be able to take a batch of input(of dim 500-ivector) and be able to produce its representation r\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(500, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "    def forward(self, x):\n",
    "        return self.fc3(F.relu(self.fc2(F.relu(self.fc1(x)))))\n",
    "    \n",
    "#We will use Decoder as Generator    \n",
    "#Decoder should be able to take input of dim 128(r) and 100(z),concatenate r and z and \n",
    "#produce an output od dim 500-ivector    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(228,256 )\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512,500)\n",
    "    def forward(self, x):\n",
    "        #inputs = torch.cat([z, x], 1)\n",
    "        return F.sigmoid(self.fc3(F.relu(self.fc2(F.relu(self.fc1(x))))))\n",
    "\n",
    "#input to Generator alias Decoder is inputs = torch.cat([z, r], 1)\n",
    "#Where r is the output of encoder given x i.e., representation of x encoded by encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we defined the Encoder and Decoder we now Implement the Generator \n",
    "\n",
    "class Generator(nn.Module):\n",
    "                                \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = Encoder()\n",
    "        self.fc2 = Decoder()\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        #inputs = torch.cat([z, x], 1)\n",
    "        return self.fc2(torch.cat([z, self.fc1(x)],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #self.inputs = torch.cat([z, c], 1)\n",
    "        self.fc1 = torch.nn.Linear(500, 512)\n",
    "        self.fc2 = torch.nn.Linear(512,512)\n",
    "        self.fc3 = torch.nn.Linear(512,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #inputs = torch.cat([X, c], 1)\n",
    "        return F.sigmoid(self.fc3(F.relu(self.fc2(F.relu(self.fc1(x))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of Generator(\n",
       "  (fc1): Encoder(\n",
       "    (fc1): Linear(in_features=500, out_features=512)\n",
       "    (fc2): Linear(in_features=512, out_features=256)\n",
       "    (fc3): Linear(in_features=256, out_features=128)\n",
       "  )\n",
       "  (fc2): Decoder(\n",
       "    (fc1): Linear(in_features=228, out_features=256)\n",
       "    (fc2): Linear(in_features=256, out_features=512)\n",
       "    (fc3): Linear(in_features=512, out_features=500)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (fc1): Linear(in_features=500, out_features=512)\n",
       "  (fc2): Linear(in_features=512, out_features=512)\n",
       "  (fc3): Linear(in_features=512, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))\n",
    "ones_label_fake = Variable(torch.ones(mb_size*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "#criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=betas)\n",
    "D_solver = torch.optim.Adam(D.parameters(), lr=learning_rate/2, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4053"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter-0; D_loss: [ 1.3923099]; G_loss: [ 0.68064016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satishk/miniconda3/envs/lre17/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/home/satishk/miniconda3/envs/lre17/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-256; D_loss: [ 1.32532799]; G_loss: [ 0.67773587]\n",
      "Iter-512; D_loss: [ 1.26042986]; G_loss: [ 0.67278099]\n",
      "Iter-768; D_loss: [ 1.20539045]; G_loss: [ 0.67248237]\n",
      "Iter-1024; D_loss: [ 1.1521492]; G_loss: [ 0.67095649]\n",
      "Iter-1280; D_loss: [ 1.10531056]; G_loss: [ 0.67292452]\n",
      "Iter-1536; D_loss: [ 1.05051136]; G_loss: [ 0.66994667]\n",
      "Iter-1792; D_loss: [ 1.00457585]; G_loss: [ 0.67301136]\n",
      "Iter-2048; D_loss: [ 0.96177876]; G_loss: [ 0.67975926]\n",
      "Iter-2304; D_loss: [ 0.91761458]; G_loss: [ 0.68670934]\n",
      "Iter-2560; D_loss: [ 0.87502897]; G_loss: [ 0.69697028]\n",
      "Iter-2816; D_loss: [ 0.82520777]; G_loss: [ 0.70500743]\n",
      "Iter-3072; D_loss: [ 0.77675295]; G_loss: [ 0.71681732]\n",
      "Iter-3328; D_loss: [ 0.73848492]; G_loss: [ 0.7353968]\n",
      "Iter-3584; D_loss: [ 0.68780065]; G_loss: [ 0.74879307]\n",
      "epoch: 1\n",
      "Iter-0; D_loss: [ 0.65560472]; G_loss: [ 0.77047747]\n",
      "Iter-256; D_loss: [ 0.61212242]; G_loss: [ 0.78551167]\n",
      "Iter-512; D_loss: [ 0.56940925]; G_loss: [ 0.80017954]\n",
      "Iter-768; D_loss: [ 0.54405999]; G_loss: [ 0.82274568]\n",
      "Iter-1024; D_loss: [ 0.51055288]; G_loss: [ 0.84142715]\n",
      "Iter-1280; D_loss: [ 0.48554599]; G_loss: [ 0.86436701]\n",
      "Iter-1536; D_loss: [ 0.44592261]; G_loss: [ 0.88120902]\n",
      "Iter-1792; D_loss: [ 0.41996583]; G_loss: [ 0.90431327]\n",
      "Iter-2048; D_loss: [ 0.40345031]; G_loss: [ 0.93264812]\n",
      "Iter-2304; D_loss: [ 0.37695423]; G_loss: [ 0.95478523]\n",
      "Iter-2560; D_loss: [ 0.36122257]; G_loss: [ 0.98131466]\n",
      "Iter-2816; D_loss: [ 0.33048677]; G_loss: [ 0.99911457]\n",
      "Iter-3072; D_loss: [ 0.30998313]; G_loss: [ 1.01967359]\n",
      "Iter-3328; D_loss: [ 0.29855967]; G_loss: [ 1.04095674]\n",
      "Iter-3584; D_loss: [ 0.27661139]; G_loss: [ 1.05336654]\n",
      "epoch: 2\n",
      "Iter-0; D_loss: [ 0.27271268]; G_loss: [ 1.07006204]\n",
      "Iter-256; D_loss: [ 0.25750157]; G_loss: [ 1.0729928]\n",
      "Iter-512; D_loss: [ 0.24422964]; G_loss: [ 1.07489467]\n",
      "Iter-768; D_loss: [ 0.24502325]; G_loss: [ 1.06901026]\n",
      "Iter-1024; D_loss: [ 0.24455597]; G_loss: [ 1.05908835]\n",
      "Iter-1280; D_loss: [ 0.24942562]; G_loss: [ 1.03009844]\n",
      "Iter-1536; D_loss: [ 0.25452027]; G_loss: [ 0.98488194]\n",
      "Iter-1792; D_loss: [ 0.27600983]; G_loss: [ 0.92356807]\n",
      "Iter-2048; D_loss: [ 0.31282413]; G_loss: [ 0.8563354]\n",
      "Iter-2304; D_loss: [ 0.36542508]; G_loss: [ 0.76200646]\n",
      "Iter-2560; D_loss: [ 0.44231635]; G_loss: [ 0.67165506]\n",
      "Iter-2816; D_loss: [ 0.5102247]; G_loss: [ 0.5788421]\n",
      "Iter-3072; D_loss: [ 0.59177274]; G_loss: [ 0.50153577]\n",
      "Iter-3328; D_loss: [ 0.65051407]; G_loss: [ 0.45728552]\n",
      "Iter-3584; D_loss: [ 0.68730724]; G_loss: [ 0.42288834]\n",
      "epoch: 3\n",
      "Iter-0; D_loss: [ 0.6985904]; G_loss: [ 0.42114913]\n",
      "Iter-256; D_loss: [ 0.68983549]; G_loss: [ 0.41831538]\n",
      "Iter-512; D_loss: [ 0.67281091]; G_loss: [ 0.42145452]\n",
      "Iter-768; D_loss: [ 0.6501416]; G_loss: [ 0.43540877]\n",
      "Iter-1024; D_loss: [ 0.62925845]; G_loss: [ 0.44847748]\n",
      "Iter-1280; D_loss: [ 0.60627633]; G_loss: [ 0.46290642]\n",
      "Iter-1536; D_loss: [ 0.57799894]; G_loss: [ 0.47533128]\n",
      "Iter-1792; D_loss: [ 0.55357188]; G_loss: [ 0.49311405]\n",
      "Iter-2048; D_loss: [ 0.53473669]; G_loss: [ 0.51465541]\n",
      "Iter-2304; D_loss: [ 0.50622463]; G_loss: [ 0.53267431]\n",
      "Iter-2560; D_loss: [ 0.48488498]; G_loss: [ 0.55575037]\n",
      "Iter-2816; D_loss: [ 0.45290127]; G_loss: [ 0.57497841]\n",
      "Iter-3072; D_loss: [ 0.42922097]; G_loss: [ 0.59740645]\n",
      "Iter-3328; D_loss: [ 0.40958124]; G_loss: [ 0.6199581]\n",
      "Iter-3584; D_loss: [ 0.38537139]; G_loss: [ 0.63904041]\n",
      "epoch: 4\n",
      "Iter-0; D_loss: [ 0.37407827]; G_loss: [ 0.66088778]\n",
      "Iter-256; D_loss: [ 0.35662645]; G_loss: [ 0.67621225]\n",
      "Iter-512; D_loss: [ 0.34306872]; G_loss: [ 0.68869305]\n",
      "Iter-768; D_loss: [ 0.33552405]; G_loss: [ 0.69907135]\n",
      "Iter-1024; D_loss: [ 0.330948]; G_loss: [ 0.70596504]\n",
      "Iter-1280; D_loss: [ 0.32751733]; G_loss: [ 0.71019131]\n",
      "Iter-1536; D_loss: [ 0.32235181]; G_loss: [ 0.70955461]\n",
      "Iter-1792; D_loss: [ 0.32050163]; G_loss: [ 0.71197087]\n",
      "Iter-2048; D_loss: [ 0.32271308]; G_loss: [ 0.7179088]\n",
      "Iter-2304; D_loss: [ 0.31580305]; G_loss: [ 0.72138709]\n",
      "Iter-2560; D_loss: [ 0.31370047]; G_loss: [ 0.72847736]\n",
      "Iter-2816; D_loss: [ 0.30219951]; G_loss: [ 0.73425001]\n",
      "Iter-3072; D_loss: [ 0.29714689]; G_loss: [ 0.74063981]\n",
      "Iter-3328; D_loss: [ 0.29308707]; G_loss: [ 0.74739319]\n",
      "Iter-3584; D_loss: [ 0.28678128]; G_loss: [ 0.75040936]\n",
      "epoch: 5\n",
      "Iter-0; D_loss: [ 0.28757784]; G_loss: [ 0.75657922]\n",
      "Iter-256; D_loss: [ 0.28303021]; G_loss: [ 0.75946629]\n",
      "Iter-512; D_loss: [ 0.27830216]; G_loss: [ 0.76350701]\n",
      "Iter-768; D_loss: [ 0.27268472]; G_loss: [ 0.77300447]\n",
      "Iter-1024; D_loss: [ 0.26691473]; G_loss: [ 0.78390795]\n",
      "Iter-1280; D_loss: [ 0.25964612]; G_loss: [ 0.79655546]\n",
      "Iter-1536; D_loss: [ 0.24992056]; G_loss: [ 0.80872571]\n",
      "Iter-1792; D_loss: [ 0.24292004]; G_loss: [ 0.82246351]\n",
      "Iter-2048; D_loss: [ 0.24046297]; G_loss: [ 0.83748472]\n",
      "Iter-2304; D_loss: [ 0.23249143]; G_loss: [ 0.84712762]\n",
      "Iter-2560; D_loss: [ 0.23108247]; G_loss: [ 0.85519397]\n",
      "Iter-2816; D_loss: [ 0.22354551]; G_loss: [ 0.86034489]\n",
      "Iter-3072; D_loss: [ 0.21852146]; G_loss: [ 0.87033224]\n",
      "Iter-3328; D_loss: [ 0.21289524]; G_loss: [ 0.88339305]\n",
      "Iter-3584; D_loss: [ 0.20472816]; G_loss: [ 0.8956508]\n",
      "epoch: 6\n",
      "Iter-0; D_loss: [ 0.20150667]; G_loss: [ 0.91107792]\n",
      "Iter-256; D_loss: [ 0.19433297]; G_loss: [ 0.92436141]\n",
      "Iter-512; D_loss: [ 0.18808982]; G_loss: [ 0.93702537]\n",
      "Iter-768; D_loss: [ 0.18471129]; G_loss: [ 0.94649029]\n",
      "Iter-1024; D_loss: [ 0.18366493]; G_loss: [ 0.95231819]\n",
      "Iter-1280; D_loss: [ 0.17958631]; G_loss: [ 0.96287209]\n",
      "Iter-1536; D_loss: [ 0.17268911]; G_loss: [ 0.97572869]\n",
      "Iter-1792; D_loss: [ 0.16762199]; G_loss: [ 0.9906413]\n",
      "Iter-2048; D_loss: [ 0.16616304]; G_loss: [ 1.0073632]\n",
      "Iter-2304; D_loss: [ 0.15902361]; G_loss: [ 1.02122664]\n",
      "Iter-2560; D_loss: [ 0.15578394]; G_loss: [ 1.03691983]\n",
      "Iter-2816; D_loss: [ 0.14796695]; G_loss: [ 1.05046797]\n",
      "Iter-3072; D_loss: [ 0.14350781]; G_loss: [ 1.06546605]\n",
      "Iter-3328; D_loss: [ 0.13936284]; G_loss: [ 1.08050716]\n",
      "Iter-3584; D_loss: [ 0.13364311]; G_loss: [ 1.09471929]\n",
      "epoch: 7\n",
      "Iter-0; D_loss: [ 0.13180594]; G_loss: [ 1.11059403]\n",
      "Iter-256; D_loss: [ 0.12705857]; G_loss: [ 1.12490022]\n",
      "Iter-512; D_loss: [ 0.12275399]; G_loss: [ 1.13922596]\n",
      "Iter-768; D_loss: [ 0.11940852]; G_loss: [ 1.15313685]\n",
      "Iter-1024; D_loss: [ 0.11811044]; G_loss: [ 1.16532063]\n",
      "Iter-1280; D_loss: [ 0.11468596]; G_loss: [ 1.1805625]\n",
      "Iter-1536; D_loss: [ 0.1094339]; G_loss: [ 1.19643128]\n",
      "Iter-1792; D_loss: [ 0.10603725]; G_loss: [ 1.21258855]\n",
      "Iter-2048; D_loss: [ 0.10586198]; G_loss: [ 1.22977293]\n",
      "Iter-2304; D_loss: [ 0.10075755]; G_loss: [ 1.24426973]\n",
      "Iter-2560; D_loss: [ 0.09895826]; G_loss: [ 1.26009464]\n",
      "Iter-2816; D_loss: [ 0.0935795]; G_loss: [ 1.27403581]\n",
      "Iter-3072; D_loss: [ 0.09086078]; G_loss: [ 1.28907275]\n",
      "Iter-3328; D_loss: [ 0.08827884]; G_loss: [ 1.3040005]\n",
      "Iter-3584; D_loss: [ 0.084636]; G_loss: [ 1.31824374]\n",
      "epoch: 8\n",
      "Iter-0; D_loss: [ 0.08385213]; G_loss: [ 1.33358359]\n",
      "Iter-256; D_loss: [ 0.08097398]; G_loss: [ 1.34766018]\n",
      "Iter-512; D_loss: [ 0.07831743]; G_loss: [ 1.36175048]\n",
      "Iter-768; D_loss: [ 0.07598345]; G_loss: [ 1.3757503]\n",
      "Iter-1024; D_loss: [ 0.07436196]; G_loss: [ 1.38994336]\n",
      "Iter-1280; D_loss: [ 0.07255125]; G_loss: [ 1.40381563]\n",
      "Iter-1536; D_loss: [ 0.06974747]; G_loss: [ 1.41711867]\n",
      "Iter-1792; D_loss: [ 0.06803344]; G_loss: [ 1.43078506]\n",
      "Iter-2048; D_loss: [ 0.06888006]; G_loss: [ 1.44535434]\n",
      "Iter-2304; D_loss: [ 0.06548208]; G_loss: [ 1.45773673]\n",
      "Iter-2560; D_loss: [ 0.0648023]; G_loss: [ 1.47128212]\n",
      "Iter-2816; D_loss: [ 0.06127175]; G_loss: [ 1.48351789]\n",
      "Iter-3072; D_loss: [ 0.05977419]; G_loss: [ 1.49647498]\n",
      "Iter-3328; D_loss: [ 0.05833604]; G_loss: [ 1.50933707]\n",
      "Iter-3584; D_loss: [ 0.05612026]; G_loss: [ 1.52176678]\n",
      "epoch: 9\n",
      "Iter-0; D_loss: [ 0.05597829]; G_loss: [ 1.53493583]\n",
      "Iter-256; D_loss: [ 0.05432106]; G_loss: [ 1.54728532]\n",
      "Iter-512; D_loss: [ 0.05276797]; G_loss: [ 1.55944395]\n",
      "Iter-768; D_loss: [ 0.05131917]; G_loss: [ 1.57158041]\n",
      "Iter-1024; D_loss: [ 0.0504612]; G_loss: [ 1.58388126]\n",
      "Iter-1280; D_loss: [ 0.04947623]; G_loss: [ 1.59593439]\n",
      "Iter-1536; D_loss: [ 0.04768781]; G_loss: [ 1.60752261]\n",
      "Iter-1792; D_loss: [ 0.04670519]; G_loss: [ 1.61933184]\n",
      "Iter-2048; D_loss: [ 0.04785611]; G_loss: [ 1.63185513]\n",
      "Iter-2304; D_loss: [ 0.04537362]; G_loss: [ 1.64263117]\n",
      "Iter-2560; D_loss: [ 0.04517997]; G_loss: [ 1.6544981]\n",
      "Iter-2816; D_loss: [ 0.04266755]; G_loss: [ 1.66504073]\n",
      "Iter-3072; D_loss: [ 0.04178768]; G_loss: [ 1.67636979]\n",
      "Iter-3328; D_loss: [ 0.04090871]; G_loss: [ 1.68758428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3584; D_loss: [ 0.03946702]; G_loss: [ 1.69838524]\n",
      "epoch: 10\n",
      "Iter-0; D_loss: [ 0.03956528]; G_loss: [ 1.70989585]\n",
      "Iter-256; D_loss: [ 0.03854638]; G_loss: [ 1.72051835]\n",
      "Iter-512; D_loss: [ 0.0376025]; G_loss: [ 1.73124337]\n",
      "Iter-768; D_loss: [ 0.03661457]; G_loss: [ 1.74178374]\n",
      "Iter-1024; D_loss: [ 0.03613324]; G_loss: [ 1.75250053]\n",
      "Iter-1280; D_loss: [ 0.03557245]; G_loss: [ 1.76296735]\n",
      "Iter-1536; D_loss: [ 0.03435844]; G_loss: [ 1.77306628]\n",
      "Iter-1792; D_loss: [ 0.03376666]; G_loss: [ 1.78340316]\n",
      "Iter-2048; D_loss: [ 0.0349505]; G_loss: [ 1.79435766]\n",
      "Iter-2304; D_loss: [ 0.03302854]; G_loss: [ 1.80368519]\n",
      "Iter-2560; D_loss: [ 0.03306772]; G_loss: [ 1.81399095]\n",
      "Iter-2816; D_loss: [ 0.03119673]; G_loss: [ 1.8233062]\n",
      "Iter-3072; D_loss: [ 0.03064796]; G_loss: [ 1.83322942]\n",
      "Iter-3328; D_loss: [ 0.03007655]; G_loss: [ 1.84303677]\n",
      "Iter-3584; D_loss: [ 0.02909223]; G_loss: [ 1.85258937]\n",
      "epoch: 11\n",
      "Iter-0; D_loss: [ 0.02926257]; G_loss: [ 1.86254239]\n",
      "Iter-256; D_loss: [ 0.02861589]; G_loss: [ 1.8719368]\n",
      "Iter-512; D_loss: [ 0.02801024]; G_loss: [ 1.88133395]\n",
      "Iter-768; D_loss: [ 0.02729999]; G_loss: [ 1.89060533]\n",
      "Iter-1024; D_loss: [ 0.02701303]; G_loss: [ 1.89999783]\n",
      "Iter-1280; D_loss: [ 0.02668704]; G_loss: [ 1.90919602]\n",
      "Iter-1536; D_loss: [ 0.0258176]; G_loss: [ 1.91813719]\n",
      "Iter-1792; D_loss: [ 0.02544051]; G_loss: [ 1.92719054]\n",
      "Iter-2048; D_loss: [ 0.02656084]; G_loss: [ 1.93680227]\n",
      "Iter-2304; D_loss: [ 0.02502196]; G_loss: [ 1.94505119]\n",
      "Iter-2560; D_loss: [ 0.02516917]; G_loss: [ 1.95410597]\n",
      "Iter-2816; D_loss: [ 0.02371669]; G_loss: [ 1.96236563]\n",
      "Iter-3072; D_loss: [ 0.02335995]; G_loss: [ 1.9711175]\n",
      "Iter-3328; D_loss: [ 0.02296803]; G_loss: [ 1.97980511]\n",
      "Iter-3584; D_loss: [ 0.02226891]; G_loss: [ 1.98826683]\n",
      "epoch: 12\n",
      "Iter-0; D_loss: [ 0.02245236]; G_loss: [ 1.99706411]\n",
      "Iter-256; D_loss: [ 0.02202342]; G_loss: [ 2.00537205]\n",
      "Iter-512; D_loss: [ 0.02162041]; G_loss: [ 2.01371264]\n",
      "Iter-768; D_loss: [ 0.02108322]; G_loss: [ 2.02194285]\n",
      "Iter-1024; D_loss: [ 0.02090473]; G_loss: [ 2.03023601]\n",
      "Iter-1280; D_loss: [ 0.02071484]; G_loss: [ 2.03846216]\n",
      "Iter-1536; D_loss: [ 0.02006453]; G_loss: [ 2.04637909]\n",
      "Iter-1792; D_loss: [ 0.01981675]; G_loss: [ 2.05448055]\n",
      "Iter-2048; D_loss: [ 0.02083622]; G_loss: [ 2.06291842]\n",
      "Iter-2304; D_loss: [ 0.01957286]; G_loss: [ 2.07028055]\n",
      "Iter-2560; D_loss: [ 0.01976768]; G_loss: [ 2.07837105]\n",
      "Iter-2816; D_loss: [ 0.01860392]; G_loss: [ 2.08577371]\n",
      "Iter-3072; D_loss: [ 0.01836565]; G_loss: [ 2.09358335]\n",
      "Iter-3328; D_loss: [ 0.01808267]; G_loss: [ 2.10131907]\n",
      "Iter-3584; D_loss: [ 0.01757086]; G_loss: [ 2.10890436]\n",
      "epoch: 13\n",
      "Iter-0; D_loss: [ 0.01774386]; G_loss: [ 2.11676455]\n",
      "Iter-256; D_loss: [ 0.0174514]; G_loss: [ 2.12423897]\n",
      "Iter-512; D_loss: [ 0.01717337]; G_loss: [ 2.13167906]\n",
      "Iter-768; D_loss: [ 0.01675192]; G_loss: [ 2.13903069]\n",
      "Iter-1024; D_loss: [ 0.01663646]; G_loss: [ 2.14646053]\n",
      "Iter-1280; D_loss: [ 0.01652692]; G_loss: [ 2.15380192]\n",
      "Iter-1536; D_loss: [ 0.01602567]; G_loss: [ 2.16098046]\n",
      "Iter-1792; D_loss: [ 0.01585542]; G_loss: [ 2.16822577]\n",
      "Iter-2048; D_loss: [ 0.01677376]; G_loss: [ 2.1757822]\n",
      "Iter-2304; D_loss: [ 0.01571287]; G_loss: [ 2.18244386]\n",
      "Iter-2560; D_loss: [ 0.01592528]; G_loss: [ 2.18968177]\n",
      "Iter-2816; D_loss: [ 0.01497054]; G_loss: [ 2.19633937]\n",
      "Iter-3072; D_loss: [ 0.01480861]; G_loss: [ 2.20338702]\n",
      "Iter-3328; D_loss: [ 0.01459564]; G_loss: [ 2.21036625]\n",
      "Iter-3584; D_loss: [ 0.01421056]; G_loss: [ 2.21722031]\n",
      "epoch: 14\n",
      "Iter-0; D_loss: [ 0.01436426]; G_loss: [ 2.22424841]\n",
      "Iter-256; D_loss: [ 0.01415954]; G_loss: [ 2.23104954]\n",
      "Iter-512; D_loss: [ 0.01396314]; G_loss: [ 2.23774958]\n",
      "Iter-768; D_loss: [ 0.01362433]; G_loss: [ 2.24443722]\n",
      "Iter-1024; D_loss: [ 0.01354559]; G_loss: [ 2.25109577]\n",
      "Iter-1280; D_loss: [ 0.01348661]; G_loss: [ 2.25776601]\n",
      "Iter-1536; D_loss: [ 0.01308714]; G_loss: [ 2.26428676]\n",
      "Iter-1792; D_loss: [ 0.01296782]; G_loss: [ 2.27083778]\n",
      "Iter-2048; D_loss: [ 0.01379031]; G_loss: [ 2.27768493]\n",
      "Iter-2304; D_loss: [ 0.01288619]; G_loss: [ 2.28364992]\n",
      "Iter-2560; D_loss: [ 0.01310303]; G_loss: [ 2.29026341]\n",
      "Iter-2816; D_loss: [ 0.01230245]; G_loss: [ 2.29634404]\n",
      "Iter-3072; D_loss: [ 0.01219072]; G_loss: [ 2.30274129]\n",
      "Iter-3328; D_loss: [ 0.01202493]; G_loss: [ 2.30909538]\n",
      "Iter-3584; D_loss: [ 0.01172907]; G_loss: [ 2.31533408]\n",
      "epoch: 15\n",
      "Iter-0; D_loss: [ 0.01186301]; G_loss: [ 2.32172346]\n",
      "Iter-256; D_loss: [ 0.01171614]; G_loss: [ 2.3279016]\n",
      "Iter-512; D_loss: [ 0.01157522]; G_loss: [ 2.33401752]\n",
      "Iter-768; D_loss: [ 0.01129498]; G_loss: [ 2.34005809]\n",
      "Iter-1024; D_loss: [ 0.0112416]; G_loss: [ 2.34618711]\n",
      "Iter-1280; D_loss: [ 0.01121307]; G_loss: [ 2.35229373]\n",
      "Iter-1536; D_loss: [ 0.01088745]; G_loss: [ 2.35817432]\n",
      "Iter-1792; D_loss: [ 0.01080191]; G_loss: [ 2.36416817]\n",
      "Iter-2048; D_loss: [ 0.0115377]; G_loss: [ 2.3704288]\n",
      "Iter-2304; D_loss: [ 0.01075774]; G_loss: [ 2.3759439]\n",
      "Iter-2560; D_loss: [ 0.01096897]; G_loss: [ 2.38191915]\n",
      "Iter-2816; D_loss: [ 0.01028806]; G_loss: [ 2.38749456]\n",
      "Iter-3072; D_loss: [ 0.01021042]; G_loss: [ 2.39336395]\n",
      "Iter-3328; D_loss: [ 0.01007741]; G_loss: [ 2.39918756]\n",
      "Iter-3584; D_loss: [ 0.00984648]; G_loss: [ 2.40489864]\n",
      "epoch: 16\n",
      "Iter-0; D_loss: [ 0.00996139]; G_loss: [ 2.410743]\n",
      "Iter-256; D_loss: [ 0.00985448]; G_loss: [ 2.4164145]\n",
      "Iter-512; D_loss: [ 0.00975132]; G_loss: [ 2.42201805]\n",
      "Iter-768; D_loss: [ 0.00951593]; G_loss: [ 2.42758489]\n",
      "Iter-1024; D_loss: [ 0.00947746]; G_loss: [ 2.43316078]\n",
      "Iter-1280; D_loss: [ 0.00946985]; G_loss: [ 2.43877816]\n",
      "Iter-1536; D_loss: [ 0.00919981]; G_loss: [ 2.44424033]\n",
      "Iter-1792; D_loss: [ 0.00913619]; G_loss: [ 2.44971991]\n",
      "Iter-2048; D_loss: [ 0.00979638]; G_loss: [ 2.45539641]\n",
      "Iter-2304; D_loss: [ 0.00911628]; G_loss: [ 2.46051383]\n",
      "Iter-2560; D_loss: [ 0.00931844]; G_loss: [ 2.46601033]\n",
      "Iter-2816; D_loss: [ 0.00873124]; G_loss: [ 2.4712131]\n",
      "Iter-3072; D_loss: [ 0.00867702]; G_loss: [ 2.47659326]\n",
      "Iter-3328; D_loss: [ 0.00856756]; G_loss: [ 2.48192739]\n",
      "Iter-3584; D_loss: [ 0.00838482]; G_loss: [ 2.48724127]\n",
      "epoch: 17\n",
      "Iter-0; D_loss: [ 0.00848292]; G_loss: [ 2.49263883]\n",
      "Iter-256; D_loss: [ 0.00840405]; G_loss: [ 2.49782729]\n",
      "Iter-512; D_loss: [ 0.00832757]; G_loss: [ 2.50302696]\n",
      "Iter-768; D_loss: [ 0.0081269]; G_loss: [ 2.50815463]\n",
      "Iter-1024; D_loss: [ 0.00809905]; G_loss: [ 2.51334548]\n",
      "Iter-1280; D_loss: [ 0.00810391]; G_loss: [ 2.51850629]\n",
      "Iter-1536; D_loss: [ 0.00787682]; G_loss: [ 2.52353597]\n",
      "Iter-1792; D_loss: [ 0.00782846]; G_loss: [ 2.52863121]\n",
      "Iter-2048; D_loss: [ 0.00842292]; G_loss: [ 2.53390002]\n",
      "Iter-2304; D_loss: [ 0.00782368]; G_loss: [ 2.53863168]\n",
      "Iter-2560; D_loss: [ 0.00801544]; G_loss: [ 2.54372907]\n",
      "Iter-2816; D_loss: [ 0.0075029]; G_loss: [ 2.5485146]\n",
      "Iter-3072; D_loss: [ 0.00746646]; G_loss: [ 2.5535152]\n",
      "Iter-3328; D_loss: [ 0.00737423]; G_loss: [ 2.55849409]\n",
      "Iter-3584; D_loss: [ 0.00722734]; G_loss: [ 2.56340075]\n",
      "epoch: 18\n",
      "Iter-0; D_loss: [ 0.00731132]; G_loss: [ 2.56835389]\n",
      "Iter-256; D_loss: [ 0.00725305]; G_loss: [ 2.57324004]\n",
      "Iter-512; D_loss: [ 0.00719495]; G_loss: [ 2.57803178]\n",
      "Iter-768; D_loss: [ 0.00702238]; G_loss: [ 2.58281875]\n",
      "Iter-1024; D_loss: [ 0.00700118]; G_loss: [ 2.58760691]\n",
      "Iter-1280; D_loss: [ 0.00701463]; G_loss: [ 2.59241366]\n",
      "Iter-1536; D_loss: [ 0.00682089]; G_loss: [ 2.59709239]\n",
      "Iter-1792; D_loss: [ 0.00678355]; G_loss: [ 2.60186148]\n",
      "Iter-2048; D_loss: [ 0.00732057]; G_loss: [ 2.60667634]\n",
      "Iter-2304; D_loss: [ 0.00678892]; G_loss: [ 2.61112428]\n",
      "Iter-2560; D_loss: [ 0.0069691]; G_loss: [ 2.61589575]\n",
      "Iter-2816; D_loss: [ 0.00651745]; G_loss: [ 2.62033629]\n",
      "Iter-3072; D_loss: [ 0.00649368]; G_loss: [ 2.62498856]\n",
      "Iter-3328; D_loss: [ 0.00641493]; G_loss: [ 2.6296134]\n",
      "Iter-3584; D_loss: [ 0.00629569]; G_loss: [ 2.63419938]\n",
      "epoch: 19\n",
      "Iter-0; D_loss: [ 0.00636733]; G_loss: [ 2.63883615]\n",
      "Iter-256; D_loss: [ 0.00632364]; G_loss: [ 2.64337325]\n",
      "Iter-512; D_loss: [ 0.00627937]; G_loss: [ 2.64785099]\n",
      "Iter-768; D_loss: [ 0.00612912]; G_loss: [ 2.65231133]\n",
      "Iter-1024; D_loss: [ 0.00611301]; G_loss: [ 2.65680146]\n",
      "Iter-1280; D_loss: [ 0.00613205]; G_loss: [ 2.6612885]\n",
      "Iter-1536; D_loss: [ 0.0059647]; G_loss: [ 2.66566491]\n",
      "Iter-1792; D_loss: [ 0.00593492]; G_loss: [ 2.6700902]\n",
      "Iter-2048; D_loss: [ 0.00642257]; G_loss: [ 2.67465734]\n",
      "Iter-2304; D_loss: [ 0.0059464]; G_loss: [ 2.67874622]\n",
      "Iter-2560; D_loss: [ 0.00611593]; G_loss: [ 2.68320203]\n",
      "Iter-2816; D_loss: [ 0.00571488]; G_loss: [ 2.68737674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3072; D_loss: [ 0.00570022]; G_loss: [ 2.69173694]\n",
      "Iter-3328; D_loss: [ 0.00563192]; G_loss: [ 2.6960845]\n",
      "Iter-3584; D_loss: [ 0.00553396]; G_loss: [ 2.70036173]\n",
      "epoch: 20\n",
      "Iter-0; D_loss: [ 0.00559557]; G_loss: [ 2.70470476]\n",
      "Iter-256; D_loss: [ 0.00556289]; G_loss: [ 2.70895791]\n",
      "Iter-512; D_loss: [ 0.00552863]; G_loss: [ 2.71313524]\n",
      "Iter-768; D_loss: [ 0.00539697]; G_loss: [ 2.71733832]\n",
      "Iter-1024; D_loss: [ 0.00538412]; G_loss: [ 2.72152305]\n",
      "Iter-1280; D_loss: [ 0.00540677]; G_loss: [ 2.72572374]\n",
      "Iter-1536; D_loss: [ 0.00526098]; G_loss: [ 2.72984529]\n",
      "Iter-1792; D_loss: [ 0.00523661]; G_loss: [ 2.73399878]\n",
      "Iter-2048; D_loss: [ 0.00568078]; G_loss: [ 2.73825979]\n",
      "Iter-2304; D_loss: [ 0.00525238]; G_loss: [ 2.7421174]\n",
      "Iter-2560; D_loss: [ 0.00541104]; G_loss: [ 2.74629879]\n",
      "Iter-2816; D_loss: [ 0.00505239]; G_loss: [ 2.7502284]\n",
      "Iter-3072; D_loss: [ 0.00504457]; G_loss: [ 2.75433087]\n",
      "Iter-3328; D_loss: [ 0.00498451]; G_loss: [ 2.75838947]\n",
      "Iter-3584; D_loss: [ 0.00490368]; G_loss: [ 2.76244903]\n",
      "epoch: 21\n",
      "Iter-0; D_loss: [ 0.00495647]; G_loss: [ 2.76652122]\n",
      "Iter-256; D_loss: [ 0.00493196]; G_loss: [ 2.77049661]\n",
      "Iter-512; D_loss: [ 0.00490535]; G_loss: [ 2.77445984]\n",
      "Iter-768; D_loss: [ 0.00478913]; G_loss: [ 2.77838445]\n",
      "Iter-1024; D_loss: [ 0.00477884]; G_loss: [ 2.78234696]\n",
      "Iter-1280; D_loss: [ 0.00480342]; G_loss: [ 2.78630137]\n",
      "Iter-1536; D_loss: [ 0.00467529]; G_loss: [ 2.79015803]\n",
      "Iter-1792; D_loss: [ 0.00465525]; G_loss: [ 2.79408932]\n",
      "Iter-2048; D_loss: [ 0.00506143]; G_loss: [ 2.79806924]\n",
      "Iter-2304; D_loss: [ 0.00467355]; G_loss: [ 2.80173683]\n",
      "Iter-2560; D_loss: [ 0.00482209]; G_loss: [ 2.80565619]\n",
      "Iter-2816; D_loss: [ 0.00449942]; G_loss: [ 2.80937004]\n",
      "Iter-3072; D_loss: [ 0.00449669]; G_loss: [ 2.81324816]\n",
      "Iter-3328; D_loss: [ 0.00444324]; G_loss: [ 2.81707835]\n",
      "Iter-3584; D_loss: [ 0.00437593]; G_loss: [ 2.82089138]\n",
      "epoch: 22\n",
      "Iter-0; D_loss: [ 0.00442147]; G_loss: [ 2.82470965]\n",
      "Iter-256; D_loss: [ 0.0044034]; G_loss: [ 2.82849598]\n",
      "Iter-512; D_loss: [ 0.00438238]; G_loss: [ 2.83222342]\n",
      "Iter-768; D_loss: [ 0.00427907]; G_loss: [ 2.83594513]\n",
      "Iter-1024; D_loss: [ 0.00427056]; G_loss: [ 2.83969641]\n",
      "Iter-1280; D_loss: [ 0.00429622]; G_loss: [ 2.8434093]\n",
      "Iter-1536; D_loss: [ 0.00418283]; G_loss: [ 2.84706926]\n",
      "Iter-1792; D_loss: [ 0.00416573]; G_loss: [ 2.85075235]\n",
      "Iter-2048; D_loss: [ 0.00453872]; G_loss: [ 2.85453343]\n",
      "Iter-2304; D_loss: [ 0.00418575]; G_loss: [ 2.85802627]\n",
      "Iter-2560; D_loss: [ 0.00432488]; G_loss: [ 2.86173153]\n",
      "Iter-2816; D_loss: [ 0.00403263]; G_loss: [ 2.86522341]\n",
      "Iter-3072; D_loss: [ 0.0040338]; G_loss: [ 2.86889482]\n",
      "Iter-3328; D_loss: [ 0.00398592]; G_loss: [ 2.87250519]\n",
      "Iter-3584; D_loss: [ 0.00392964]; G_loss: [ 2.8761332]\n",
      "epoch: 23\n",
      "Iter-0; D_loss: [ 0.00396906]; G_loss: [ 2.87976623]\n",
      "Iter-256; D_loss: [ 0.00395554]; G_loss: [ 2.88332415]\n",
      "Iter-512; D_loss: [ 0.00393892]; G_loss: [ 2.88684797]\n",
      "Iter-768; D_loss: [ 0.00384666]; G_loss: [ 2.89037108]\n",
      "Iter-1024; D_loss: [ 0.00383936]; G_loss: [ 2.89392328]\n",
      "Iter-1280; D_loss: [ 0.00386573]; G_loss: [ 2.8974309]\n",
      "Iter-1536; D_loss: [ 0.00376477]; G_loss: [ 2.9009304]\n",
      "Iter-1792; D_loss: [ 0.00374981]; G_loss: [ 2.90442634]\n",
      "Iter-2048; D_loss: [ 0.00409329]; G_loss: [ 2.90800023]\n",
      "Iter-2304; D_loss: [ 0.00377076]; G_loss: [ 2.91128087]\n",
      "Iter-2560; D_loss: [ 0.00390117]; G_loss: [ 2.91481328]\n",
      "Iter-2816; D_loss: [ 0.00363543]; G_loss: [ 2.91814566]\n",
      "Iter-3072; D_loss: [ 0.00363932]; G_loss: [ 2.92161059]\n",
      "Iter-3328; D_loss: [ 0.00359621]; G_loss: [ 2.92506576]\n",
      "Iter-3584; D_loss: [ 0.0035487]; G_loss: [ 2.92848945]\n",
      "epoch: 24\n",
      "Iter-0; D_loss: [ 0.00358294]; G_loss: [ 2.9319334]\n",
      "Iter-256; D_loss: [ 0.00357312]; G_loss: [ 2.93531418]\n",
      "Iter-512; D_loss: [ 0.00355997]; G_loss: [ 2.93867397]\n",
      "Iter-768; D_loss: [ 0.00347694]; G_loss: [ 2.94199467]\n",
      "Iter-1024; D_loss: [ 0.00347076]; G_loss: [ 2.94536018]\n",
      "Iter-1280; D_loss: [ 0.00349725]; G_loss: [ 2.9487381]\n",
      "Iter-1536; D_loss: [ 0.00340662]; G_loss: [ 2.95203924]\n",
      "Iter-1792; D_loss: [ 0.0033935]; G_loss: [ 2.95536041]\n",
      "Iter-2048; D_loss: [ 0.00371081]; G_loss: [ 2.95874286]\n",
      "Iter-2304; D_loss: [ 0.00341469]; G_loss: [ 2.96188021]\n",
      "Iter-2560; D_loss: [ 0.00353729]; G_loss: [ 2.96522522]\n",
      "Iter-2816; D_loss: [ 0.00329433]; G_loss: [ 2.96839452]\n",
      "Iter-3072; D_loss: [ 0.00330036]; G_loss: [ 2.97170234]\n",
      "Iter-3328; D_loss: [ 0.00326108]; G_loss: [ 2.97497654]\n",
      "Iter-3584; D_loss: [ 0.003221]; G_loss: [ 2.97824454]\n",
      "epoch: 25\n",
      "Iter-0; D_loss: [ 0.00325075]; G_loss: [ 2.98152399]\n",
      "Iter-256; D_loss: [ 0.0032438]; G_loss: [ 2.98474574]\n",
      "Iter-512; D_loss: [ 0.00323333]; G_loss: [ 2.98794103]\n",
      "Iter-768; D_loss: [ 0.00315834]; G_loss: [ 2.99110579]\n",
      "Iter-1024; D_loss: [ 0.00315287]; G_loss: [ 2.99432158]\n",
      "Iter-1280; D_loss: [ 0.00317921]; G_loss: [ 2.99751854]\n",
      "Iter-1536; D_loss: [ 0.00309755]; G_loss: [ 3.00065827]\n",
      "Iter-1792; D_loss: [ 0.00308579]; G_loss: [ 3.00383735]\n",
      "Iter-2048; D_loss: [ 0.00337982]; G_loss: [ 3.0070827]\n",
      "Iter-2304; D_loss: [ 0.00310703]; G_loss: [ 3.01004434]\n",
      "Iter-2560; D_loss: [ 0.00322214]; G_loss: [ 3.01321912]\n",
      "Iter-2816; D_loss: [ 0.00299937]; G_loss: [ 3.01627779]\n",
      "Iter-3072; D_loss: [ 0.00300688]; G_loss: [ 3.01941895]\n",
      "Iter-3328; D_loss: [ 0.00297106]; G_loss: [ 3.02254796]\n",
      "Iter-3584; D_loss: [ 0.00293697]; G_loss: [ 3.02566767]\n",
      "epoch: 26\n",
      "Iter-0; D_loss: [ 0.00296286]; G_loss: [ 3.02875996]\n",
      "Iter-256; D_loss: [ 0.00295829]; G_loss: [ 3.03185225]\n",
      "Iter-512; D_loss: [ 0.00294988]; G_loss: [ 3.03491187]\n",
      "Iter-768; D_loss: [ 0.00288182]; G_loss: [ 3.03793812]\n",
      "Iter-1024; D_loss: [ 0.00287694]; G_loss: [ 3.04099059]\n",
      "Iter-1280; D_loss: [ 0.00290294]; G_loss: [ 3.04405165]\n",
      "Iter-1536; D_loss: [ 0.00282898]; G_loss: [ 3.0470686]\n",
      "Iter-1792; D_loss: [ 0.0028182]; G_loss: [ 3.05008006]\n",
      "Iter-2048; D_loss: [ 0.00309153]; G_loss: [ 3.05315113]\n",
      "Iter-2304; D_loss: [ 0.0028394]; G_loss: [ 3.05602431]\n",
      "Iter-2560; D_loss: [ 0.00294766]; G_loss: [ 3.05905461]\n",
      "Iter-2816; D_loss: [ 0.00274245]; G_loss: [ 3.06195545]\n",
      "Iter-3072; D_loss: [ 0.0027511]; G_loss: [ 3.06496644]\n",
      "Iter-3328; D_loss: [ 0.0027182]; G_loss: [ 3.0679512]\n",
      "Iter-3584; D_loss: [ 0.00268923]; G_loss: [ 3.07093596]\n",
      "epoch: 27\n",
      "Iter-0; D_loss: [ 0.00271177]; G_loss: [ 3.07389903]\n",
      "Iter-256; D_loss: [ 0.00270893]; G_loss: [ 3.07683825]\n",
      "Iter-512; D_loss: [ 0.00270215]; G_loss: [ 3.07976294]\n",
      "Iter-768; D_loss: [ 0.00264034]; G_loss: [ 3.08265448]\n",
      "Iter-1024; D_loss: [ 0.00263591]; G_loss: [ 3.08558941]\n",
      "Iter-1280; D_loss: [ 0.00266133]; G_loss: [ 3.08852386]\n",
      "Iter-1536; D_loss: [ 0.00259402]; G_loss: [ 3.09138131]\n",
      "Iter-1792; D_loss: [ 0.00258411]; G_loss: [ 3.09429002]\n",
      "Iter-2048; D_loss: [ 0.0028387]; G_loss: [ 3.09720564]\n",
      "Iter-2304; D_loss: [ 0.00260505]; G_loss: [ 3.09999013]\n",
      "Iter-2560; D_loss: [ 0.00270692]; G_loss: [ 3.1028707]\n",
      "Iter-2816; D_loss: [ 0.00251734]; G_loss: [ 3.10565686]\n",
      "Iter-3072; D_loss: [ 0.00252674]; G_loss: [ 3.10853028]\n",
      "Iter-3328; D_loss: [ 0.00249648]; G_loss: [ 3.11139107]\n",
      "Iter-3584; D_loss: [ 0.00247176]; G_loss: [ 3.11425352]\n",
      "epoch: 28\n",
      "Iter-0; D_loss: [ 0.00249151]; G_loss: [ 3.11709094]\n",
      "Iter-256; D_loss: [ 0.00249003]; G_loss: [ 3.11992884]\n",
      "Iter-512; D_loss: [ 0.00248447]; G_loss: [ 3.12269759]\n",
      "Iter-768; D_loss: [ 0.00242812]; G_loss: [ 3.12549829]\n",
      "Iter-1024; D_loss: [ 0.00242394]; G_loss: [ 3.1282959]\n",
      "Iter-1280; D_loss: [ 0.00244887]; G_loss: [ 3.13111567]\n",
      "Iter-1536; D_loss: [ 0.00238737]; G_loss: [ 3.13384604]\n",
      "Iter-1792; D_loss: [ 0.00237815]; G_loss: [ 3.13664412]\n",
      "Iter-2048; D_loss: [ 0.00261597]; G_loss: [ 3.13943863]\n",
      "Iter-2304; D_loss: [ 0.00239868]; G_loss: [ 3.14208651]\n",
      "Iter-2560; D_loss: [ 0.00249482]; G_loss: [ 3.14485765]\n",
      "Iter-2816; D_loss: [ 0.00231901]; G_loss: [ 3.14756107]\n",
      "Iter-3072; D_loss: [ 0.00232894]; G_loss: [ 3.15030718]\n",
      "Iter-3328; D_loss: [ 0.00230092]; G_loss: [ 3.15305471]\n",
      "Iter-3584; D_loss: [ 0.00227983]; G_loss: [ 3.15578651]\n",
      "epoch: 29\n",
      "Iter-0; D_loss: [ 0.00229718]; G_loss: [ 3.15854359]\n",
      "Iter-256; D_loss: [ 0.00229675]; G_loss: [ 3.16123223]\n",
      "Iter-512; D_loss: [ 0.00229229]; G_loss: [ 3.16389227]\n",
      "Iter-768; D_loss: [ 0.00224059]; G_loss: [ 3.16656089]\n",
      "Iter-1024; D_loss: [ 0.0022367]; G_loss: [ 3.16927886]\n",
      "Iter-1280; D_loss: [ 0.00226091]; G_loss: [ 3.1719768]\n",
      "Iter-1536; D_loss: [ 0.00220454]; G_loss: [ 3.1745975]\n",
      "Iter-1792; D_loss: [ 0.0021959]; G_loss: [ 3.17727757]\n",
      "Iter-2048; D_loss: [ 0.00241851]; G_loss: [ 3.17997217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2304; D_loss: [ 0.00221581]; G_loss: [ 3.18249226]\n",
      "Iter-2560; D_loss: [ 0.00230668]; G_loss: [ 3.18517542]\n",
      "Iter-2816; D_loss: [ 0.00214327]; G_loss: [ 3.18776941]\n",
      "Iter-3072; D_loss: [ 0.00215358]; G_loss: [ 3.19040537]\n",
      "Iter-3328; D_loss: [ 0.00212754]; G_loss: [ 3.19306445]\n",
      "Iter-3584; D_loss: [ 0.00210939]; G_loss: [ 3.19565797]\n",
      "epoch: 30\n",
      "Iter-0; D_loss: [ 0.00212468]; G_loss: [ 3.19829512]\n",
      "Iter-256; D_loss: [ 0.00212511]; G_loss: [ 3.20090532]\n",
      "Iter-512; D_loss: [ 0.00212151]; G_loss: [ 3.20347786]\n",
      "Iter-768; D_loss: [ 0.00207399]; G_loss: [ 3.20606184]\n",
      "Iter-1024; D_loss: [ 0.00207034]; G_loss: [ 3.20864105]\n",
      "Iter-1280; D_loss: [ 0.00209392]; G_loss: [ 3.21122313]\n",
      "Iter-1536; D_loss: [ 0.00204203]; G_loss: [ 3.21376944]\n",
      "Iter-1792; D_loss: [ 0.00203379]; G_loss: [ 3.21633029]\n",
      "Iter-2048; D_loss: [ 0.00224265]; G_loss: [ 3.2189374]\n",
      "Iter-2304; D_loss: [ 0.00205325]; G_loss: [ 3.22135639]\n",
      "Iter-2560; D_loss: [ 0.00213919]; G_loss: [ 3.22394586]\n",
      "Iter-2816; D_loss: [ 0.00198687]; G_loss: [ 3.22644973]\n",
      "Iter-3072; D_loss: [ 0.00199735]; G_loss: [ 3.22896576]\n",
      "Iter-3328; D_loss: [ 0.0019731]; G_loss: [ 3.23152018]\n",
      "Iter-3584; D_loss: [ 0.00195763]; G_loss: [ 3.23406434]\n",
      "epoch: 31\n",
      "Iter-0; D_loss: [ 0.00197098]; G_loss: [ 3.23657823]\n",
      "Iter-256; D_loss: [ 0.00197219]; G_loss: [ 3.23909712]\n",
      "Iter-512; D_loss: [ 0.00196923]; G_loss: [ 3.2415607]\n",
      "Iter-768; D_loss: [ 0.0019254]; G_loss: [ 3.24403214]\n",
      "Iter-1024; D_loss: [ 0.00192195]; G_loss: [ 3.24653292]\n",
      "Iter-1280; D_loss: [ 0.00194476]; G_loss: [ 3.24903226]\n",
      "Iter-1536; D_loss: [ 0.00189686]; G_loss: [ 3.25147605]\n",
      "Iter-1792; D_loss: [ 0.00188901]; G_loss: [ 3.25393224]\n",
      "Iter-2048; D_loss: [ 0.00208538]; G_loss: [ 3.25645304]\n",
      "Iter-2304; D_loss: [ 0.00190794]; G_loss: [ 3.258811]\n",
      "Iter-2560; D_loss: [ 0.00198928]; G_loss: [ 3.26129532]\n",
      "Iter-2816; D_loss: [ 0.00184694]; G_loss: [ 3.26367354]\n",
      "Iter-3072; D_loss: [ 0.00185759]; G_loss: [ 3.26612616]\n",
      "Iter-3328; D_loss: [ 0.0018349]; G_loss: [ 3.26857305]\n",
      "Iter-3584; D_loss: [ 0.00182165]; G_loss: [ 3.27104259]\n",
      "epoch: 32\n",
      "Iter-0; D_loss: [ 0.00183335]; G_loss: [ 3.27346277]\n",
      "Iter-256; D_loss: [ 0.00183508]; G_loss: [ 3.27587628]\n",
      "Iter-512; D_loss: [ 0.00183274]; G_loss: [ 3.2782743]\n",
      "Iter-768; D_loss: [ 0.0017922]; G_loss: [ 3.28065395]\n",
      "Iter-1024; D_loss: [ 0.0017889]; G_loss: [ 3.283077]\n",
      "Iter-1280; D_loss: [ 0.00181101]; G_loss: [ 3.2854712]\n",
      "Iter-1536; D_loss: [ 0.0017667]; G_loss: [ 3.28783703]\n",
      "Iter-1792; D_loss: [ 0.00175916]; G_loss: [ 3.29021835]\n",
      "Iter-2048; D_loss: [ 0.00194407]; G_loss: [ 3.29262733]\n",
      "Iter-2304; D_loss: [ 0.00177754]; G_loss: [ 3.29491282]\n",
      "Iter-2560; D_loss: [ 0.00185464]; G_loss: [ 3.29729652]\n",
      "Iter-2816; D_loss: [ 0.00172134]; G_loss: [ 3.29959655]\n",
      "Iter-3072; D_loss: [ 0.00173201]; G_loss: [ 3.30199456]\n",
      "Iter-3328; D_loss: [ 0.00171072]; G_loss: [ 3.30432868]\n",
      "Iter-3584; D_loss: [ 0.00169944]; G_loss: [ 3.30669355]\n",
      "epoch: 33\n",
      "Iter-0; D_loss: [ 0.00170975]; G_loss: [ 3.30907488]\n",
      "Iter-256; D_loss: [ 0.00171188]; G_loss: [ 3.31139827]\n",
      "Iter-512; D_loss: [ 0.00170993]; G_loss: [ 3.31366825]\n",
      "Iter-768; D_loss: [ 0.00167242]; G_loss: [ 3.31600976]\n",
      "Iter-1024; D_loss: [ 0.00166921]; G_loss: [ 3.31830573]\n",
      "Iter-1280; D_loss: [ 0.00169067]; G_loss: [ 3.32066393]\n",
      "Iter-1536; D_loss: [ 0.00164949]; G_loss: [ 3.3229239]\n",
      "Iter-1792; D_loss: [ 0.00164225]; G_loss: [ 3.32524061]\n",
      "Iter-2048; D_loss: [ 0.00181669]; G_loss: [ 3.32754374]\n",
      "Iter-2304; D_loss: [ 0.00166004]; G_loss: [ 3.32976747]\n",
      "Iter-2560; D_loss: [ 0.00173323]; G_loss: [ 3.33207011]\n",
      "Iter-2816; D_loss: [ 0.00160817]; G_loss: [ 3.33431482]\n",
      "Iter-3072; D_loss: [ 0.00161873]; G_loss: [ 3.33659506]\n",
      "Iter-3328; D_loss: [ 0.00159878]; G_loss: [ 3.33889389]\n",
      "Iter-3584; D_loss: [ 0.00158912]; G_loss: [ 3.34116483]\n",
      "epoch: 34\n",
      "Iter-0; D_loss: [ 0.00159819]; G_loss: [ 3.34344697]\n",
      "Iter-256; D_loss: [ 0.00160062]; G_loss: [ 3.3456893]\n",
      "Iter-512; D_loss: [ 0.00159908]; G_loss: [ 3.34793353]\n",
      "Iter-768; D_loss: [ 0.00156421]; G_loss: [ 3.35017943]\n",
      "Iter-1024; D_loss: [ 0.00156114]; G_loss: [ 3.35239506]\n",
      "Iter-1280; D_loss: [ 0.00158192]; G_loss: [ 3.35465312]\n",
      "Iter-1536; D_loss: [ 0.00154359]; G_loss: [ 3.35685945]\n",
      "Iter-1792; D_loss: [ 0.00153656]; G_loss: [ 3.35910368]\n",
      "Iter-2048; D_loss: [ 0.00170143]; G_loss: [ 3.3613236]\n",
      "Iter-2304; D_loss: [ 0.00155384]; G_loss: [ 3.3634665]\n",
      "Iter-2560; D_loss: [ 0.00162337]; G_loss: [ 3.36569118]\n",
      "Iter-2816; D_loss: [ 0.00150578]; G_loss: [ 3.36787295]\n",
      "Iter-3072; D_loss: [ 0.00151626]; G_loss: [ 3.37009501]\n",
      "Iter-3328; D_loss: [ 0.00149744]; G_loss: [ 3.37228751]\n",
      "Iter-3584; D_loss: [ 0.00148926]; G_loss: [ 3.37448525]\n",
      "epoch: 35\n",
      "Iter-0; D_loss: [ 0.00149718]; G_loss: [ 3.37668824]\n",
      "Iter-256; D_loss: [ 0.00149995]; G_loss: [ 3.37888646]\n",
      "Iter-512; D_loss: [ 0.00149866]; G_loss: [ 3.3810401]\n",
      "Iter-768; D_loss: [ 0.0014662]; G_loss: [ 3.38321018]\n",
      "Iter-1024; D_loss: [ 0.00146323]; G_loss: [ 3.38536358]\n",
      "Iter-1280; D_loss: [ 0.00148331]; G_loss: [ 3.38755035]\n",
      "Iter-1536; D_loss: [ 0.00144757]; G_loss: [ 3.38971758]\n",
      "Iter-1792; D_loss: [ 0.00144073]; G_loss: [ 3.39186692]\n",
      "Iter-2048; D_loss: [ 0.00159684]; G_loss: [ 3.39402604]\n",
      "Iter-2304; D_loss: [ 0.00145746]; G_loss: [ 3.39609361]\n",
      "Iter-2560; D_loss: [ 0.00152359]; G_loss: [ 3.39826226]\n",
      "Iter-2816; D_loss: [ 0.00141284]; G_loss: [ 3.40035057]\n",
      "Iter-3072; D_loss: [ 0.00142318]; G_loss: [ 3.40250111]\n",
      "Iter-3328; D_loss: [ 0.00140545]; G_loss: [ 3.40463686]\n",
      "Iter-3584; D_loss: [ 0.00139851]; G_loss: [ 3.40677142]\n",
      "epoch: 36\n",
      "Iter-0; D_loss: [ 0.00140545]; G_loss: [ 3.40891504]\n",
      "Iter-256; D_loss: [ 0.00140839]; G_loss: [ 3.41103745]\n",
      "Iter-512; D_loss: [ 0.00140735]; G_loss: [ 3.41311908]\n",
      "Iter-768; D_loss: [ 0.00137711]; G_loss: [ 3.41522837]\n",
      "Iter-1024; D_loss: [ 0.00137421]; G_loss: [ 3.41731453]\n",
      "Iter-1280; D_loss: [ 0.00139367]; G_loss: [ 3.4194243]\n",
      "Iter-1536; D_loss: [ 0.00136022]; G_loss: [ 3.42151237]\n",
      "Iter-1792; D_loss: [ 0.00135358]; G_loss: [ 3.42359853]\n",
      "Iter-2048; D_loss: [ 0.00150162]; G_loss: [ 3.42570782]\n",
      "Iter-2304; D_loss: [ 0.00136974]; G_loss: [ 3.42770052]\n",
      "Iter-2560; D_loss: [ 0.00143278]; G_loss: [ 3.42981029]\n",
      "Iter-2816; D_loss: [ 0.00132824]; G_loss: [ 3.43183899]\n",
      "Iter-3072; D_loss: [ 0.00133841]; G_loss: [ 3.43392038]\n",
      "Iter-3328; D_loss: [ 0.00132168]; G_loss: [ 3.43600225]\n",
      "Iter-3584; D_loss: [ 0.0013158]; G_loss: [ 3.43806338]\n",
      "epoch: 37\n",
      "Iter-0; D_loss: [ 0.00132186]; G_loss: [ 3.44014335]\n",
      "Iter-256; D_loss: [ 0.00132497]; G_loss: [ 3.44220567]\n",
      "Iter-512; D_loss: [ 0.00132413]; G_loss: [ 3.44423628]\n",
      "Iter-768; D_loss: [ 0.00129588]; G_loss: [ 3.4462533]\n",
      "Iter-1024; D_loss: [ 0.00129307]; G_loss: [ 3.44830036]\n",
      "Iter-1280; D_loss: [ 0.00131186]; G_loss: [ 3.45034099]\n",
      "Iter-1536; D_loss: [ 0.00128054]; G_loss: [ 3.4523561]\n",
      "Iter-1792; D_loss: [ 0.00127406]; G_loss: [ 3.45440269]\n",
      "Iter-2048; D_loss: [ 0.0014146]; G_loss: [ 3.45642853]\n",
      "Iter-2304; D_loss: [ 0.00128975]; G_loss: [ 3.45839]\n",
      "Iter-2560; D_loss: [ 0.00134978]; G_loss: [ 3.46042562]\n",
      "Iter-2816; D_loss: [ 0.00125098]; G_loss: [ 3.46236253]\n",
      "Iter-3072; D_loss: [ 0.00126103]; G_loss: [ 3.4644177]\n",
      "Iter-3328; D_loss: [ 0.00124516]; G_loss: [ 3.46643496]\n",
      "Iter-3584; D_loss: [ 0.00124026]; G_loss: [ 3.46844959]\n",
      "epoch: 38\n",
      "Iter-0; D_loss: [ 0.00124552]; G_loss: [ 3.47045565]\n",
      "Iter-256; D_loss: [ 0.00124878]; G_loss: [ 3.47242546]\n",
      "Iter-512; D_loss: [ 0.0012481]; G_loss: [ 3.47442675]\n",
      "Iter-768; D_loss: [ 0.00122163]; G_loss: [ 3.47638392]\n",
      "Iter-1024; D_loss: [ 0.00121892]; G_loss: [ 3.47838116]\n",
      "Iter-1280; D_loss: [ 0.00123706]; G_loss: [ 3.48036289]\n",
      "Iter-1536; D_loss: [ 0.00120767]; G_loss: [ 3.48230696]\n",
      "Iter-1792; D_loss: [ 0.00120134]; G_loss: [ 3.484272]\n",
      "Iter-2048; D_loss: [ 0.00133497]; G_loss: [ 3.48626375]\n",
      "Iter-2304; D_loss: [ 0.00121652]; G_loss: [ 3.48816657]\n",
      "Iter-2560; D_loss: [ 0.00127381]; G_loss: [ 3.49015212]\n",
      "Iter-2816; D_loss: [ 0.00118028]; G_loss: [ 3.49205947]\n",
      "Iter-3072; D_loss: [ 0.00119012]; G_loss: [ 3.49402142]\n",
      "Iter-3328; D_loss: [ 0.00117508]; G_loss: [ 3.49597645]\n",
      "Iter-3584; D_loss: [ 0.00117099]; G_loss: [ 3.49792767]\n",
      "epoch: 39\n",
      "Iter-0; D_loss: [ 0.00117556]; G_loss: [ 3.49988365]\n",
      "Iter-256; D_loss: [ 0.0011789]; G_loss: [ 3.50182104]\n",
      "Iter-512; D_loss: [ 0.00117836]; G_loss: [ 3.50373435]\n",
      "Iter-768; D_loss: [ 0.00115357]; G_loss: [ 3.50566339]\n",
      "Iter-1024; D_loss: [ 0.00115089]; G_loss: [ 3.50757909]\n",
      "Iter-1280; D_loss: [ 0.00116844]; G_loss: [ 3.50951433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1536; D_loss: [ 0.00114083]; G_loss: [ 3.51141191]\n",
      "Iter-1792; D_loss: [ 0.00113462]; G_loss: [ 3.51334572]\n",
      "Iter-2048; D_loss: [ 0.00126183]; G_loss: [ 3.51525784]\n",
      "Iter-2304; D_loss: [ 0.00114933]; G_loss: [ 3.51709914]\n",
      "Iter-2560; D_loss: [ 0.00120405]; G_loss: [ 3.5190165]\n",
      "Iter-2816; D_loss: [ 0.00111539]; G_loss: [ 3.52087021]\n",
      "Iter-3072; D_loss: [ 0.00112501]; G_loss: [ 3.52281404]\n",
      "Iter-3328; D_loss: [ 0.00111071]; G_loss: [ 3.52471375]\n",
      "Iter-3584; D_loss: [ 0.00110737]; G_loss: [ 3.52660465]\n",
      "epoch: 40\n",
      "Iter-0; D_loss: [ 0.00111131]; G_loss: [ 3.52849913]\n",
      "Iter-256; D_loss: [ 0.00111474]; G_loss: [ 3.53039312]\n",
      "Iter-512; D_loss: [ 0.00111428]; G_loss: [ 3.53224468]\n",
      "Iter-768; D_loss: [ 0.001091]; G_loss: [ 3.53411555]\n",
      "Iter-1024; D_loss: [ 0.0010884]; G_loss: [ 3.53599834]\n",
      "Iter-1280; D_loss: [ 0.00110537]; G_loss: [ 3.53784847]\n",
      "Iter-1536; D_loss: [ 0.00107937]; G_loss: [ 3.53972745]\n",
      "Iter-1792; D_loss: [ 0.00107325]; G_loss: [ 3.54159784]\n",
      "Iter-2048; D_loss: [ 0.00119451]; G_loss: [ 3.54345131]\n",
      "Iter-2304; D_loss: [ 0.00108752]; G_loss: [ 3.54524422]\n",
      "Iter-2560; D_loss: [ 0.00113983]; G_loss: [ 3.54710269]\n",
      "Iter-2816; D_loss: [ 0.00105568]; G_loss: [ 3.54893756]\n",
      "Iter-3072; D_loss: [ 0.00106508]; G_loss: [ 3.55079055]\n",
      "Iter-3328; D_loss: [ 0.00105149]; G_loss: [ 3.55266166]\n",
      "Iter-3584; D_loss: [ 0.00104878]; G_loss: [ 3.55450368]\n",
      "epoch: 41\n",
      "Iter-0; D_loss: [ 0.00105218]; G_loss: [ 3.55637002]\n",
      "Iter-256; D_loss: [ 0.00105564]; G_loss: [ 3.55817533]\n",
      "Iter-512; D_loss: [ 0.00105529]; G_loss: [ 3.55999684]\n",
      "Iter-768; D_loss: [ 0.00103337]; G_loss: [ 3.56181455]\n",
      "Iter-1024; D_loss: [ 0.00103084]; G_loss: [ 3.56364536]\n",
      "Iter-1280; D_loss: [ 0.00104723]; G_loss: [ 3.56547332]\n",
      "Iter-1536; D_loss: [ 0.00102271]; G_loss: [ 3.56726313]\n",
      "Iter-1792; D_loss: [ 0.00101674]; G_loss: [ 3.56908894]\n",
      "Iter-2048; D_loss: [ 0.00113242]; G_loss: [ 3.57090926]\n",
      "Iter-2304; D_loss: [ 0.00103053]; G_loss: [ 3.57264256]\n",
      "Iter-2560; D_loss: [ 0.00108062]; G_loss: [ 3.57448268]\n",
      "Iter-2816; D_loss: [ 0.00100061]; G_loss: [ 3.57625937]\n",
      "Iter-3072; D_loss: [ 0.00100979]; G_loss: [ 3.57806349]\n",
      "Iter-3328; D_loss: [ 0.00099685]; G_loss: [ 3.57987738]\n",
      "Iter-3584; D_loss: [ 0.0009947]; G_loss: [ 3.5816617]\n",
      "epoch: 42\n",
      "Iter-0; D_loss: [ 0.00099761]; G_loss: [ 3.5834794]\n",
      "Iter-256; D_loss: [ 0.00100108]; G_loss: [ 3.58525395]\n",
      "Iter-512; D_loss: [ 0.0010008]; G_loss: [ 3.58702564]\n",
      "Iter-768; D_loss: [ 0.00098017]; G_loss: [ 3.58879161]\n",
      "Iter-1024; D_loss: [ 0.00097768]; G_loss: [ 3.5905602]\n",
      "Iter-1280; D_loss: [ 0.00099355]; G_loss: [ 3.59235001]\n",
      "Iter-1536; D_loss: [ 0.00097037]; G_loss: [ 3.59411263]\n",
      "Iter-1792; D_loss: [ 0.00096451]; G_loss: [ 3.59587836]\n",
      "Iter-2048; D_loss: [ 0.00107503]; G_loss: [ 3.59764671]\n",
      "Iter-2304; D_loss: [ 0.00097788]; G_loss: [ 3.59935379]\n",
      "Iter-2560; D_loss: [ 0.00102584]; G_loss: [ 3.60114312]\n",
      "Iter-2816; D_loss: [ 0.00094971]; G_loss: [ 3.60286975]\n",
      "Iter-3072; D_loss: [ 0.00095866]; G_loss: [ 3.60461211]\n",
      "Iter-3328; D_loss: [ 0.00094633]; G_loss: [ 3.60640693]\n",
      "Iter-3584; D_loss: [ 0.00094466]; G_loss: [ 3.60813355]\n",
      "epoch: 43\n",
      "Iter-0; D_loss: [ 0.00094713]; G_loss: [ 3.60990429]\n",
      "Iter-256; D_loss: [ 0.0009506]; G_loss: [ 3.6116302]\n",
      "Iter-512; D_loss: [ 0.0009504]; G_loss: [ 3.61334395]\n",
      "Iter-768; D_loss: [ 0.00093094]; G_loss: [ 3.61509299]\n",
      "Iter-1024; D_loss: [ 0.00092849]; G_loss: [ 3.61681294]\n",
      "Iter-1280; D_loss: [ 0.00094383]; G_loss: [ 3.61856318]\n",
      "Iter-1536; D_loss: [ 0.00092195]; G_loss: [ 3.62027764]\n",
      "Iter-1792; D_loss: [ 0.00091617]; G_loss: [ 3.62199807]\n",
      "Iter-2048; D_loss: [ 0.00102186]; G_loss: [ 3.62373185]\n",
      "Iter-2304; D_loss: [ 0.00092914]; G_loss: [ 3.6254046]\n",
      "Iter-2560; D_loss: [ 0.00097511]; G_loss: [ 3.62713981]\n",
      "Iter-2816; D_loss: [ 0.00090258]; G_loss: [ 3.62881589]\n",
      "Iter-3072; D_loss: [ 0.00091131]; G_loss: [ 3.63053179]\n",
      "Iter-3328; D_loss: [ 0.00089951]; G_loss: [ 3.63224864]\n",
      "Iter-3584; D_loss: [ 0.00089831]; G_loss: [ 3.63396001]\n",
      "epoch: 44\n",
      "Iter-0; D_loss: [ 0.00090037]; G_loss: [ 3.63566804]\n",
      "Iter-256; D_loss: [ 0.00090385]; G_loss: [ 3.63736939]\n",
      "Iter-512; D_loss: [ 0.00090368]; G_loss: [ 3.63906479]\n",
      "Iter-768; D_loss: [ 0.00088529]; G_loss: [ 3.64073205]\n",
      "Iter-1024; D_loss: [ 0.00088291]; G_loss: [ 3.64242864]\n",
      "Iter-1280; D_loss: [ 0.00089774]; G_loss: [ 3.64412832]\n",
      "Iter-1536; D_loss: [ 0.00087702]; G_loss: [ 3.6457963]\n",
      "Iter-1792; D_loss: [ 0.00087133]; G_loss: [ 3.64749026]\n",
      "Iter-2048; D_loss: [ 0.00097251]; G_loss: [ 3.64917493]\n",
      "Iter-2304; D_loss: [ 0.00088391]; G_loss: [ 3.65079594]\n",
      "Iter-2560; D_loss: [ 0.000928]; G_loss: [ 3.6524713]\n",
      "Iter-2816; D_loss: [ 0.00085886]; G_loss: [ 3.65413785]\n",
      "Iter-3072; D_loss: [ 0.00086735]; G_loss: [ 3.65580845]\n",
      "Iter-3328; D_loss: [ 0.00085608]; G_loss: [ 3.65749645]\n",
      "Iter-3584; D_loss: [ 0.00085526]; G_loss: [ 3.65915084]\n",
      "epoch: 45\n",
      "Iter-0; D_loss: [ 0.00085695]; G_loss: [ 3.6608429]\n",
      "Iter-256; D_loss: [ 0.00086041]; G_loss: [ 3.66246128]\n",
      "Iter-512; D_loss: [ 0.0008603]; G_loss: [ 3.66411209]\n",
      "Iter-768; D_loss: [ 0.0008429]; G_loss: [ 3.66578197]\n",
      "Iter-1024; D_loss: [ 0.00084056]; G_loss: [ 3.66743517]\n",
      "Iter-1280; D_loss: [ 0.00085491]; G_loss: [ 3.66909075]\n",
      "Iter-1536; D_loss: [ 0.00083526]; G_loss: [ 3.67069554]\n",
      "Iter-1792; D_loss: [ 0.00082969]; G_loss: [ 3.67234421]\n",
      "Iter-2048; D_loss: [ 0.00092663]; G_loss: [ 3.67402291]\n",
      "Iter-2304; D_loss: [ 0.00084187]; G_loss: [ 3.67558551]\n",
      "Iter-2560; D_loss: [ 0.00088422]; G_loss: [ 3.67724061]\n",
      "Iter-2816; D_loss: [ 0.00081818]; G_loss: [ 3.67884493]\n",
      "Iter-3072; D_loss: [ 0.00082646]; G_loss: [ 3.68049669]\n",
      "Iter-3328; D_loss: [ 0.00081567]; G_loss: [ 3.68213964]\n",
      "Iter-3584; D_loss: [ 0.00081521]; G_loss: [ 3.68375754]\n",
      "epoch: 46\n",
      "Iter-0; D_loss: [ 0.00081659]; G_loss: [ 3.6853919]\n",
      "Iter-256; D_loss: [ 0.00082002]; G_loss: [ 3.68702602]\n",
      "Iter-512; D_loss: [ 0.00081991]; G_loss: [ 3.68861628]\n",
      "Iter-768; D_loss: [ 0.00080346]; G_loss: [ 3.69022083]\n",
      "Iter-1024; D_loss: [ 0.00080116]; G_loss: [ 3.69184494]\n",
      "Iter-1280; D_loss: [ 0.00081505]; G_loss: [ 3.69345188]\n",
      "Iter-1536; D_loss: [ 0.00079642]; G_loss: [ 3.6950438]\n",
      "Iter-1792; D_loss: [ 0.00079091]; G_loss: [ 3.69667363]\n",
      "Iter-2048; D_loss: [ 0.00088387]; G_loss: [ 3.69829631]\n",
      "Iter-2304; D_loss: [ 0.00080272]; G_loss: [ 3.69985533]\n",
      "Iter-2560; D_loss: [ 0.00084338]; G_loss: [ 3.70146799]\n",
      "Iter-2816; D_loss: [ 0.00078025]; G_loss: [ 3.70306873]\n",
      "Iter-3072; D_loss: [ 0.0007883]; G_loss: [ 3.70467496]\n",
      "Iter-3328; D_loss: [ 0.00077795]; G_loss: [ 3.70630503]\n",
      "Iter-3584; D_loss: [ 0.00077777]; G_loss: [ 3.7079072]\n",
      "epoch: 47\n",
      "Iter-0; D_loss: [ 0.00077884]; G_loss: [ 3.70950031]\n",
      "Iter-256; D_loss: [ 0.00078223]; G_loss: [ 3.71109891]\n",
      "Iter-512; D_loss: [ 0.00078213]; G_loss: [ 3.71267438]\n",
      "Iter-768; D_loss: [ 0.00076653]; G_loss: [ 3.71426582]\n",
      "Iter-1024; D_loss: [ 0.00076424]; G_loss: [ 3.71585703]\n",
      "Iter-1280; D_loss: [ 0.00077769]; G_loss: [ 3.717448]\n",
      "Iter-1536; D_loss: [ 0.00075998]; G_loss: [ 3.71902895]\n",
      "Iter-1792; D_loss: [ 0.00075452]; G_loss: [ 3.72060132]\n",
      "Iter-2048; D_loss: [ 0.00084375]; G_loss: [ 3.72221661]\n",
      "Iter-2304; D_loss: [ 0.00076598]; G_loss: [ 3.72372246]\n",
      "Iter-2560; D_loss: [ 0.00080509]; G_loss: [ 3.72532344]\n",
      "Iter-2816; D_loss: [ 0.0007447]; G_loss: [ 3.72687244]\n",
      "Iter-3072; D_loss: [ 0.00075254]; G_loss: [ 3.72845888]\n",
      "Iter-3328; D_loss: [ 0.00074261]; G_loss: [ 3.73004365]\n",
      "Iter-3584; D_loss: [ 0.0007427]; G_loss: [ 3.73159027]\n",
      "epoch: 48\n",
      "Iter-0; D_loss: [ 0.00074352]; G_loss: [ 3.73317456]\n",
      "Iter-256; D_loss: [ 0.00074688]; G_loss: [ 3.73472023]\n",
      "Iter-512; D_loss: [ 0.0007468]; G_loss: [ 3.7362864]\n",
      "Iter-768; D_loss: [ 0.00073198]; G_loss: [ 3.73782229]\n",
      "Iter-1024; D_loss: [ 0.00072975]; G_loss: [ 3.739393]\n",
      "Iter-1280; D_loss: [ 0.00074277]; G_loss: [ 3.74094033]\n",
      "Iter-1536; D_loss: [ 0.00072593]; G_loss: [ 3.74249339]\n",
      "Iter-1792; D_loss: [ 0.00072056]; G_loss: [ 3.74403358]\n",
      "Iter-2048; D_loss: [ 0.00080627]; G_loss: [ 3.74558663]\n",
      "Iter-2304; D_loss: [ 0.00073169]; G_loss: [ 3.74708986]\n",
      "Iter-2560; D_loss: [ 0.0007693]; G_loss: [ 3.74863434]\n",
      "Iter-2816; D_loss: [ 0.00071149]; G_loss: [ 3.750139]\n",
      "Iter-3072; D_loss: [ 0.00071913]; G_loss: [ 3.75170922]\n",
      "Iter-3328; D_loss: [ 0.00070958]; G_loss: [ 3.75323892]\n",
      "Iter-3584; D_loss: [ 0.00070993]; G_loss: [ 3.75477886]\n",
      "epoch: 49\n",
      "Iter-0; D_loss: [ 0.00071051]; G_loss: [ 3.75631571]\n",
      "Iter-256; D_loss: [ 0.00071383]; G_loss: [ 3.75783491]\n",
      "Iter-512; D_loss: [ 0.00071376]; G_loss: [ 3.75935841]\n",
      "Iter-768; D_loss: [ 0.00069969]; G_loss: [ 3.76087594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1024; D_loss: [ 0.0006975]; G_loss: [ 3.76239991]\n",
      "Iter-1280; D_loss: [ 0.00071013]; G_loss: [ 3.76392245]\n",
      "Iter-1536; D_loss: [ 0.00069411]; G_loss: [ 3.76543927]\n",
      "Iter-1792; D_loss: [ 0.0006888]; G_loss: [ 3.76693058]\n",
      "Iter-2048; D_loss: [ 0.00077121]; G_loss: [ 3.76846981]\n",
      "Iter-2304; D_loss: [ 0.00069961]; G_loss: [ 3.76991963]\n",
      "Iter-2560; D_loss: [ 0.00073584]; G_loss: [ 3.77144432]\n",
      "Iter-2816; D_loss: [ 0.00068044]; G_loss: [ 3.77291369]\n",
      "Iter-3072; D_loss: [ 0.00068787]; G_loss: [ 3.77443027]\n",
      "Iter-3328; D_loss: [ 0.0006787]; G_loss: [ 3.77595448]\n",
      "Iter-3584; D_loss: [ 0.00067925]; G_loss: [ 3.77746201]\n",
      "epoch: 50\n",
      "Iter-0; D_loss: [ 0.00067963]; G_loss: [ 3.77895713]\n",
      "Iter-256; D_loss: [ 0.0006829]; G_loss: [ 3.78045988]\n",
      "Iter-512; D_loss: [ 0.00068285]; G_loss: [ 3.78193784]\n",
      "Iter-768; D_loss: [ 0.00066946]; G_loss: [ 3.7834096]\n",
      "Iter-1024; D_loss: [ 0.00066733]; G_loss: [ 3.78490973]\n",
      "Iter-1280; D_loss: [ 0.00067957]; G_loss: [ 3.78639412]\n",
      "Iter-1536; D_loss: [ 0.0006643]; G_loss: [ 3.7878685]\n",
      "Iter-1792; D_loss: [ 0.00065908]; G_loss: [ 3.78937101]\n",
      "Iter-2048; D_loss: [ 0.00073836]; G_loss: [ 3.790833]\n",
      "Iter-2304; D_loss: [ 0.00066958]; G_loss: [ 3.79226446]\n",
      "Iter-2560; D_loss: [ 0.00070448]; G_loss: [ 3.79377985]\n",
      "Iter-2816; D_loss: [ 0.00065134]; G_loss: [ 3.79523063]\n",
      "Iter-3072; D_loss: [ 0.00065859]; G_loss: [ 3.79670191]\n",
      "Iter-3328; D_loss: [ 0.00064976]; G_loss: [ 3.7981782]\n",
      "Iter-3584; D_loss: [ 0.00065051]; G_loss: [ 3.79964304]\n",
      "epoch: 51\n",
      "Iter-0; D_loss: [ 0.00065069]; G_loss: [ 3.80114317]\n",
      "Iter-256; D_loss: [ 0.00065393]; G_loss: [ 3.80257916]\n",
      "Iter-512; D_loss: [ 0.00065389]; G_loss: [ 3.80403113]\n",
      "Iter-768; D_loss: [ 0.00064115]; G_loss: [ 3.80549145]\n",
      "Iter-1024; D_loss: [ 0.00063904]; G_loss: [ 3.806952]\n",
      "Iter-1280; D_loss: [ 0.0006509]; G_loss: [ 3.80840921]\n",
      "Iter-1536; D_loss: [ 0.00063636]; G_loss: [ 3.8098712]\n",
      "Iter-1792; D_loss: [ 0.0006312]; G_loss: [ 3.8112998]\n",
      "Iter-2048; D_loss: [ 0.00070755]; G_loss: [ 3.81277633]\n",
      "Iter-2304; D_loss: [ 0.00064142]; G_loss: [ 3.81416368]\n",
      "Iter-2560; D_loss: [ 0.00067505]; G_loss: [ 3.8155973]\n",
      "Iter-2816; D_loss: [ 0.00062406]; G_loss: [ 3.81706738]\n",
      "Iter-3072; D_loss: [ 0.00063111]; G_loss: [ 3.81850052]\n",
      "Iter-3328; D_loss: [ 0.0006226]; G_loss: [ 3.81995654]\n",
      "Iter-3584; D_loss: [ 0.00062353]; G_loss: [ 3.82140398]\n",
      "epoch: 52\n",
      "Iter-0; D_loss: [ 0.00062355]; G_loss: [ 3.82283568]\n",
      "Iter-256; D_loss: [ 0.00062673]; G_loss: [ 3.82428598]\n",
      "Iter-512; D_loss: [ 0.00062667]; G_loss: [ 3.82569385]\n",
      "Iter-768; D_loss: [ 0.00061455]; G_loss: [ 3.82713675]\n",
      "Iter-1024; D_loss: [ 0.00061249]; G_loss: [ 3.82855511]\n",
      "Iter-1280; D_loss: [ 0.00062401]; G_loss: [ 3.82997036]\n",
      "Iter-1536; D_loss: [ 0.00061012]; G_loss: [ 3.83141088]\n",
      "Iter-1792; D_loss: [ 0.00060503]; G_loss: [ 3.83282733]\n",
      "Iter-2048; D_loss: [ 0.00067858]; G_loss: [ 3.83422399]\n",
      "Iter-2304; D_loss: [ 0.00061498]; G_loss: [ 3.83562899]\n",
      "Iter-2560; D_loss: [ 0.00064742]; G_loss: [ 3.83705878]\n",
      "Iter-2816; D_loss: [ 0.00059841]; G_loss: [ 3.83844209]\n",
      "Iter-3072; D_loss: [ 0.0006053]; G_loss: [ 3.83986402]\n",
      "Iter-3328; D_loss: [ 0.00059709]; G_loss: [ 3.84130001]\n",
      "Iter-3584; D_loss: [ 0.00059818]; G_loss: [ 3.84271479]\n",
      "epoch: 53\n",
      "Iter-0; D_loss: [ 0.00059804]; G_loss: [ 3.84412169]\n",
      "Iter-256; D_loss: [ 0.00060116]; G_loss: [ 3.84552312]\n",
      "Iter-512; D_loss: [ 0.00060112]; G_loss: [ 3.84691906]\n",
      "Iter-768; D_loss: [ 0.00058956]; G_loss: [ 3.84832501]\n",
      "Iter-1024; D_loss: [ 0.00058753]; G_loss: [ 3.84972095]\n",
      "Iter-1280; D_loss: [ 0.00059871]; G_loss: [ 3.85112691]\n",
      "Iter-1536; D_loss: [ 0.00058544]; G_loss: [ 3.85249615]\n",
      "Iter-1792; D_loss: [ 0.00058043]; G_loss: [ 3.85389566]\n",
      "Iter-2048; D_loss: [ 0.00065134]; G_loss: [ 3.85530782]\n",
      "Iter-2304; D_loss: [ 0.00059011]; G_loss: [ 3.85664582]\n",
      "Iter-2560; D_loss: [ 0.00062141]; G_loss: [ 3.85804319]\n",
      "Iter-2816; D_loss: [ 0.00057431]; G_loss: [ 3.8594203]\n",
      "Iter-3072; D_loss: [ 0.00058101]; G_loss: [ 3.86082697]\n",
      "Iter-3328; D_loss: [ 0.0005731]; G_loss: [ 3.86219954]\n",
      "Iter-3584; D_loss: [ 0.00057432]; G_loss: [ 3.86358953]\n",
      "epoch: 54\n",
      "Iter-0; D_loss: [ 0.00057403]; G_loss: [ 3.86499143]\n",
      "Iter-256; D_loss: [ 0.00057711]; G_loss: [ 3.8663497]\n",
      "Iter-512; D_loss: [ 0.00057706]; G_loss: [ 3.86773705]\n",
      "Iter-768; D_loss: [ 0.00056603]; G_loss: [ 3.86909032]\n",
      "Iter-1024; D_loss: [ 0.00056404]; G_loss: [ 3.87047076]\n",
      "Iter-1280; D_loss: [ 0.00057491]; G_loss: [ 3.87183547]\n",
      "Iter-1536; D_loss: [ 0.00056221]; G_loss: [ 3.87321901]\n",
      "Iter-1792; D_loss: [ 0.00055726]; G_loss: [ 3.87457156]\n",
      "Iter-2048; D_loss: [ 0.00062568]; G_loss: [ 3.87594748]\n",
      "Iter-2304; D_loss: [ 0.0005667]; G_loss: [ 3.87726426]\n",
      "Iter-2560; D_loss: [ 0.00059692]; G_loss: [ 3.87863541]\n",
      "Iter-2816; D_loss: [ 0.0005516]; G_loss: [ 3.87999892]\n",
      "Iter-3072; D_loss: [ 0.00055812]; G_loss: [ 3.88135076]\n",
      "Iter-3328; D_loss: [ 0.0005505]; G_loss: [ 3.8827343]\n",
      "Iter-3584; D_loss: [ 0.00055184]; G_loss: [ 3.88409209]\n",
      "epoch: 55\n",
      "Iter-0; D_loss: [ 0.00055143]; G_loss: [ 3.88544846]\n",
      "Iter-256; D_loss: [ 0.00055445]; G_loss: [ 3.88679433]\n",
      "Iter-512; D_loss: [ 0.00055439]; G_loss: [ 3.88812542]\n",
      "Iter-768; D_loss: [ 0.00054387]; G_loss: [ 3.88947487]\n",
      "Iter-1024; D_loss: [ 0.00054191]; G_loss: [ 3.89081788]\n",
      "Iter-1280; D_loss: [ 0.00055247]; G_loss: [ 3.89219928]\n",
      "Iter-1536; D_loss: [ 0.00054032]; G_loss: [ 3.89353848]\n",
      "Iter-1792; D_loss: [ 0.00053544]; G_loss: [ 3.89484835]\n",
      "Iter-2048; D_loss: [ 0.00060148]; G_loss: [ 3.89620852]\n",
      "Iter-2304; D_loss: [ 0.00054462]; G_loss: [ 3.89750981]\n",
      "Iter-2560; D_loss: [ 0.00057382]; G_loss: [ 3.89883566]\n",
      "Iter-2816; D_loss: [ 0.0005302]; G_loss: [ 3.90018821]\n",
      "Iter-3072; D_loss: [ 0.00053655]; G_loss: [ 3.90153289]\n",
      "Iter-3328; D_loss: [ 0.00052918]; G_loss: [ 3.902843]\n",
      "Iter-3584; D_loss: [ 0.00053064]; G_loss: [ 3.90418673]\n",
      "epoch: 56\n",
      "Iter-0; D_loss: [ 0.00053011]; G_loss: [ 3.90552711]\n",
      "Iter-256; D_loss: [ 0.00053307]; G_loss: [ 3.90686059]\n",
      "Iter-512; D_loss: [ 0.00053301]; G_loss: [ 3.90815663]\n",
      "Iter-768; D_loss: [ 0.00052295]; G_loss: [ 3.90948009]\n",
      "Iter-1024; D_loss: [ 0.00052104]; G_loss: [ 3.91082144]\n",
      "Iter-1280; D_loss: [ 0.00053128]; G_loss: [ 3.91215611]\n",
      "Iter-1536; D_loss: [ 0.00051966]; G_loss: [ 3.91344857]\n",
      "Iter-1792; D_loss: [ 0.00051484]; G_loss: [ 3.91477633]\n",
      "Iter-2048; D_loss: [ 0.00057862]; G_loss: [ 3.91609025]\n",
      "Iter-2304; D_loss: [ 0.00052379]; G_loss: [ 3.91735959]\n",
      "Iter-2560; D_loss: [ 0.000552]; G_loss: [ 3.91869926]\n",
      "Iter-2816; D_loss: [ 0.00050998]; G_loss: [ 3.91997981]\n",
      "Iter-3072; D_loss: [ 0.00051617]; G_loss: [ 3.92130995]\n",
      "Iter-3328; D_loss: [ 0.00050905]; G_loss: [ 3.9226141]\n",
      "Iter-3584; D_loss: [ 0.00051061]; G_loss: [ 3.92394209]\n",
      "epoch: 57\n",
      "Iter-0; D_loss: [ 0.00050997]; G_loss: [ 3.9252429]\n",
      "Iter-256; D_loss: [ 0.00051288]; G_loss: [ 3.92656016]\n",
      "Iter-512; D_loss: [ 0.00051281]; G_loss: [ 3.92784142]\n",
      "Iter-768; D_loss: [ 0.0005032]; G_loss: [ 3.92912936]\n",
      "Iter-1024; D_loss: [ 0.00050132]; G_loss: [ 3.93042493]\n",
      "Iter-1280; D_loss: [ 0.00051127]; G_loss: [ 3.93174839]\n",
      "Iter-1536; D_loss: [ 0.00050014]; G_loss: [ 3.93303585]\n",
      "Iter-1792; D_loss: [ 0.00049538]; G_loss: [ 3.9343183]\n",
      "Iter-2048; D_loss: [ 0.00055703]; G_loss: [ 3.93561864]\n",
      "Iter-2304; D_loss: [ 0.0005041]; G_loss: [ 3.93688154]\n",
      "Iter-2560; D_loss: [ 0.00053139]; G_loss: [ 3.93816972]\n",
      "Iter-2816; D_loss: [ 0.00049089]; G_loss: [ 3.93944359]\n",
      "Iter-3072; D_loss: [ 0.00049692]; G_loss: [ 3.940732]\n",
      "Iter-3328; D_loss: [ 0.00049003]; G_loss: [ 3.94202471]\n",
      "Iter-3584; D_loss: [ 0.00049167]; G_loss: [ 3.94333744]\n",
      "epoch: 58\n",
      "Iter-0; D_loss: [ 0.00049094]; G_loss: [ 3.94462228]\n",
      "Iter-256; D_loss: [ 0.00049379]; G_loss: [ 3.94590425]\n",
      "Iter-512; D_loss: [ 0.00049372]; G_loss: [ 3.94714308]\n",
      "Iter-768; D_loss: [ 0.00048452]; G_loss: [ 3.94842649]\n",
      "Iter-1024; D_loss: [ 0.00048268]; G_loss: [ 3.94969797]\n",
      "Iter-1280; D_loss: [ 0.00049235]; G_loss: [ 3.95098591]\n",
      "Iter-1536; D_loss: [ 0.00048168]; G_loss: [ 3.95226073]\n",
      "Iter-1792; D_loss: [ 0.00047698]; G_loss: [ 3.95353723]\n",
      "Iter-2048; D_loss: [ 0.0005366]; G_loss: [ 3.95479226]\n",
      "Iter-2304; D_loss: [ 0.00048549]; G_loss: [ 3.95603633]\n",
      "Iter-2560; D_loss: [ 0.00051188]; G_loss: [ 3.95729637]\n",
      "Iter-2816; D_loss: [ 0.00047282]; G_loss: [ 3.95855069]\n",
      "Iter-3072; D_loss: [ 0.00047869]; G_loss: [ 3.95983076]\n",
      "Iter-3328; D_loss: [ 0.00047203]; G_loss: [ 3.9611094]\n",
      "Iter-3584; D_loss: [ 0.00047374]; G_loss: [ 3.96238112]\n",
      "epoch: 59\n",
      "Iter-0; D_loss: [ 0.00047293]; G_loss: [ 3.96362972]\n",
      "Iter-256; D_loss: [ 0.00047573]; G_loss: [ 3.96489882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-512; D_loss: [ 0.00047564]; G_loss: [ 3.96612144]\n",
      "Iter-768; D_loss: [ 0.00046684]; G_loss: [ 3.96739101]\n",
      "Iter-1024; D_loss: [ 0.00046504]; G_loss: [ 3.96863246]\n",
      "Iter-1280; D_loss: [ 0.00047443]; G_loss: [ 3.96990347]\n",
      "Iter-1536; D_loss: [ 0.00046421]; G_loss: [ 3.97116613]\n",
      "Iter-1792; D_loss: [ 0.00045956]; G_loss: [ 3.97239923]\n",
      "Iter-2048; D_loss: [ 0.00051725]; G_loss: [ 3.97364855]\n",
      "Iter-2304; D_loss: [ 0.00046786]; G_loss: [ 3.97485733]\n",
      "Iter-2560; D_loss: [ 0.0004934]; G_loss: [ 3.97608447]\n",
      "Iter-2816; D_loss: [ 0.00045572]; G_loss: [ 3.97734404]\n",
      "Iter-3072; D_loss: [ 0.00046144]; G_loss: [ 3.97861195]\n",
      "Iter-3328; D_loss: [ 0.00045498]; G_loss: [ 3.97984529]\n",
      "Iter-3584; D_loss: [ 0.00045676]; G_loss: [ 3.98108387]\n",
      "epoch: 60\n",
      "Iter-0; D_loss: [ 0.00045587]; G_loss: [ 3.98234081]\n",
      "Iter-256; D_loss: [ 0.00045862]; G_loss: [ 3.98357129]\n",
      "Iter-512; D_loss: [ 0.00045853]; G_loss: [ 3.98479342]\n",
      "Iter-768; D_loss: [ 0.0004501]; G_loss: [ 3.98602152]\n",
      "Iter-1024; D_loss: [ 0.00044832]; G_loss: [ 3.9872458]\n",
      "Iter-1280; D_loss: [ 0.00045746]; G_loss: [ 3.98850465]\n",
      "Iter-1536; D_loss: [ 0.00044764]; G_loss: [ 3.98972225]\n",
      "Iter-1792; D_loss: [ 0.00044305]; G_loss: [ 3.99095178]\n",
      "Iter-2048; D_loss: [ 0.00049889]; G_loss: [ 3.99218798]\n",
      "Iter-2304; D_loss: [ 0.00045115]; G_loss: [ 3.99335289]\n",
      "Iter-2560; D_loss: [ 0.00047589]; G_loss: [ 3.99458623]\n",
      "Iter-2816; D_loss: [ 0.00043949]; G_loss: [ 3.99582124]\n",
      "Iter-3072; D_loss: [ 0.00044508]; G_loss: [ 3.99704695]\n",
      "Iter-3328; D_loss: [ 0.00043883]; G_loss: [ 3.99827695]\n",
      "Iter-3584; D_loss: [ 0.00044066]; G_loss: [ 3.99949956]\n",
      "epoch: 61\n",
      "Iter-0; D_loss: [ 0.0004397]; G_loss: [ 4.00071859]\n",
      "Iter-256; D_loss: [ 0.00044239]; G_loss: [ 4.0019331]\n",
      "Iter-512; D_loss: [ 0.00044229]; G_loss: [ 4.00314522]\n",
      "Iter-768; D_loss: [ 0.00043421]; G_loss: [ 4.00432968]\n",
      "Iter-1024; D_loss: [ 0.00043246]; G_loss: [ 4.00554943]\n",
      "Iter-1280; D_loss: [ 0.00044136]; G_loss: [ 4.00677347]\n",
      "Iter-1536; D_loss: [ 0.00043193]; G_loss: [ 4.00797844]\n",
      "Iter-1792; D_loss: [ 0.0004274]; G_loss: [ 4.00919247]\n",
      "Iter-2048; D_loss: [ 0.00048148]; G_loss: [ 4.01039028]\n",
      "Iter-2304; D_loss: [ 0.0004353]; G_loss: [ 4.01157999]\n",
      "Iter-2560; D_loss: [ 0.00045926]; G_loss: [ 4.01276827]\n",
      "Iter-2816; D_loss: [ 0.00042411]; G_loss: [ 4.01395988]\n",
      "Iter-3072; D_loss: [ 0.00042956]; G_loss: [ 4.01518106]\n",
      "Iter-3328; D_loss: [ 0.00042349]; G_loss: [ 4.016397]\n",
      "Iter-3584; D_loss: [ 0.00042538]; G_loss: [ 4.01760721]\n",
      "epoch: 62\n",
      "Iter-0; D_loss: [ 0.00042436]; G_loss: [ 4.01879454]\n",
      "Iter-256; D_loss: [ 0.00042699]; G_loss: [ 4.01999903]\n",
      "Iter-512; D_loss: [ 0.00042688]; G_loss: [ 4.02117634]\n",
      "Iter-768; D_loss: [ 0.00041913]; G_loss: [ 4.02237797]\n",
      "Iter-1024; D_loss: [ 0.00041741]; G_loss: [ 4.0235548]\n",
      "Iter-1280; D_loss: [ 0.00042608]; G_loss: [ 4.02476168]\n",
      "Iter-1536; D_loss: [ 0.00041702]; G_loss: [ 4.0259347]\n",
      "Iter-1792; D_loss: [ 0.00041253]; G_loss: [ 4.02713871]\n",
      "Iter-2048; D_loss: [ 0.00046494]; G_loss: [ 4.02832508]\n",
      "Iter-2304; D_loss: [ 0.00042025]; G_loss: [ 4.02946758]\n",
      "Iter-2560; D_loss: [ 0.00044348]; G_loss: [ 4.03064966]\n",
      "Iter-2816; D_loss: [ 0.00040949]; G_loss: [ 4.03183794]\n",
      "Iter-3072; D_loss: [ 0.0004148]; G_loss: [ 4.03304577]\n",
      "Iter-3328; D_loss: [ 0.00040892]; G_loss: [ 4.03422117]\n",
      "Iter-3584; D_loss: [ 0.00041085]; G_loss: [ 4.03542757]\n",
      "epoch: 63\n",
      "Iter-0; D_loss: [ 0.00040978]; G_loss: [ 4.03660059]\n",
      "Iter-256; D_loss: [ 0.00041236]; G_loss: [ 4.03776217]\n",
      "Iter-512; D_loss: [ 0.00041224]; G_loss: [ 4.03892183]\n",
      "Iter-768; D_loss: [ 0.00040481]; G_loss: [ 4.04009533]\n",
      "Iter-1024; D_loss: [ 0.00040311]; G_loss: [ 4.04128742]\n",
      "Iter-1280; D_loss: [ 0.00041155]; G_loss: [ 4.04246283]\n",
      "Iter-1536; D_loss: [ 0.00040284]; G_loss: [ 4.04362392]\n",
      "Iter-1792; D_loss: [ 0.0003984]; G_loss: [ 4.04478121]\n",
      "Iter-2048; D_loss: [ 0.00044922]; G_loss: [ 4.04595947]\n",
      "Iter-2304; D_loss: [ 0.00040595]; G_loss: [ 4.04710293]\n",
      "Iter-2560; D_loss: [ 0.00042846]; G_loss: [ 4.04827213]\n",
      "Iter-2816; D_loss: [ 0.0003956]; G_loss: [ 4.04942083]\n",
      "Iter-3072; D_loss: [ 0.00040078]; G_loss: [ 4.05059099]\n",
      "Iter-3328; D_loss: [ 0.00039508]; G_loss: [ 4.05178022]\n",
      "Iter-3584; D_loss: [ 0.00039705]; G_loss: [ 4.05294609]\n",
      "epoch: 64\n",
      "Iter-0; D_loss: [ 0.00039592]; G_loss: [ 4.05411339]\n",
      "Iter-256; D_loss: [ 0.00039845]; G_loss: [ 4.05527353]\n",
      "Iter-512; D_loss: [ 0.00039832]; G_loss: [ 4.05639124]\n",
      "Iter-768; D_loss: [ 0.00039118]; G_loss: [ 4.05755138]\n",
      "Iter-1024; D_loss: [ 0.00038952]; G_loss: [ 4.05870962]\n",
      "Iter-1280; D_loss: [ 0.00039773]; G_loss: [ 4.05986929]\n",
      "Iter-1536; D_loss: [ 0.00038934]; G_loss: [ 4.06101799]\n",
      "Iter-1792; D_loss: [ 0.00038498]; G_loss: [ 4.0621748]\n",
      "Iter-2048; D_loss: [ 0.00043425]; G_loss: [ 4.06331015]\n",
      "Iter-2304; D_loss: [ 0.00039234]; G_loss: [ 4.06444645]\n",
      "Iter-2560; D_loss: [ 0.00041417]; G_loss: [ 4.06560183]\n",
      "Iter-2816; D_loss: [ 0.00038239]; G_loss: [ 4.06674623]\n",
      "Iter-3072; D_loss: [ 0.00038744]; G_loss: [ 4.0678997]\n",
      "Iter-3328; D_loss: [ 0.0003819]; G_loss: [ 4.06905556]\n",
      "Iter-3584; D_loss: [ 0.00038389]; G_loss: [ 4.07018471]\n",
      "epoch: 65\n",
      "Iter-0; D_loss: [ 0.00038273]; G_loss: [ 4.07134008]\n",
      "Iter-256; D_loss: [ 0.0003852]; G_loss: [ 4.07248449]\n",
      "Iter-512; D_loss: [ 0.00038507]; G_loss: [ 4.0736022]\n",
      "Iter-768; D_loss: [ 0.00037821]; G_loss: [ 4.07474709]\n",
      "Iter-1024; D_loss: [ 0.00037658]; G_loss: [ 4.07590055]\n",
      "Iter-1280; D_loss: [ 0.00038458]; G_loss: [ 4.07702303]\n",
      "Iter-1536; D_loss: [ 0.0003765]; G_loss: [ 4.07816505]\n",
      "Iter-1792; D_loss: [ 0.00037219]; G_loss: [ 4.07930374]\n",
      "Iter-2048; D_loss: [ 0.00042]; G_loss: [ 4.08043098]\n",
      "Iter-2304; D_loss: [ 0.00037939]; G_loss: [ 4.08152723]\n",
      "Iter-2560; D_loss: [ 0.00040057]; G_loss: [ 4.08267736]\n",
      "Iter-2816; D_loss: [ 0.0003698]; G_loss: [ 4.08377981]\n",
      "Iter-3072; D_loss: [ 0.00037473]; G_loss: [ 4.08492756]\n",
      "Iter-3328; D_loss: [ 0.00036935]; G_loss: [ 4.08605051]\n",
      "Iter-3584; D_loss: [ 0.00037138]; G_loss: [ 4.08719635]\n",
      "epoch: 66\n",
      "Iter-0; D_loss: [ 0.00037016]; G_loss: [ 4.0883379]\n",
      "Iter-256; D_loss: [ 0.00037259]; G_loss: [ 4.08945084]\n",
      "Iter-512; D_loss: [ 0.00037246]; G_loss: [ 4.09055185]\n",
      "Iter-768; D_loss: [ 0.00036587]; G_loss: [ 4.09166718]\n",
      "Iter-1024; D_loss: [ 0.00036425]; G_loss: [ 4.09280777]\n",
      "Iter-1280; D_loss: [ 0.00037204]; G_loss: [ 4.0939126]\n",
      "Iter-1536; D_loss: [ 0.00036427]; G_loss: [ 4.09505367]\n",
      "Iter-1792; D_loss: [ 0.00036002]; G_loss: [ 4.09615946]\n",
      "Iter-2048; D_loss: [ 0.00040642]; G_loss: [ 4.09727192]\n",
      "Iter-2304; D_loss: [ 0.00036704]; G_loss: [ 4.09836245]\n",
      "Iter-2560; D_loss: [ 0.00038761]; G_loss: [ 4.09947729]\n",
      "Iter-2816; D_loss: [ 0.00035781]; G_loss: [ 4.10057259]\n",
      "Iter-3072; D_loss: [ 0.00036262]; G_loss: [ 4.10170984]\n",
      "Iter-3328; D_loss: [ 0.00035739]; G_loss: [ 4.10281897]\n",
      "Iter-3584; D_loss: [ 0.00035944]; G_loss: [ 4.10392189]\n",
      "epoch: 67\n",
      "Iter-0; D_loss: [ 0.0003582]; G_loss: [ 4.10506058]\n",
      "Iter-256; D_loss: [ 0.00036058]; G_loss: [ 4.1061635]\n",
      "Iter-512; D_loss: [ 0.00036043]; G_loss: [ 4.10722923]\n",
      "Iter-768; D_loss: [ 0.0003541]; G_loss: [ 4.10835886]\n",
      "Iter-1024; D_loss: [ 0.0003525]; G_loss: [ 4.10945559]\n",
      "Iter-1280; D_loss: [ 0.0003601]; G_loss: [ 4.11056614]\n",
      "Iter-1536; D_loss: [ 0.0003526]; G_loss: [ 4.11166573]\n",
      "Iter-1792; D_loss: [ 0.00034841]; G_loss: [ 4.11276722]\n",
      "Iter-2048; D_loss: [ 0.00039347]; G_loss: [ 4.11387253]\n",
      "Iter-2304; D_loss: [ 0.00035527]; G_loss: [ 4.11491776]\n",
      "Iter-2560; D_loss: [ 0.00037524]; G_loss: [ 4.1160264]\n",
      "Iter-2816; D_loss: [ 0.00034638]; G_loss: [ 4.11711311]\n",
      "Iter-3072; D_loss: [ 0.00035108]; G_loss: [ 4.11821651]\n",
      "Iter-3328; D_loss: [ 0.00034599]; G_loss: [ 4.11934233]\n",
      "Iter-3584; D_loss: [ 0.00034805]; G_loss: [ 4.12044096]\n",
      "epoch: 68\n",
      "Iter-0; D_loss: [ 0.00034679]; G_loss: [ 4.12154007]\n",
      "Iter-256; D_loss: [ 0.00034911]; G_loss: [ 4.12260723]\n",
      "Iter-512; D_loss: [ 0.00034896]; G_loss: [ 4.12369251]\n",
      "Iter-768; D_loss: [ 0.00034287]; G_loss: [ 4.12478638]\n",
      "Iter-1024; D_loss: [ 0.0003413]; G_loss: [ 4.12588263]\n",
      "Iter-1280; D_loss: [ 0.0003487]; G_loss: [ 4.12694407]\n",
      "Iter-1536; D_loss: [ 0.00034148]; G_loss: [ 4.12803888]\n",
      "Iter-1792; D_loss: [ 0.00033733]; G_loss: [ 4.12912416]\n",
      "Iter-2048; D_loss: [ 0.00038111]; G_loss: [ 4.130229]\n",
      "Iter-2304; D_loss: [ 0.00034404]; G_loss: [ 4.13127232]\n",
      "Iter-2560; D_loss: [ 0.00036343]; G_loss: [ 4.13235903]\n",
      "Iter-2816; D_loss: [ 0.00033546]; G_loss: [ 4.13344145]\n",
      "Iter-3072; D_loss: [ 0.00034006]; G_loss: [ 4.1345129]\n",
      "Iter-3328; D_loss: [ 0.00033511]; G_loss: [ 4.13560581]\n",
      "Iter-3584; D_loss: [ 0.00033719]; G_loss: [ 4.13668966]\n",
      "epoch: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [ 0.00033588]; G_loss: [ 4.13777399]\n",
      "Iter-256; D_loss: [ 0.00033817]; G_loss: [ 4.1388402]\n",
      "Iter-512; D_loss: [ 0.000338]; G_loss: [ 4.13991499]\n",
      "Iter-768; D_loss: [ 0.00033214]; G_loss: [ 4.14097595]\n",
      "Iter-1024; D_loss: [ 0.00033059]; G_loss: [ 4.14205742]\n",
      "Iter-1280; D_loss: [ 0.00033782]; G_loss: [ 4.14311647]\n",
      "Iter-1536; D_loss: [ 0.00033085]; G_loss: [ 4.14419651]\n",
      "Iter-1792; D_loss: [ 0.00032676]; G_loss: [ 4.14528036]\n",
      "Iter-2048; D_loss: [ 0.0003693]; G_loss: [ 4.1463418]\n",
      "Iter-2304; D_loss: [ 0.00033332]; G_loss: [ 4.14737368]\n",
      "Iter-2560; D_loss: [ 0.00035216]; G_loss: [ 4.14843512]\n",
      "Iter-2816; D_loss: [ 0.00032504]; G_loss: [ 4.14950275]\n",
      "Iter-3072; D_loss: [ 0.00032952]; G_loss: [ 4.1505928]\n",
      "Iter-3328; D_loss: [ 0.00032471]; G_loss: [ 4.15164709]\n",
      "Iter-3584; D_loss: [ 0.0003268]; G_loss: [ 4.1527319]\n",
      "epoch: 70\n",
      "Iter-0; D_loss: [ 0.00032547]; G_loss: [ 4.1537838]\n",
      "Iter-256; D_loss: [ 0.0003277]; G_loss: [ 4.15483189]\n",
      "Iter-512; D_loss: [ 0.00032754]; G_loss: [ 4.15590143]\n",
      "Iter-768; D_loss: [ 0.00032189]; G_loss: [ 4.15694952]\n",
      "Iter-1024; D_loss: [ 0.00032038]; G_loss: [ 4.15800095]\n",
      "Iter-1280; D_loss: [ 0.00032742]; G_loss: [ 4.15907955]\n",
      "Iter-1536; D_loss: [ 0.00032069]; G_loss: [ 4.16012096]\n",
      "Iter-1792; D_loss: [ 0.00031665]; G_loss: [ 4.1611743]\n",
      "Iter-2048; D_loss: [ 0.00035801]; G_loss: [ 4.16222095]\n",
      "Iter-2304; D_loss: [ 0.00032307]; G_loss: [ 4.16324568]\n",
      "Iter-2560; D_loss: [ 0.00034139]; G_loss: [ 4.1643033]\n",
      "Iter-2816; D_loss: [ 0.00031508]; G_loss: [ 4.16535997]\n",
      "Iter-3072; D_loss: [ 0.00031946]; G_loss: [ 4.16641617]\n",
      "Iter-3328; D_loss: [ 0.00031477]; G_loss: [ 4.16746664]\n",
      "Iter-3584; D_loss: [ 0.00031687]; G_loss: [ 4.16853428]\n",
      "epoch: 71\n",
      "Iter-0; D_loss: [ 0.00031553]; G_loss: [ 4.16958523]\n",
      "Iter-256; D_loss: [ 0.00031771]; G_loss: [ 4.1706214]\n",
      "Iter-512; D_loss: [ 0.00031755]; G_loss: [ 4.17166138]\n",
      "Iter-768; D_loss: [ 0.0003121]; G_loss: [ 4.17269468]\n",
      "Iter-1024; D_loss: [ 0.00031061]; G_loss: [ 4.17373705]\n",
      "Iter-1280; D_loss: [ 0.00031747]; G_loss: [ 4.17478228]\n",
      "Iter-1536; D_loss: [ 0.00031098]; G_loss: [ 4.17582321]\n",
      "Iter-1792; D_loss: [ 0.00030699]; G_loss: [ 4.17686176]\n",
      "Iter-2048; D_loss: [ 0.00034722]; G_loss: [ 4.17790747]\n",
      "Iter-2304; D_loss: [ 0.00031328]; G_loss: [ 4.17892408]\n",
      "Iter-2560; D_loss: [ 0.00033109]; G_loss: [ 4.17996264]\n",
      "Iter-2816; D_loss: [ 0.00030555]; G_loss: [ 4.18099499]\n",
      "Iter-3072; D_loss: [ 0.00030983]; G_loss: [ 4.18203974]\n",
      "Iter-3328; D_loss: [ 0.00030527]; G_loss: [ 4.18307686]\n",
      "Iter-3584; D_loss: [ 0.00030737]; G_loss: [ 4.18411541]\n",
      "epoch: 72\n",
      "Iter-0; D_loss: [ 0.000306]; G_loss: [ 4.18515348]\n",
      "Iter-256; D_loss: [ 0.00030814]; G_loss: [ 4.18618917]\n",
      "Iter-512; D_loss: [ 0.00030797]; G_loss: [ 4.18720865]\n",
      "Iter-768; D_loss: [ 0.00030273]; G_loss: [ 4.18824577]\n",
      "Iter-1024; D_loss: [ 0.00030125]; G_loss: [ 4.18925333]\n",
      "Iter-1280; D_loss: [ 0.00030796]; G_loss: [ 4.19028568]\n",
      "Iter-1536; D_loss: [ 0.00030169]; G_loss: [ 4.1913166]\n",
      "Iter-1792; D_loss: [ 0.00029775]; G_loss: [ 4.19234657]\n",
      "Iter-2048; D_loss: [ 0.00033689]; G_loss: [ 4.19336176]\n",
      "Iter-2304; D_loss: [ 0.0003039]; G_loss: [ 4.19437075]\n",
      "Iter-2560; D_loss: [ 0.00032122]; G_loss: [ 4.19540882]\n",
      "Iter-2816; D_loss: [ 0.00029643]; G_loss: [ 4.19642591]\n",
      "Iter-3072; D_loss: [ 0.00030062]; G_loss: [ 4.19743395]\n",
      "Iter-3328; D_loss: [ 0.00029617]; G_loss: [ 4.19846582]\n",
      "Iter-3584; D_loss: [ 0.00029827]; G_loss: [ 4.19949484]\n",
      "epoch: 73\n",
      "Iter-0; D_loss: [ 0.0002969]; G_loss: [ 4.20052624]\n",
      "Iter-256; D_loss: [ 0.00029899]; G_loss: [ 4.20155525]\n",
      "Iter-512; D_loss: [ 0.00029881]; G_loss: [ 4.20254421]\n",
      "Iter-768; D_loss: [ 0.00029376]; G_loss: [ 4.20356369]\n",
      "Iter-1024; D_loss: [ 0.0002923]; G_loss: [ 4.20457077]\n",
      "Iter-1280; D_loss: [ 0.00029885]; G_loss: [ 4.20559931]\n",
      "Iter-1536; D_loss: [ 0.00029279]; G_loss: [ 4.20661592]\n",
      "Iter-1792; D_loss: [ 0.00028891]; G_loss: [ 4.20761395]\n",
      "Iter-2048; D_loss: [ 0.00032699]; G_loss: [ 4.20861912]\n",
      "Iter-2304; D_loss: [ 0.00029492]; G_loss: [ 4.20962572]\n",
      "Iter-2560; D_loss: [ 0.00031177]; G_loss: [ 4.21062183]\n",
      "Iter-2816; D_loss: [ 0.0002877]; G_loss: [ 4.21163225]\n",
      "Iter-3072; D_loss: [ 0.00029179]; G_loss: [ 4.21266556]\n",
      "Iter-3328; D_loss: [ 0.00028746]; G_loss: [ 4.21365929]\n",
      "Iter-3584; D_loss: [ 0.00028956]; G_loss: [ 4.21468401]\n",
      "epoch: 74\n",
      "Iter-0; D_loss: [ 0.00028817]; G_loss: [ 4.21568298]\n",
      "Iter-256; D_loss: [ 0.00029022]; G_loss: [ 4.21670198]\n",
      "Iter-512; D_loss: [ 0.00029004]; G_loss: [ 4.21768188]\n",
      "Iter-768; D_loss: [ 0.00028517]; G_loss: [ 4.21869755]\n",
      "Iter-1024; D_loss: [ 0.00028373]; G_loss: [ 4.21969414]\n",
      "Iter-1280; D_loss: [ 0.00029012]; G_loss: [ 4.22068739]\n",
      "Iter-1536; D_loss: [ 0.00028426]; G_loss: [ 4.22170496]\n",
      "Iter-1792; D_loss: [ 0.00028043]; G_loss: [ 4.22269392]\n",
      "Iter-2048; D_loss: [ 0.00031751]; G_loss: [ 4.22368193]\n",
      "Iter-2304; D_loss: [ 0.00028632]; G_loss: [ 4.22465229]\n",
      "Iter-2560; D_loss: [ 0.00030272]; G_loss: [ 4.22567654]\n",
      "Iter-2816; D_loss: [ 0.00027933]; G_loss: [ 4.22665644]\n",
      "Iter-3072; D_loss: [ 0.00028334]; G_loss: [ 4.22764778]\n",
      "Iter-3328; D_loss: [ 0.00027911]; G_loss: [ 4.22866154]\n",
      "Iter-3584; D_loss: [ 0.00028121]; G_loss: [ 4.22965622]\n",
      "epoch: 75\n",
      "Iter-0; D_loss: [ 0.00027981]; G_loss: [ 4.23066568]\n",
      "Iter-256; D_loss: [ 0.00028182]; G_loss: [ 4.23165083]\n",
      "Iter-512; D_loss: [ 0.00028163]; G_loss: [ 4.23263073]\n",
      "Iter-768; D_loss: [ 0.00027693]; G_loss: [ 4.23361349]\n",
      "Iter-1024; D_loss: [ 0.00027551]; G_loss: [ 4.23459816]\n",
      "Iter-1280; D_loss: [ 0.00028175]; G_loss: [ 4.23560905]\n",
      "Iter-1536; D_loss: [ 0.00027609]; G_loss: [ 4.23659897]\n",
      "Iter-1792; D_loss: [ 0.0002723]; G_loss: [ 4.23757601]\n",
      "Iter-2048; D_loss: [ 0.00030842]; G_loss: [ 4.23856783]\n",
      "Iter-2304; D_loss: [ 0.00027807]; G_loss: [ 4.23952913]\n",
      "Iter-2560; D_loss: [ 0.00029404]; G_loss: [ 4.24051285]\n",
      "Iter-2816; D_loss: [ 0.00027132]; G_loss: [ 4.24148226]\n",
      "Iter-3072; D_loss: [ 0.00027523]; G_loss: [ 4.24247456]\n",
      "Iter-3328; D_loss: [ 0.0002711]; G_loss: [ 4.2434783]\n",
      "Iter-3584; D_loss: [ 0.0002732]; G_loss: [ 4.2444582]\n",
      "epoch: 76\n",
      "Iter-0; D_loss: [ 0.00027179]; G_loss: [ 4.24544573]\n",
      "Iter-256; D_loss: [ 0.00027376]; G_loss: [ 4.24641991]\n",
      "Iter-512; D_loss: [ 0.00027357]; G_loss: [ 4.24738979]\n",
      "Iter-768; D_loss: [ 0.00026904]; G_loss: [ 4.2483716]\n",
      "Iter-1024; D_loss: [ 0.00026763]; G_loss: [ 4.2493453]\n",
      "Iter-1280; D_loss: [ 0.00027373]; G_loss: [ 4.25032568]\n",
      "Iter-1536; D_loss: [ 0.00026825]; G_loss: [ 4.25130129]\n",
      "Iter-1792; D_loss: [ 0.00026451]; G_loss: [ 4.2522769]\n",
      "Iter-2048; D_loss: [ 0.00029969]; G_loss: [ 4.25322771]\n",
      "Iter-2304; D_loss: [ 0.00027016]; G_loss: [ 4.25418329]\n",
      "Iter-2560; D_loss: [ 0.00028571]; G_loss: [ 4.25516224]\n",
      "Iter-2816; D_loss: [ 0.00026362]; G_loss: [ 4.25612688]\n",
      "Iter-3072; D_loss: [ 0.00026745]; G_loss: [ 4.25710869]\n",
      "Iter-3328; D_loss: [ 0.00026342]; G_loss: [ 4.25808334]\n",
      "Iter-3584; D_loss: [ 0.00026552]; G_loss: [ 4.25906181]\n",
      "epoch: 77\n",
      "Iter-0; D_loss: [ 0.00026409]; G_loss: [ 4.2600379]\n",
      "Iter-256; D_loss: [ 0.00026603]; G_loss: [ 4.26100159]\n",
      "Iter-512; D_loss: [ 0.00026584]; G_loss: [ 4.26194763]\n",
      "Iter-768; D_loss: [ 0.00026146]; G_loss: [ 4.26291895]\n",
      "Iter-1024; D_loss: [ 0.00026007]; G_loss: [ 4.26388502]\n",
      "Iter-1280; D_loss: [ 0.00026603]; G_loss: [ 4.26485205]\n",
      "Iter-1536; D_loss: [ 0.00026072]; G_loss: [ 4.26581812]\n",
      "Iter-1792; D_loss: [ 0.00025704]; G_loss: [ 4.26679182]\n",
      "Iter-2048; D_loss: [ 0.00029132]; G_loss: [ 4.26773787]\n",
      "Iter-2304; D_loss: [ 0.00026256]; G_loss: [ 4.26869392]\n",
      "Iter-2560; D_loss: [ 0.00027772]; G_loss: [ 4.26962852]\n",
      "Iter-2816; D_loss: [ 0.00025624]; G_loss: [ 4.2705965]\n",
      "Iter-3072; D_loss: [ 0.00025998]; G_loss: [ 4.27156782]\n",
      "Iter-3328; D_loss: [ 0.00025605]; G_loss: [ 4.27253819]\n",
      "Iter-3584; D_loss: [ 0.00025814]; G_loss: [ 4.27347946]\n",
      "epoch: 78\n",
      "Iter-0; D_loss: [ 0.00025671]; G_loss: [ 4.27444315]\n",
      "Iter-256; D_loss: [ 0.00025861]; G_loss: [ 4.27541208]\n",
      "Iter-512; D_loss: [ 0.00025841]; G_loss: [ 4.27634811]\n",
      "Iter-768; D_loss: [ 0.00025418]; G_loss: [ 4.27731085]\n",
      "Iter-1024; D_loss: [ 0.00025282]; G_loss: [ 4.278265]\n",
      "Iter-1280; D_loss: [ 0.00025864]; G_loss: [ 4.27920485]\n",
      "Iter-1536; D_loss: [ 0.0002535]; G_loss: [ 4.28016996]\n",
      "Iter-1792; D_loss: [ 0.00024986]; G_loss: [ 4.28110552]\n",
      "Iter-2048; D_loss: [ 0.00028327]; G_loss: [ 4.28206825]\n",
      "Iter-2304; D_loss: [ 0.00025527]; G_loss: [ 4.28298807]\n",
      "Iter-2560; D_loss: [ 0.00027004]; G_loss: [ 4.2839241]\n",
      "Iter-2816; D_loss: [ 0.00024914]; G_loss: [ 4.28488111]\n",
      "Iter-3072; D_loss: [ 0.0002528]; G_loss: [ 4.28584671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3328; D_loss: [ 0.00024897]; G_loss: [ 4.28678131]\n",
      "Iter-3584; D_loss: [ 0.00025105]; G_loss: [ 4.28774738]\n",
      "epoch: 79\n",
      "Iter-0; D_loss: [ 0.00024962]; G_loss: [ 4.28870869]\n",
      "Iter-256; D_loss: [ 0.00025147]; G_loss: [ 4.28963041]\n",
      "Iter-512; D_loss: [ 0.00025127]; G_loss: [ 4.29056501]\n",
      "Iter-768; D_loss: [ 0.00024719]; G_loss: [ 4.29152346]\n",
      "Iter-1024; D_loss: [ 0.00024584]; G_loss: [ 4.29244947]\n",
      "Iter-1280; D_loss: [ 0.00025153]; G_loss: [ 4.29340363]\n",
      "Iter-1536; D_loss: [ 0.00024655]; G_loss: [ 4.29433203]\n",
      "Iter-1792; D_loss: [ 0.00024297]; G_loss: [ 4.29526758]\n",
      "Iter-2048; D_loss: [ 0.00027554]; G_loss: [ 4.29619598]\n",
      "Iter-2304; D_loss: [ 0.00024828]; G_loss: [ 4.29714298]\n",
      "Iter-2560; D_loss: [ 0.00026266]; G_loss: [ 4.29807043]\n",
      "Iter-2816; D_loss: [ 0.00024233]; G_loss: [ 4.29898548]\n",
      "Iter-3072; D_loss: [ 0.00024591]; G_loss: [ 4.29994965]\n",
      "Iter-3328; D_loss: [ 0.00024217]; G_loss: [ 4.30088282]\n",
      "Iter-3584; D_loss: [ 0.00024424]; G_loss: [ 4.30183744]\n",
      "epoch: 80\n",
      "Iter-0; D_loss: [ 0.0002428]; G_loss: [ 4.30276251]\n",
      "Iter-256; D_loss: [ 0.00024462]; G_loss: [ 4.30368137]\n",
      "Iter-512; D_loss: [ 0.00024442]; G_loss: [ 4.30460644]\n",
      "Iter-768; D_loss: [ 0.00024047]; G_loss: [ 4.30556154]\n",
      "Iter-1024; D_loss: [ 0.00023914]; G_loss: [ 4.3064847]\n",
      "Iter-1280; D_loss: [ 0.00024471]; G_loss: [ 4.30740786]\n",
      "Iter-1536; D_loss: [ 0.00023988]; G_loss: [ 4.30835676]\n",
      "Iter-1792; D_loss: [ 0.00023633]; G_loss: [ 4.30926991]\n",
      "Iter-2048; D_loss: [ 0.0002681]; G_loss: [ 4.31020594]\n",
      "Iter-2304; D_loss: [ 0.00024154]; G_loss: [ 4.31110764]\n",
      "Iter-2560; D_loss: [ 0.00025556]; G_loss: [ 4.31204176]\n",
      "Iter-2816; D_loss: [ 0.00023578]; G_loss: [ 4.312953]\n",
      "Iter-3072; D_loss: [ 0.00023928]; G_loss: [ 4.31387758]\n",
      "Iter-3328; D_loss: [ 0.00023562]; G_loss: [ 4.3148303]\n",
      "Iter-3584; D_loss: [ 0.00023768]; G_loss: [ 4.31574392]\n",
      "epoch: 81\n",
      "Iter-0; D_loss: [ 0.00023625]; G_loss: [ 4.31667423]\n",
      "Iter-256; D_loss: [ 0.00023803]; G_loss: [ 4.31759405]\n",
      "Iter-512; D_loss: [ 0.00023783]; G_loss: [ 4.31850576]\n",
      "Iter-768; D_loss: [ 0.00023401]; G_loss: [ 4.31942463]\n",
      "Iter-1024; D_loss: [ 0.0002327]; G_loss: [ 4.3203373]\n",
      "Iter-1280; D_loss: [ 0.00023814]; G_loss: [ 4.32126665]\n",
      "Iter-1536; D_loss: [ 0.00023346]; G_loss: [ 4.32217598]\n",
      "Iter-1792; D_loss: [ 0.00022996]; G_loss: [ 4.32309484]\n",
      "Iter-2048; D_loss: [ 0.00026095]; G_loss: [ 4.32401323]\n",
      "Iter-2304; D_loss: [ 0.00023506]; G_loss: [ 4.32491112]\n",
      "Iter-2560; D_loss: [ 0.00024874]; G_loss: [ 4.3258357]\n",
      "Iter-2816; D_loss: [ 0.00022947]; G_loss: [ 4.32673693]\n",
      "Iter-3072; D_loss: [ 0.0002329]; G_loss: [ 4.32765961]\n",
      "Iter-3328; D_loss: [ 0.00022933]; G_loss: [ 4.32858086]\n",
      "Iter-3584; D_loss: [ 0.00023138]; G_loss: [ 4.32949352]\n",
      "epoch: 82\n",
      "Iter-0; D_loss: [ 0.00022994]; G_loss: [ 4.33042336]\n",
      "Iter-256; D_loss: [ 0.0002317]; G_loss: [ 4.33132124]\n",
      "Iter-512; D_loss: [ 0.00023148]; G_loss: [ 4.33223152]\n",
      "Iter-768; D_loss: [ 0.00022779]; G_loss: [ 4.33314705]\n",
      "Iter-1024; D_loss: [ 0.0002265]; G_loss: [ 4.33405066]\n",
      "Iter-1280; D_loss: [ 0.00023182]; G_loss: [ 4.3349719]\n",
      "Iter-1536; D_loss: [ 0.00022728]; G_loss: [ 4.33587885]\n",
      "Iter-1792; D_loss: [ 0.00022383]; G_loss: [ 4.3367691]\n",
      "Iter-2048; D_loss: [ 0.00025408]; G_loss: [ 4.33768129]\n",
      "Iter-2304; D_loss: [ 0.00022883]; G_loss: [ 4.33857107]\n",
      "Iter-2560; D_loss: [ 0.00024216]; G_loss: [ 4.33946466]\n",
      "Iter-2816; D_loss: [ 0.00022341]; G_loss: [ 4.34036398]\n",
      "Iter-3072; D_loss: [ 0.00022676]; G_loss: [ 4.34128523]\n",
      "Iter-3328; D_loss: [ 0.00022327]; G_loss: [ 4.34218454]\n",
      "Iter-3584; D_loss: [ 0.00022531]; G_loss: [ 4.34309578]\n",
      "epoch: 83\n",
      "Iter-0; D_loss: [ 0.00022388]; G_loss: [ 4.34401464]\n",
      "Iter-256; D_loss: [ 0.00022559]; G_loss: [ 4.34491491]\n",
      "Iter-512; D_loss: [ 0.00022538]; G_loss: [ 4.34579659]\n",
      "Iter-768; D_loss: [ 0.0002218]; G_loss: [ 4.34669924]\n",
      "Iter-1024; D_loss: [ 0.00022053]; G_loss: [ 4.34760809]\n",
      "Iter-1280; D_loss: [ 0.00022573]; G_loss: [ 4.34849024]\n",
      "Iter-1536; D_loss: [ 0.00022134]; G_loss: [ 4.34938622]\n",
      "Iter-1792; D_loss: [ 0.00021793]; G_loss: [ 4.35029268]\n",
      "Iter-2048; D_loss: [ 0.00024745]; G_loss: [ 4.3511796]\n",
      "Iter-2304; D_loss: [ 0.00022283]; G_loss: [ 4.35207129]\n",
      "Iter-2560; D_loss: [ 0.00023584]; G_loss: [ 4.35294628]\n",
      "Iter-2816; D_loss: [ 0.00021757]; G_loss: [ 4.35384893]\n",
      "Iter-3072; D_loss: [ 0.00022086]; G_loss: [ 4.35475731]\n",
      "Iter-3328; D_loss: [ 0.00021744]; G_loss: [ 4.35565567]\n",
      "Iter-3584; D_loss: [ 0.00021947]; G_loss: [ 4.3565464]\n",
      "epoch: 84\n",
      "Iter-0; D_loss: [ 0.00021804]; G_loss: [ 4.35744476]\n",
      "Iter-256; D_loss: [ 0.00021972]; G_loss: [ 4.35833979]\n",
      "Iter-512; D_loss: [ 0.0002195]; G_loss: [ 4.35922003]\n",
      "Iter-768; D_loss: [ 0.00021604]; G_loss: [ 4.36011696]\n",
      "Iter-1024; D_loss: [ 0.00021478]; G_loss: [ 4.3609848]\n",
      "Iter-1280; D_loss: [ 0.00021987]; G_loss: [ 4.36189127]\n",
      "Iter-1536; D_loss: [ 0.00021561]; G_loss: [ 4.36276817]\n",
      "Iter-1792; D_loss: [ 0.00021224]; G_loss: [ 4.36366653]\n",
      "Iter-2048; D_loss: [ 0.00024107]; G_loss: [ 4.36453629]\n",
      "Iter-2304; D_loss: [ 0.00021705]; G_loss: [ 4.36542082]\n",
      "Iter-2560; D_loss: [ 0.00022975]; G_loss: [ 4.36629486]\n",
      "Iter-2816; D_loss: [ 0.00021194]; G_loss: [ 4.36719275]\n",
      "Iter-3072; D_loss: [ 0.00021516]; G_loss: [ 4.36806583]\n",
      "Iter-3328; D_loss: [ 0.00021182]; G_loss: [ 4.36896753]\n",
      "Iter-3584; D_loss: [ 0.00021384]; G_loss: [ 4.36984158]\n",
      "epoch: 85\n",
      "Iter-0; D_loss: [ 0.00021241]; G_loss: [ 4.37074661]\n",
      "Iter-256; D_loss: [ 0.00021405]; G_loss: [ 4.37160444]\n",
      "Iter-512; D_loss: [ 0.00021384]; G_loss: [ 4.37247276]\n",
      "Iter-768; D_loss: [ 0.00021048]; G_loss: [ 4.37336588]\n",
      "Iter-1024; D_loss: [ 0.00020925]; G_loss: [ 4.37424231]\n",
      "Iter-1280; D_loss: [ 0.00021423]; G_loss: [ 4.37514067]\n",
      "Iter-1536; D_loss: [ 0.00021009]; G_loss: [ 4.3759985]\n",
      "Iter-1792; D_loss: [ 0.00020677]; G_loss: [ 4.37689161]\n",
      "Iter-2048; D_loss: [ 0.00023491]; G_loss: [ 4.37776041]\n",
      "Iter-2304; D_loss: [ 0.00021148]; G_loss: [ 4.37861633]\n",
      "Iter-2560; D_loss: [ 0.00022387]; G_loss: [ 4.3794899]\n",
      "Iter-2816; D_loss: [ 0.00020652]; G_loss: [ 4.38037777]\n",
      "Iter-3072; D_loss: [ 0.00020967]; G_loss: [ 4.38124561]\n",
      "Iter-3328; D_loss: [ 0.00020641]; G_loss: [ 4.3821106]\n",
      "Iter-3584; D_loss: [ 0.00020841]; G_loss: [ 4.383008]\n",
      "epoch: 86\n",
      "Iter-0; D_loss: [ 0.00020698]; G_loss: [ 4.38387823]\n",
      "Iter-256; D_loss: [ 0.0002086]; G_loss: [ 4.38474274]\n",
      "Iter-512; D_loss: [ 0.00020838]; G_loss: [ 4.38562822]\n",
      "Iter-768; D_loss: [ 0.00020513]; G_loss: [ 4.38649321]\n",
      "Iter-1024; D_loss: [ 0.00020391]; G_loss: [ 4.38734961]\n",
      "Iter-1280; D_loss: [ 0.00020878]; G_loss: [ 4.3882165]\n",
      "Iter-1536; D_loss: [ 0.00020477]; G_loss: [ 4.38910055]\n",
      "Iter-1792; D_loss: [ 0.00020149]; G_loss: [ 4.38996267]\n",
      "Iter-2048; D_loss: [ 0.00022898]; G_loss: [ 4.39083099]\n",
      "Iter-2304; D_loss: [ 0.00020612]; G_loss: [ 4.39167643]\n",
      "Iter-2560; D_loss: [ 0.00021821]; G_loss: [ 4.39253759]\n",
      "Iter-2816; D_loss: [ 0.00020129]; G_loss: [ 4.39340448]\n",
      "Iter-3072; D_loss: [ 0.00020438]; G_loss: [ 4.39429188]\n",
      "Iter-3328; D_loss: [ 0.00020118]; G_loss: [ 4.39515448]\n",
      "Iter-3584; D_loss: [ 0.00020318]; G_loss: [ 4.39601755]\n",
      "epoch: 87\n",
      "Iter-0; D_loss: [ 0.00020175]; G_loss: [ 4.3968811]\n",
      "Iter-256; D_loss: [ 0.00020334]; G_loss: [ 4.39773607]\n",
      "Iter-512; D_loss: [ 0.00020311]; G_loss: [ 4.398592]\n",
      "Iter-768; D_loss: [ 0.00019997]; G_loss: [ 4.39944649]\n",
      "Iter-1024; D_loss: [ 0.00019877]; G_loss: [ 4.40032768]\n",
      "Iter-1280; D_loss: [ 0.00020354]; G_loss: [ 4.40118837]\n",
      "Iter-1536; D_loss: [ 0.00019964]; G_loss: [ 4.40204811]\n",
      "Iter-1792; D_loss: [ 0.0001964]; G_loss: [ 4.40290308]\n",
      "Iter-2048; D_loss: [ 0.00022326]; G_loss: [ 4.40376139]\n",
      "Iter-2304; D_loss: [ 0.00020094]; G_loss: [ 4.40460205]\n",
      "Iter-2560; D_loss: [ 0.00021275]; G_loss: [ 4.4054637]\n",
      "Iter-2816; D_loss: [ 0.00019625]; G_loss: [ 4.40631914]\n",
      "Iter-3072; D_loss: [ 0.00019927]; G_loss: [ 4.40717363]\n",
      "Iter-3328; D_loss: [ 0.00019615]; G_loss: [ 4.40804148]\n",
      "Iter-3584; D_loss: [ 0.00019813]; G_loss: [ 4.40889978]\n",
      "epoch: 88\n",
      "Iter-0; D_loss: [ 0.0001967]; G_loss: [ 4.40975714]\n",
      "Iter-256; D_loss: [ 0.00019826]; G_loss: [ 4.41059637]\n",
      "Iter-512; D_loss: [ 0.00019804]; G_loss: [ 4.41145229]\n",
      "Iter-768; D_loss: [ 0.00019499]; G_loss: [ 4.41230249]\n",
      "Iter-1024; D_loss: [ 0.0001938]; G_loss: [ 4.4131546]\n",
      "Iter-1280; D_loss: [ 0.00019847]; G_loss: [ 4.41401291]\n",
      "Iter-1536; D_loss: [ 0.00019468]; G_loss: [ 4.41485786]\n",
      "Iter-1792; D_loss: [ 0.00019149]; G_loss: [ 4.41571093]\n",
      "Iter-2048; D_loss: [ 0.00021774]; G_loss: [ 4.41653728]\n",
      "Iter-2304; D_loss: [ 0.00019595]; G_loss: [ 4.4173789]\n",
      "Iter-2560; D_loss: [ 0.00020748]; G_loss: [ 4.41823816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2816; D_loss: [ 0.00019138]; G_loss: [ 4.41908312]\n",
      "Iter-3072; D_loss: [ 0.00019435]; G_loss: [ 4.41993809]\n",
      "Iter-3328; D_loss: [ 0.00019129]; G_loss: [ 4.42079163]\n",
      "Iter-3584; D_loss: [ 0.00019325]; G_loss: [ 4.42164755]\n",
      "epoch: 89\n",
      "Iter-0; D_loss: [ 0.00019183]; G_loss: [ 4.42250109]\n",
      "Iter-256; D_loss: [ 0.00019336]; G_loss: [ 4.42334414]\n",
      "Iter-512; D_loss: [ 0.00019313]; G_loss: [ 4.42416]\n",
      "Iter-768; D_loss: [ 0.00019018]; G_loss: [ 4.42501163]\n",
      "Iter-1024; D_loss: [ 0.00018901]; G_loss: [ 4.42585135]\n",
      "Iter-1280; D_loss: [ 0.00019358]; G_loss: [ 4.42669868]\n",
      "Iter-1536; D_loss: [ 0.0001899]; G_loss: [ 4.42754841]\n",
      "Iter-1792; D_loss: [ 0.00018675]; G_loss: [ 4.42837095]\n",
      "Iter-2048; D_loss: [ 0.00021241]; G_loss: [ 4.42921638]\n",
      "Iter-2304; D_loss: [ 0.00019112]; G_loss: [ 4.43005753]\n",
      "Iter-2560; D_loss: [ 0.00020239]; G_loss: [ 4.43088055]\n",
      "Iter-2816; D_loss: [ 0.00018668]; G_loss: [ 4.43172359]\n",
      "Iter-3072; D_loss: [ 0.0001896]; G_loss: [ 4.43255663]\n",
      "Iter-3328; D_loss: [ 0.0001866]; G_loss: [ 4.43340921]\n",
      "Iter-3584; D_loss: [ 0.00018854]; G_loss: [ 4.43423605]\n",
      "epoch: 90\n",
      "Iter-0; D_loss: [ 0.00018713]; G_loss: [ 4.43508005]\n",
      "Iter-256; D_loss: [ 0.00018863]; G_loss: [ 4.43593025]\n",
      "Iter-512; D_loss: [ 0.0001884]; G_loss: [ 4.43674231]\n",
      "Iter-768; D_loss: [ 0.00018554]; G_loss: [ 4.43758583]\n",
      "Iter-1024; D_loss: [ 0.00018438]; G_loss: [ 4.4384222]\n",
      "Iter-1280; D_loss: [ 0.00018886]; G_loss: [ 4.43924093]\n",
      "Iter-1536; D_loss: [ 0.00018528]; G_loss: [ 4.44008303]\n",
      "Iter-1792; D_loss: [ 0.00018217]; G_loss: [ 4.44092989]\n",
      "Iter-2048; D_loss: [ 0.00020726]; G_loss: [ 4.44174814]\n",
      "Iter-2304; D_loss: [ 0.00018646]; G_loss: [ 4.44257402]\n",
      "Iter-2560; D_loss: [ 0.00019747]; G_loss: [ 4.44338703]\n",
      "Iter-2816; D_loss: [ 0.00018215]; G_loss: [ 4.4442277]\n",
      "Iter-3072; D_loss: [ 0.00018501]; G_loss: [ 4.4450736]\n",
      "Iter-3328; D_loss: [ 0.00018207]; G_loss: [ 4.44589472]\n",
      "Iter-3584; D_loss: [ 0.000184]; G_loss: [ 4.44674063]\n",
      "epoch: 91\n",
      "Iter-0; D_loss: [ 0.00018259]; G_loss: [ 4.44756985]\n",
      "Iter-256; D_loss: [ 0.00018406]; G_loss: [ 4.44838285]\n",
      "Iter-512; D_loss: [ 0.00018384]; G_loss: [ 4.44922304]\n",
      "Iter-768; D_loss: [ 0.00018106]; G_loss: [ 4.45003557]\n",
      "Iter-1024; D_loss: [ 0.00017992]; G_loss: [ 4.45086479]\n",
      "Iter-1280; D_loss: [ 0.00018431]; G_loss: [ 4.45168066]\n",
      "Iter-1536; D_loss: [ 0.00018083]; G_loss: [ 4.45252752]\n",
      "Iter-1792; D_loss: [ 0.00017775]; G_loss: [ 4.45333147]\n",
      "Iter-2048; D_loss: [ 0.00020229]; G_loss: [ 4.45413971]\n",
      "Iter-2304; D_loss: [ 0.00018197]; G_loss: [ 4.45497322]\n",
      "Iter-2560; D_loss: [ 0.00019273]; G_loss: [ 4.45578909]\n",
      "Iter-2816; D_loss: [ 0.00017776]; G_loss: [ 4.45660973]\n",
      "Iter-3072; D_loss: [ 0.00018057]; G_loss: [ 4.45742607]\n",
      "Iter-3328; D_loss: [ 0.00017769]; G_loss: [ 4.45826578]\n",
      "Iter-3584; D_loss: [ 0.00017961]; G_loss: [ 4.45910931]\n",
      "epoch: 92\n",
      "Iter-0; D_loss: [ 0.00017821]; G_loss: [ 4.4599247]\n",
      "Iter-256; D_loss: [ 0.00017965]; G_loss: [ 4.4607234]\n",
      "Iter-512; D_loss: [ 0.00017942]; G_loss: [ 4.4615531]\n",
      "Iter-768; D_loss: [ 0.00017672]; G_loss: [ 4.46236372]\n",
      "Iter-1024; D_loss: [ 0.00017559]; G_loss: [ 4.46319103]\n",
      "Iter-1280; D_loss: [ 0.0001799]; G_loss: [ 4.46400547]\n",
      "Iter-1536; D_loss: [ 0.00017651]; G_loss: [ 4.46481562]\n",
      "Iter-1792; D_loss: [ 0.00017348]; G_loss: [ 4.4656415]\n",
      "Iter-2048; D_loss: [ 0.00019747]; G_loss: [ 4.46645117]\n",
      "Iter-2304; D_loss: [ 0.00017762]; G_loss: [ 4.46724701]\n",
      "Iter-2560; D_loss: [ 0.00018814]; G_loss: [ 4.46805096]\n",
      "Iter-2816; D_loss: [ 0.00017353]; G_loss: [ 4.46888161]\n",
      "Iter-3072; D_loss: [ 0.00017628]; G_loss: [ 4.46969032]\n",
      "Iter-3328; D_loss: [ 0.00017345]; G_loss: [ 4.47051573]\n",
      "Iter-3584; D_loss: [ 0.00017536]; G_loss: [ 4.47133017]\n",
      "epoch: 93\n",
      "Iter-0; D_loss: [ 0.00017397]; G_loss: [ 4.47214174]\n",
      "Iter-256; D_loss: [ 0.00017538]; G_loss: [ 4.47295856]\n",
      "Iter-512; D_loss: [ 0.00017515]; G_loss: [ 4.47376728]\n",
      "Iter-768; D_loss: [ 0.00017253]; G_loss: [ 4.47457266]\n",
      "Iter-1024; D_loss: [ 0.00017143]; G_loss: [ 4.47536707]\n",
      "Iter-1280; D_loss: [ 0.00017564]; G_loss: [ 4.47620249]\n",
      "Iter-1536; D_loss: [ 0.00017235]; G_loss: [ 4.47699594]\n",
      "Iter-1792; D_loss: [ 0.00016936]; G_loss: [ 4.47780657]\n",
      "Iter-2048; D_loss: [ 0.00019283]; G_loss: [ 4.47860956]\n",
      "Iter-2304; D_loss: [ 0.00017341]; G_loss: [ 4.47939634]\n",
      "Iter-2560; D_loss: [ 0.00018369]; G_loss: [ 4.48020458]\n",
      "Iter-2816; D_loss: [ 0.00016943]; G_loss: [ 4.48101377]\n",
      "Iter-3072; D_loss: [ 0.00017213]; G_loss: [ 4.48182774]\n",
      "Iter-3328; D_loss: [ 0.00016936]; G_loss: [ 4.48263597]\n",
      "Iter-3584; D_loss: [ 0.00017125]; G_loss: [ 4.48345566]\n",
      "epoch: 94\n",
      "Iter-0; D_loss: [ 0.00016986]; G_loss: [ 4.48426867]\n",
      "Iter-256; D_loss: [ 0.00017125]; G_loss: [ 4.48505592]\n",
      "Iter-512; D_loss: [ 0.00017102]; G_loss: [ 4.4858551]\n",
      "Iter-768; D_loss: [ 0.00016849]; G_loss: [ 4.4866581]\n",
      "Iter-1024; D_loss: [ 0.00016739]; G_loss: [ 4.48745155]\n",
      "Iter-1280; D_loss: [ 0.00017152]; G_loss: [ 4.48825455]\n",
      "Iter-1536; D_loss: [ 0.00016832]; G_loss: [ 4.48907232]\n",
      "Iter-1792; D_loss: [ 0.00016536]; G_loss: [ 4.48987818]\n",
      "Iter-2048; D_loss: [ 0.00018833]; G_loss: [ 4.49066591]\n",
      "Iter-2304; D_loss: [ 0.00016935]; G_loss: [ 4.49145794]\n",
      "Iter-2560; D_loss: [ 0.0001794]; G_loss: [ 4.49224997]\n",
      "Iter-2816; D_loss: [ 0.00016547]; G_loss: [ 4.49305105]\n",
      "Iter-3072; D_loss: [ 0.00016812]; G_loss: [ 4.49384308]\n",
      "Iter-3328; D_loss: [ 0.0001654]; G_loss: [ 4.49464369]\n",
      "Iter-3584; D_loss: [ 0.00016728]; G_loss: [ 4.49545527]\n",
      "epoch: 95\n",
      "Iter-0; D_loss: [ 0.0001659]; G_loss: [ 4.49624252]\n",
      "Iter-256; D_loss: [ 0.00016726]; G_loss: [ 4.49704552]\n",
      "Iter-512; D_loss: [ 0.00016703]; G_loss: [ 4.49782896]\n",
      "Iter-768; D_loss: [ 0.00016457]; G_loss: [ 4.49863052]\n",
      "Iter-1024; D_loss: [ 0.00016348]; G_loss: [ 4.49941492]\n",
      "Iter-1280; D_loss: [ 0.00016754]; G_loss: [ 4.50021648]\n",
      "Iter-1536; D_loss: [ 0.00016441]; G_loss: [ 4.50100422]\n",
      "Iter-1792; D_loss: [ 0.0001615]; G_loss: [ 4.50180292]\n",
      "Iter-2048; D_loss: [ 0.00018398]; G_loss: [ 4.5025878]\n",
      "Iter-2304; D_loss: [ 0.00016542]; G_loss: [ 4.50337934]\n",
      "Iter-2560; D_loss: [ 0.00017526]; G_loss: [ 4.50417042]\n",
      "Iter-2816; D_loss: [ 0.00016164]; G_loss: [ 4.50496197]\n",
      "Iter-3072; D_loss: [ 0.00016423]; G_loss: [ 4.50575161]\n",
      "Iter-3328; D_loss: [ 0.00016158]; G_loss: [ 4.50654936]\n",
      "Iter-3584; D_loss: [ 0.00016343]; G_loss: [ 4.50734186]\n",
      "epoch: 96\n",
      "Iter-0; D_loss: [ 0.00016206]; G_loss: [ 4.50813913]\n",
      "Iter-256; D_loss: [ 0.0001634]; G_loss: [ 4.50892353]\n",
      "Iter-512; D_loss: [ 0.00016317]; G_loss: [ 4.50970268]\n",
      "Iter-768; D_loss: [ 0.00016078]; G_loss: [ 4.51050186]\n",
      "Iter-1024; D_loss: [ 0.00015971]; G_loss: [ 4.51128578]\n",
      "Iter-1280; D_loss: [ 0.00016368]; G_loss: [ 4.51208639]\n",
      "Iter-1536; D_loss: [ 0.00016064]; G_loss: [ 4.51284313]\n",
      "Iter-1792; D_loss: [ 0.00015777]; G_loss: [ 4.51363373]\n",
      "Iter-2048; D_loss: [ 0.00017977]; G_loss: [ 4.51442432]\n",
      "Iter-2304; D_loss: [ 0.00016162]; G_loss: [ 4.51519537]\n",
      "Iter-2560; D_loss: [ 0.00017123]; G_loss: [ 4.51597071]\n",
      "Iter-2816; D_loss: [ 0.00015793]; G_loss: [ 4.51674557]\n",
      "Iter-3072; D_loss: [ 0.00016048]; G_loss: [ 4.51754093]\n",
      "Iter-3328; D_loss: [ 0.00015786]; G_loss: [ 4.51832485]\n",
      "Iter-3584; D_loss: [ 0.00015971]; G_loss: [ 4.51912642]\n",
      "epoch: 97\n",
      "Iter-0; D_loss: [ 0.00015835]; G_loss: [ 4.51991129]\n",
      "Iter-256; D_loss: [ 0.00015966]; G_loss: [ 4.5206871]\n",
      "Iter-512; D_loss: [ 0.00015943]; G_loss: [ 4.5214591]\n",
      "Iter-768; D_loss: [ 0.0001571]; G_loss: [ 4.52223396]\n",
      "Iter-1024; D_loss: [ 0.00015605]; G_loss: [ 4.5230155]\n",
      "Iter-1280; D_loss: [ 0.00015995]; G_loss: [ 4.52381611]\n",
      "Iter-1536; D_loss: [ 0.00015698]; G_loss: [ 4.52459145]\n",
      "Iter-1792; D_loss: [ 0.00015415]; G_loss: [ 4.52535963]\n",
      "Iter-2048; D_loss: [ 0.00017569]; G_loss: [ 4.5261426]\n",
      "Iter-2304; D_loss: [ 0.00015793]; G_loss: [ 4.52691031]\n",
      "Iter-2560; D_loss: [ 0.00016734]; G_loss: [ 4.52767944]\n",
      "Iter-2816; D_loss: [ 0.00015434]; G_loss: [ 4.5284524]\n",
      "Iter-3072; D_loss: [ 0.00015684]; G_loss: [ 4.52923822]\n",
      "Iter-3328; D_loss: [ 0.00015428]; G_loss: [ 4.5300293]\n",
      "Iter-3584; D_loss: [ 0.00015611]; G_loss: [ 4.53078699]\n",
      "epoch: 98\n",
      "Iter-0; D_loss: [ 0.00015476]; G_loss: [ 4.53157711]\n",
      "Iter-256; D_loss: [ 0.00015604]; G_loss: [ 4.53235197]\n",
      "Iter-512; D_loss: [ 0.00015581]; G_loss: [ 4.53309917]\n",
      "Iter-768; D_loss: [ 0.00015355]; G_loss: [ 4.53389597]\n",
      "Iter-1024; D_loss: [ 0.00015251]; G_loss: [ 4.53466988]\n",
      "Iter-1280; D_loss: [ 0.00015633]; G_loss: [ 4.53542614]\n",
      "Iter-1536; D_loss: [ 0.00015345]; G_loss: [ 4.53621626]\n",
      "Iter-1792; D_loss: [ 0.00015065]; G_loss: [ 4.53698587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2048; D_loss: [ 0.00017174]; G_loss: [ 4.53774214]\n",
      "Iter-2304; D_loss: [ 0.00015436]; G_loss: [ 4.53850698]\n",
      "Iter-2560; D_loss: [ 0.00016357]; G_loss: [ 4.53927612]\n",
      "Iter-2816; D_loss: [ 0.00015087]; G_loss: [ 4.54004717]\n",
      "Iter-3072; D_loss: [ 0.00015331]; G_loss: [ 4.54079485]\n",
      "Iter-3328; D_loss: [ 0.0001508]; G_loss: [ 4.5415864]\n",
      "Iter-3584; D_loss: [ 0.00015261]; G_loss: [ 4.5423708]\n",
      "epoch: 99\n",
      "Iter-0; D_loss: [ 0.00015127]; G_loss: [ 4.54314518]\n",
      "Iter-256; D_loss: [ 0.00015254]; G_loss: [ 4.54388952]\n",
      "Iter-512; D_loss: [ 0.00015231]; G_loss: [ 4.54465199]\n",
      "Iter-768; D_loss: [ 0.00015011]; G_loss: [ 4.54542255]\n",
      "Iter-1024; D_loss: [ 0.00014907]; G_loss: [ 4.54619789]\n",
      "Iter-1280; D_loss: [ 0.00015283]; G_loss: [ 4.54696131]\n",
      "Iter-1536; D_loss: [ 0.00015002]; G_loss: [ 4.54773283]\n",
      "Iter-1792; D_loss: [ 0.00014725]; G_loss: [ 4.5484767]\n",
      "Iter-2048; D_loss: [ 0.00016791]; G_loss: [ 4.54922867]\n",
      "Iter-2304; D_loss: [ 0.00015091]; G_loss: [ 4.54999352]\n",
      "Iter-2560; D_loss: [ 0.00015992]; G_loss: [ 4.55075979]\n",
      "Iter-2816; D_loss: [ 0.0001475]; G_loss: [ 4.55152416]\n",
      "Iter-3072; D_loss: [ 0.0001499]; G_loss: [ 4.5522995]\n",
      "Iter-3328; D_loss: [ 0.00014744]; G_loss: [ 4.55305862]\n",
      "Iter-3584; D_loss: [ 0.00014923]; G_loss: [ 4.55383539]\n"
     ]
    }
   ],
   "source": [
    "batch_size = mb_size\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    while it+batch_size < len(X_train) :\n",
    "        \n",
    "\n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        X = X_train[start:end]\n",
    "\n",
    "        #c = Y_train[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        #c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z, X)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        D_loss_real = binary_cross_entropy(D_real, ones_label)\n",
    "        D_loss_fake = binary_cross_entropy(D_fake, zeros_label)\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        D.zero_grad()\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        G_sample = G(z, X)\n",
    "        X_fake = torch.cat([G_sample, X], 0)\n",
    "        D_fake = D(X_fake) #Here we need to give Xi along with Xg(i.e. Xg+X or G_sample+X)\n",
    "\n",
    "        G_loss = binary_cross_entropy(D_fake, ones_label_fake)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        D.zero_grad()\n",
    "\n",
    "        #Print and plot every now and then\n",
    "        #if it % 2 == 0:\n",
    "\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "        it+= batch_size\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF=pd.DataFrame()\n",
    "samples_per_class = 1000\n",
    "#c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "#c[:, np.random.randint(0, 10)] = 1.\n",
    "for i in range(14):\n",
    "    #print(i)\n",
    "    c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "    c[:, i] = 1.\n",
    "    c_df=pd.DataFrame(c)\n",
    "    df_SF = df_SF.append(c_df,ignore_index = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = df_SF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen = Variable(torch.randn(df_SF.shape[0], Z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = Variable(torch.from_numpy(c_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G(z_gen, c_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = samples.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = c_gen.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = pd.DataFrame(train_X1)\n",
    "train_y1 = pd.DataFrame(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train.append(train_X1, ignore_index=True)\n",
    "train_y = Y_train.append(train_y1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X,  train_y = shuffle(train_X, train_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.values\n",
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch=30"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Checking Baseline Accuracy with only training data\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Baseline ERROR %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#train_X1 and train_y1 are the augmented data alone to check accuracy only on augmented data \n",
    "#feed the model.fit only with these\n",
    "train_X1 = train_X1.values\n",
    "train_y1 = train_y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Accuracy with training+augmented data train_X and train_y are 'train + augmented' data\n",
    "history = model.fit(train_X, train_y, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frame label accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('ERROR after Data Augmentation %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
