{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/train_feat_BNF_h5_07Nov_Shreyas.csv')\n",
    "#train_afds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lre = train_lre.iloc[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>ids</th>\n",
       "      <th>year</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.639420</td>\n",
       "      <td>0.345687</td>\n",
       "      <td>-0.517642</td>\n",
       "      <td>-0.736995</td>\n",
       "      <td>1.313009</td>\n",
       "      <td>1.655726</td>\n",
       "      <td>0.615175</td>\n",
       "      <td>0.799342</td>\n",
       "      <td>1.648420</td>\n",
       "      <td>1.314984</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.216082</td>\n",
       "      <td>-1.322349</td>\n",
       "      <td>-0.716935</td>\n",
       "      <td>-3.843975</td>\n",
       "      <td>-1.471226</td>\n",
       "      <td>0.945404</td>\n",
       "      <td>zkllk</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>spa-car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113609</td>\n",
       "      <td>0.738035</td>\n",
       "      <td>0.584858</td>\n",
       "      <td>-0.248514</td>\n",
       "      <td>0.256618</td>\n",
       "      <td>1.060176</td>\n",
       "      <td>-0.416205</td>\n",
       "      <td>0.133669</td>\n",
       "      <td>0.188325</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082178</td>\n",
       "      <td>1.965844</td>\n",
       "      <td>3.525489</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>1.676278</td>\n",
       "      <td>-1.116285</td>\n",
       "      <td>lid05e1_lid00562</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>ara-apc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.061305</td>\n",
       "      <td>-0.140602</td>\n",
       "      <td>-0.627102</td>\n",
       "      <td>-0.682902</td>\n",
       "      <td>1.337618</td>\n",
       "      <td>1.261542</td>\n",
       "      <td>-0.651286</td>\n",
       "      <td>0.307042</td>\n",
       "      <td>-0.980716</td>\n",
       "      <td>0.335533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996222</td>\n",
       "      <td>-3.018732</td>\n",
       "      <td>-1.841219</td>\n",
       "      <td>0.814874</td>\n",
       "      <td>-0.200840</td>\n",
       "      <td>1.180867</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>spa-car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.958050</td>\n",
       "      <td>-0.608313</td>\n",
       "      <td>-0.113530</td>\n",
       "      <td>0.167277</td>\n",
       "      <td>0.911105</td>\n",
       "      <td>1.116085</td>\n",
       "      <td>-0.847208</td>\n",
       "      <td>-0.041355</td>\n",
       "      <td>-0.542331</td>\n",
       "      <td>0.199113</td>\n",
       "      <td>...</td>\n",
       "      <td>1.487050</td>\n",
       "      <td>-0.549122</td>\n",
       "      <td>-1.254462</td>\n",
       "      <td>1.644782</td>\n",
       "      <td>0.555329</td>\n",
       "      <td>1.159080</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>spa-car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.842435</td>\n",
       "      <td>-0.417594</td>\n",
       "      <td>-0.427426</td>\n",
       "      <td>-0.485892</td>\n",
       "      <td>1.204338</td>\n",
       "      <td>1.439185</td>\n",
       "      <td>-1.056640</td>\n",
       "      <td>0.111603</td>\n",
       "      <td>-0.404314</td>\n",
       "      <td>-0.307069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712544</td>\n",
       "      <td>0.296827</td>\n",
       "      <td>-1.858668</td>\n",
       "      <td>0.209770</td>\n",
       "      <td>0.583769</td>\n",
       "      <td>1.398776</td>\n",
       "      <td>fla_0240-a</td>\n",
       "      <td>LDC2017E22</td>\n",
       "      <td>data</td>\n",
       "      <td>spa-car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 504 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.639420  0.345687 -0.517642 -0.736995  1.313009  1.655726  0.615175   \n",
       "1  0.113609  0.738035  0.584858 -0.248514  0.256618  1.060176 -0.416205   \n",
       "2  2.061305 -0.140602 -0.627102 -0.682902  1.337618  1.261542 -0.651286   \n",
       "3  1.958050 -0.608313 -0.113530  0.167277  0.911105  1.116085 -0.847208   \n",
       "4  1.842435 -0.417594 -0.427426 -0.485892  1.204338  1.439185 -1.056640   \n",
       "\n",
       "          7         8         9   ...          494       495       496  \\\n",
       "0  0.799342  1.648420  1.314984   ...    -2.216082 -1.322349 -0.716935   \n",
       "1  0.133669  0.188325  0.805241   ...    -0.082178  1.965844  3.525489   \n",
       "2  0.307042 -0.980716  0.335533   ...     0.996222 -3.018732 -1.841219   \n",
       "3 -0.041355 -0.542331  0.199113   ...     1.487050 -0.549122 -1.254462   \n",
       "4  0.111603 -0.404314 -0.307069   ...     0.712544  0.296827 -1.858668   \n",
       "\n",
       "        497       498       499               ids        year  data     lang  \n",
       "0 -3.843975 -1.471226  0.945404             zkllk  LDC2017E22  data  spa-car  \n",
       "1  0.006793  1.676278 -1.116285  lid05e1_lid00562  LDC2017E22  data  ara-apc  \n",
       "2  0.814874 -0.200840  1.180867        fla_0240-a  LDC2017E22  data  spa-car  \n",
       "3  1.644782  0.555329  1.159080        fla_0240-a  LDC2017E22  data  spa-car  \n",
       "4  0.209770  0.583769  1.398776        fla_0240-a  LDC2017E22  data  spa-car  \n",
       "\n",
       "[5 rows x 504 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'langid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f90ffd517c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_lre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'langid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/lre17/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   5160\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   5161\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5162\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   5163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5164\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[0;32m~/miniconda3/envs/lre17/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1757\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lre17/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lre17/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated, validate)\u001b[0m\n\u001b[1;32m   2840\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2843\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'langid'"
     ]
    }
   ],
   "source": [
    "train_lre.groupby(['langid']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a single class\n",
    "train_lre = train_lre.loc[train_lre['langid'] == 'ara-apc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lre = pd.read_csv('/home/satishk/lre2.0/ivectors_csv_revised/dev_feat_BNF_h5_07Nov_Shreyas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_lre = val_lre.iloc[100:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmentid</th>\n",
       "      <th>language_code</th>\n",
       "      <th>data_source</th>\n",
       "      <th>speech_duration</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>uttid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lre17_ntrlosgu.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.697234</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>-0.400756</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>-0.939232</td>\n",
       "      <td>1.500797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.314428</td>\n",
       "      <td>-0.927694</td>\n",
       "      <td>-0.370424</td>\n",
       "      <td>-0.514735</td>\n",
       "      <td>1.290885</td>\n",
       "      <td>0.688205</td>\n",
       "      <td>-0.494330</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>-1.330860</td>\n",
       "      <td>lre17_ntrlosgu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lre17_moxnwuqe.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.648232</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>-0.562867</td>\n",
       "      <td>1.035870</td>\n",
       "      <td>-1.577741</td>\n",
       "      <td>1.593584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929262</td>\n",
       "      <td>-1.301574</td>\n",
       "      <td>2.034934</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>-0.198926</td>\n",
       "      <td>-0.116174</td>\n",
       "      <td>0.347923</td>\n",
       "      <td>-0.870801</td>\n",
       "      <td>-2.599601</td>\n",
       "      <td>lre17_moxnwuqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lre17_meesvkxz.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242829</td>\n",
       "      <td>0.675515</td>\n",
       "      <td>-0.371491</td>\n",
       "      <td>0.534970</td>\n",
       "      <td>-0.246783</td>\n",
       "      <td>0.806262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691336</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>1.058771</td>\n",
       "      <td>1.018635</td>\n",
       "      <td>-1.929319</td>\n",
       "      <td>-0.307404</td>\n",
       "      <td>-0.486431</td>\n",
       "      <td>-2.839053</td>\n",
       "      <td>-2.704527</td>\n",
       "      <td>lre17_meesvkxz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lre17_rqmsmzui.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>30</td>\n",
       "      <td>1.226681</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>-0.396915</td>\n",
       "      <td>-0.097507</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>1.087025</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049862</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>2.385587</td>\n",
       "      <td>0.680073</td>\n",
       "      <td>1.500978</td>\n",
       "      <td>1.660566</td>\n",
       "      <td>-0.370672</td>\n",
       "      <td>-0.924109</td>\n",
       "      <td>0.096676</td>\n",
       "      <td>lre17_rqmsmzui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lre17_qgszpuyw.sph</td>\n",
       "      <td>ara-acm</td>\n",
       "      <td>mls14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.411728</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>0.136256</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>-1.029447</td>\n",
       "      <td>1.227100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>-1.030222</td>\n",
       "      <td>2.933880</td>\n",
       "      <td>-1.417872</td>\n",
       "      <td>-0.227513</td>\n",
       "      <td>0.748810</td>\n",
       "      <td>-0.671044</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>1.722917</td>\n",
       "      <td>lre17_qgszpuyw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            segmentid language_code data_source  speech_duration         0  \\\n",
       "0  lre17_ntrlosgu.sph       ara-acm       mls14               30  1.697234   \n",
       "1  lre17_moxnwuqe.sph       ara-acm       mls14               10  1.648232   \n",
       "2  lre17_meesvkxz.sph       ara-acm       mls14                3  1.242829   \n",
       "3  lre17_rqmsmzui.sph       ara-acm       mls14               30  1.226681   \n",
       "4  lre17_qgszpuyw.sph       ara-acm       mls14               10  1.411728   \n",
       "\n",
       "          1         2         3         4         5       ...             491  \\\n",
       "0  0.029428 -0.400756  0.513963 -0.939232  1.500797       ...       -1.314428   \n",
       "1 -0.053318 -0.562867  1.035870 -1.577741  1.593584       ...       -0.929262   \n",
       "2  0.675515 -0.371491  0.534970 -0.246783  0.806262       ...        0.691336   \n",
       "3  0.014810 -0.396915 -0.097507 -0.013574  1.087025       ...        1.049862   \n",
       "4 -0.119300  0.136256  0.030535 -1.029447  1.227100       ...        0.155196   \n",
       "\n",
       "        492       493       494       495       496       497       498  \\\n",
       "0 -0.927694 -0.370424 -0.514735  1.290885  0.688205 -0.494330 -0.053206   \n",
       "1 -1.301574  2.034934 -0.226545 -0.198926 -0.116174  0.347923 -0.870801   \n",
       "2  0.257988  1.058771  1.018635 -1.929319 -0.307404 -0.486431 -2.839053   \n",
       "3  0.285627  2.385587  0.680073  1.500978  1.660566 -0.370672 -0.924109   \n",
       "4 -1.030222  2.933880 -1.417872 -0.227513  0.748810 -0.671044  0.595977   \n",
       "\n",
       "        499           uttid  \n",
       "0 -1.330860  lre17_ntrlosgu  \n",
       "1 -2.599601  lre17_moxnwuqe  \n",
       "2 -2.704527  lre17_meesvkxz  \n",
       "3  0.096676  lre17_rqmsmzui  \n",
       "4  1.722917  lre17_qgszpuyw  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_lre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_lre.drop(\"langid\",axis=1)\n",
    "y_train = train_lre[\"langid\"]\n",
    "#y_train_uttid = train_lre[\"uttid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_lre.drop([\"language_code\",\"uttid\",\"segmentid\",\"data_source\",\"speech_duration\"],axis=1)\n",
    "y_val = val_lre[\"language_code\"]\n",
    "y_val_segmentid = val_lre[\"segmentid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val, ignore_index=True)\n",
    "y_train = y_train.append(y_val, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ara-acm', 'ara-apc', 'ara-ary', 'ara-arz', 'eng-gbr', 'eng-usg',\n",
       "       'por-brz', 'qsl-pol', 'qsl-rus', 'spa-car', 'spa-eur', 'spa-lac',\n",
       "       'zho-cmn', 'zho-nan'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_labels = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_val=X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = indices_to_one_hot(y_train, 14)\n",
    "#Y_test = indices_to_one_hot(y_test, 14)\n",
    "Y_val = indices_to_one_hot(y_val_labels, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 14)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3661, 500)\n",
      "3661 train samples\n",
      "3661 val samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "#X_val /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "#print(X_test.shape[0], 'test samples')\n",
    "print(X_val.shape[0], 'val samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 500)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 500)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 13, 13, 13])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Shuffling the dataset\n",
    "#from sklearn.utils import shuffle\n",
    "#X_train,  y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val,  y_val_labels = shuffle(X_val, y_val_labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets('/home/satishk/depy_04_AUG/MNIST_data', one_hot=True)\n",
    "mb_size = 256\n",
    "Z_dim = 100\n",
    "X_dim = 500 #mnist.train.images.shape[1]\n",
    "y_dim = 14 #mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 14)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dim, y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Generator as Encoder-Decoder pair inspired from DAGAN base paper\n",
    "\n",
    "#Encoder should be able to take a batch of input(of dim 500-ivector) and be able to produce its representation r\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(500, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        #self.fc3 = nn.Linear(256, 128)\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "    \n",
    "#We will use Decoder as Generator    \n",
    "#Decoder should be able to take input of dim 128(r) and 100(z),concatenate r and z and \n",
    "#produce an output od dim 500-ivector    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(228,256 )\n",
    "        self.fc2 = nn.Linear(256, 500)\n",
    "        #self.fc3 = nn.Linear(512,500)\n",
    "    def forward(self, x):\n",
    "        #inputs = torch.cat([z, x], 1)\n",
    "        return F.sigmoid(self.fc2(F.relu(self.fc1(x))))\n",
    "\n",
    "#input to Generator alias Decoder is inputs = torch.cat([z, r], 1)\n",
    "#Where r is the output of encoder given x i.e., representation of x encoded by encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we defined the Encoder and Decoder we now Implement the Generator \n",
    "\n",
    "class Generator(nn.Module):\n",
    "                                \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = Encoder()\n",
    "        self.fc2 = Decoder()\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        #inputs = torch.cat([z, x], 1)\n",
    "        return self.fc2(torch.cat([z, self.fc1(x)],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #self.inputs = torch.cat([z, c], 1)\n",
    "        self.fc1 = torch.nn.Linear(500, 128)\n",
    "        self.fc2 = torch.nn.Linear(128,1)\n",
    "        #self.fc3 = torch.nn.Linear(512,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #inputs = torch.cat([X, c], 1)\n",
    "        return F.sigmoid(self.fc2(F.relu(self.fc1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of Generator(\n",
       "  (fc1): Encoder(\n",
       "    (fc1): Linear(in_features=500, out_features=256)\n",
       "    (fc2): Linear(in_features=256, out_features=128)\n",
       "  )\n",
       "  (fc2): Decoder(\n",
       "    (fc1): Linear(in_features=228, out_features=256)\n",
       "    (fc2): Linear(in_features=256, out_features=500)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (fc1): Linear(in_features=500, out_features=128)\n",
       "  (fc2): Linear(in_features=128, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))\n",
    "ones_label_fake = Variable(torch.ones(mb_size*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "#criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=betas)\n",
    "D_solver = torch.optim.Adam(D.parameters(), lr=learning_rate/2, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter-0; D_loss: [ 1.33553648]; G_loss: [ 0.77732545]\n",
      "Iter-256; D_loss: [ 1.30169368]; G_loss: [ 0.79999554]\n",
      "Iter-512; D_loss: [ 1.25585699]; G_loss: [ 0.81402481]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satishk/miniconda3/envs/lre17/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/home/satishk/miniconda3/envs/lre17/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-768; D_loss: [ 1.21911371]; G_loss: [ 0.83304316]\n",
      "Iter-1024; D_loss: [ 1.18639708]; G_loss: [ 0.85274649]\n",
      "Iter-1280; D_loss: [ 1.15183926]; G_loss: [ 0.87091476]\n",
      "Iter-1536; D_loss: [ 1.13988137]; G_loss: [ 0.89904022]\n",
      "Iter-1792; D_loss: [ 1.11011243]; G_loss: [ 0.91700333]\n",
      "Iter-2048; D_loss: [ 1.07049179]; G_loss: [ 0.92865592]\n",
      "Iter-2304; D_loss: [ 1.04459429]; G_loss: [ 0.94536954]\n",
      "Iter-2560; D_loss: [ 1.03965414]; G_loss: [ 0.97067028]\n",
      "epoch: 1\n",
      "Iter-0; D_loss: [ 0.99649155]; G_loss: [ 0.9735446]\n",
      "Iter-256; D_loss: [ 0.99191022]; G_loss: [ 0.99387091]\n",
      "Iter-512; D_loss: [ 0.95859206]; G_loss: [ 0.99629956]\n",
      "Iter-768; D_loss: [ 0.94454336]; G_loss: [ 1.00704563]\n",
      "Iter-1024; D_loss: [ 0.93085539]; G_loss: [ 1.01571858]\n",
      "Iter-1280; D_loss: [ 0.9162668]; G_loss: [ 1.02276421]\n",
      "Iter-1536; D_loss: [ 0.91940081]; G_loss: [ 1.03694785]\n",
      "Iter-1792; D_loss: [ 0.90667689]; G_loss: [ 1.04288018]\n",
      "Iter-2048; D_loss: [ 0.88289022]; G_loss: [ 1.04274213]\n",
      "Iter-2304; D_loss: [ 0.8728236]; G_loss: [ 1.04896605]\n",
      "Iter-2560; D_loss: [ 0.87798691]; G_loss: [ 1.0616895]\n",
      "epoch: 2\n",
      "Iter-0; D_loss: [ 0.84317297]; G_loss: [ 1.05434012]\n",
      "Iter-256; D_loss: [ 0.8540405]; G_loss: [ 1.06989264]\n",
      "Iter-512; D_loss: [ 0.82016957]; G_loss: [ 1.06223869]\n",
      "Iter-768; D_loss: [ 0.81398833]; G_loss: [ 1.06836152]\n",
      "Iter-1024; D_loss: [ 0.80550408]; G_loss: [ 1.07265234]\n",
      "Iter-1280; D_loss: [ 0.79692698]; G_loss: [ 1.0758338]\n",
      "Iter-1536; D_loss: [ 0.80145001]; G_loss: [ 1.08348382]\n",
      "Iter-1792; D_loss: [ 0.79479599]; G_loss: [ 1.08386505]\n",
      "Iter-2048; D_loss: [ 0.77665204]; G_loss: [ 1.07680058]\n",
      "Iter-2304; D_loss: [ 0.77478909]; G_loss: [ 1.07614744]\n",
      "Iter-2560; D_loss: [ 0.78586459]; G_loss: [ 1.07348454]\n",
      "epoch: 3\n",
      "Iter-0; D_loss: [ 0.76032174]; G_loss: [ 1.04783285]\n",
      "Iter-256; D_loss: [ 0.7888006]; G_loss: [ 1.04735672]\n",
      "Iter-512; D_loss: [ 0.76678938]; G_loss: [ 1.00807917]\n",
      "Iter-768; D_loss: [ 0.78486466]; G_loss: [ 0.97943199]\n",
      "Iter-1024; D_loss: [ 0.80288249]; G_loss: [ 0.94637209]\n",
      "Iter-1280; D_loss: [ 0.82539511]; G_loss: [ 0.91038847]\n",
      "Iter-1536; D_loss: [ 0.87080204]; G_loss: [ 0.86485952]\n",
      "Iter-1792; D_loss: [ 0.9063307]; G_loss: [ 0.82543665]\n",
      "Iter-2048; D_loss: [ 0.92888713]; G_loss: [ 0.77873868]\n",
      "Iter-2304; D_loss: [ 0.959746]; G_loss: [ 0.75401551]\n",
      "Iter-2560; D_loss: [ 0.99704146]; G_loss: [ 0.73198563]\n",
      "epoch: 4\n",
      "Iter-0; D_loss: [ 0.98061192]; G_loss: [ 0.70090747]\n",
      "Iter-256; D_loss: [ 1.00538647]; G_loss: [ 0.7165004]\n",
      "Iter-512; D_loss: [ 0.97461921]; G_loss: [ 0.68760347]\n",
      "Iter-768; D_loss: [ 0.96536529]; G_loss: [ 0.69703877]\n",
      "Iter-1024; D_loss: [ 0.94919413]; G_loss: [ 0.70443386]\n",
      "Iter-1280; D_loss: [ 0.92939723]; G_loss: [ 0.71774298]\n",
      "Iter-1536; D_loss: [ 0.91500497]; G_loss: [ 0.73217154]\n",
      "Iter-1792; D_loss: [ 0.89063185]; G_loss: [ 0.74978626]\n",
      "Iter-2048; D_loss: [ 0.85707992]; G_loss: [ 0.75893235]\n",
      "Iter-2304; D_loss: [ 0.8360216]; G_loss: [ 0.77886957]\n",
      "Iter-2560; D_loss: [ 0.82664633]; G_loss: [ 0.80140609]\n",
      "epoch: 5\n",
      "Iter-0; D_loss: [ 0.77568591]; G_loss: [ 0.8038376]\n",
      "Iter-256; D_loss: [ 0.79179364]; G_loss: [ 0.83856291]\n",
      "Iter-512; D_loss: [ 0.73366904]; G_loss: [ 0.83214647]\n",
      "Iter-768; D_loss: [ 0.7253719]; G_loss: [ 0.84920967]\n",
      "Iter-1024; D_loss: [ 0.71409142]; G_loss: [ 0.86051786]\n",
      "Iter-1280; D_loss: [ 0.70712388]; G_loss: [ 0.87019992]\n",
      "Iter-1536; D_loss: [ 0.70222741]; G_loss: [ 0.87639689]\n",
      "Iter-1792; D_loss: [ 0.69746292]; G_loss: [ 0.88044846]\n",
      "Iter-2048; D_loss: [ 0.68044138]; G_loss: [ 0.87597907]\n",
      "Iter-2304; D_loss: [ 0.67865467]; G_loss: [ 0.87804955]\n",
      "Iter-2560; D_loss: [ 0.68571782]; G_loss: [ 0.88423198]\n",
      "epoch: 6\n",
      "Iter-0; D_loss: [ 0.65144396]; G_loss: [ 0.87038189]\n",
      "Iter-256; D_loss: [ 0.684807]; G_loss: [ 0.89073074]\n",
      "Iter-512; D_loss: [ 0.6367386]; G_loss: [ 0.86918342]\n",
      "Iter-768; D_loss: [ 0.64052898]; G_loss: [ 0.87450504]\n",
      "Iter-1024; D_loss: [ 0.63873625]; G_loss: [ 0.87690419]\n",
      "Iter-1280; D_loss: [ 0.638708]; G_loss: [ 0.87998962]\n",
      "Iter-1536; D_loss: [ 0.63563383]; G_loss: [ 0.88074094]\n",
      "Iter-1792; D_loss: [ 0.63513672]; G_loss: [ 0.88211787]\n",
      "Iter-2048; D_loss: [ 0.62035167]; G_loss: [ 0.87560827]\n",
      "Iter-2304; D_loss: [ 0.61938393]; G_loss: [ 0.87636846]\n",
      "Iter-2560; D_loss: [ 0.62728095]; G_loss: [ 0.88190728]\n",
      "epoch: 7\n",
      "Iter-0; D_loss: [ 0.59450352]; G_loss: [ 0.86881864]\n",
      "Iter-256; D_loss: [ 0.62869239]; G_loss: [ 0.89001858]\n",
      "Iter-512; D_loss: [ 0.57895184]; G_loss: [ 0.87050217]\n",
      "Iter-768; D_loss: [ 0.58280969]; G_loss: [ 0.87855369]\n",
      "Iter-1024; D_loss: [ 0.58116269]; G_loss: [ 0.88351327]\n",
      "Iter-1280; D_loss: [ 0.58177292]; G_loss: [ 0.88900846]\n",
      "Iter-1536; D_loss: [ 0.57607973]; G_loss: [ 0.89099032]\n",
      "Iter-1792; D_loss: [ 0.57539797]; G_loss: [ 0.89503652]\n",
      "Iter-2048; D_loss: [ 0.55987453]; G_loss: [ 0.8902325]\n",
      "Iter-2304; D_loss: [ 0.55830336]; G_loss: [ 0.89154339]\n",
      "Iter-2560; D_loss: [ 0.56629014]; G_loss: [ 0.89765173]\n",
      "epoch: 8\n",
      "Iter-0; D_loss: [ 0.53559625]; G_loss: [ 0.88507491]\n",
      "Iter-256; D_loss: [ 0.57152224]; G_loss: [ 0.90425879]\n",
      "Iter-512; D_loss: [ 0.52571189]; G_loss: [ 0.88065231]\n",
      "Iter-768; D_loss: [ 0.5334745]; G_loss: [ 0.88405788]\n",
      "Iter-1024; D_loss: [ 0.53360003]; G_loss: [ 0.88786072]\n",
      "Iter-1280; D_loss: [ 0.53382874]; G_loss: [ 0.89717144]\n",
      "Iter-1536; D_loss: [ 0.52411592]; G_loss: [ 0.90332747]\n",
      "Iter-1792; D_loss: [ 0.52134496]; G_loss: [ 0.91356146]\n",
      "Iter-2048; D_loss: [ 0.50291115]; G_loss: [ 0.91532981]\n",
      "Iter-2304; D_loss: [ 0.49814346]; G_loss: [ 0.9226352]\n",
      "Iter-2560; D_loss: [ 0.50411725]; G_loss: [ 0.93346632]\n",
      "epoch: 9\n",
      "Iter-0; D_loss: [ 0.47336614]; G_loss: [ 0.92518413]\n",
      "Iter-256; D_loss: [ 0.50710547]; G_loss: [ 0.94795126]\n",
      "Iter-512; D_loss: [ 0.45884296]; G_loss: [ 0.93141288]\n",
      "Iter-768; D_loss: [ 0.46372485]; G_loss: [ 0.94187182]\n",
      "Iter-1024; D_loss: [ 0.46354318]; G_loss: [ 0.94739777]\n",
      "Iter-1280; D_loss: [ 0.46699476]; G_loss: [ 0.95348132]\n",
      "Iter-1536; D_loss: [ 0.46094686]; G_loss: [ 0.95159584]\n",
      "Iter-1792; D_loss: [ 0.46288237]; G_loss: [ 0.95638496]\n",
      "Iter-2048; D_loss: [ 0.44607762]; G_loss: [ 0.9566204]\n",
      "Iter-2304; D_loss: [ 0.44139284]; G_loss: [ 0.96464515]\n",
      "Iter-2560; D_loss: [ 0.44675568]; G_loss: [ 0.97786307]\n",
      "epoch: 10\n",
      "Iter-0; D_loss: [ 0.41666156]; G_loss: [ 0.97358459]\n",
      "Iter-256; D_loss: [ 0.44854516]; G_loss: [ 0.99956858]\n",
      "Iter-512; D_loss: [ 0.40132022]; G_loss: [ 0.98610401]\n",
      "Iter-768; D_loss: [ 0.40647811]; G_loss: [ 0.99865782]\n",
      "Iter-1024; D_loss: [ 0.40549731]; G_loss: [ 1.00744152]\n",
      "Iter-1280; D_loss: [ 0.40962446]; G_loss: [ 1.01354814]\n",
      "Iter-1536; D_loss: [ 0.4039396]; G_loss: [ 1.00976717]\n",
      "Iter-1792; D_loss: [ 0.40575135]; G_loss: [ 1.01749825]\n",
      "Iter-2048; D_loss: [ 0.3891564]; G_loss: [ 1.0189501]\n",
      "Iter-2304; D_loss: [ 0.38503695]; G_loss: [ 1.02700579]\n",
      "Iter-2560; D_loss: [ 0.39123592]; G_loss: [ 1.04001951]\n",
      "epoch: 11\n",
      "Iter-0; D_loss: [ 0.36332303]; G_loss: [ 1.03615797]\n",
      "Iter-256; D_loss: [ 0.39484036]; G_loss: [ 1.06144679]\n",
      "Iter-512; D_loss: [ 0.34981889]; G_loss: [ 1.04886234]\n",
      "Iter-768; D_loss: [ 0.35593745]; G_loss: [ 1.06125844]\n",
      "Iter-1024; D_loss: [ 0.35589898]; G_loss: [ 1.06906104]\n",
      "Iter-1280; D_loss: [ 0.36177778]; G_loss: [ 1.07129574]\n",
      "Iter-1536; D_loss: [ 0.35544389]; G_loss: [ 1.0678407]\n",
      "Iter-1792; D_loss: [ 0.35890478]; G_loss: [ 1.07417977]\n",
      "Iter-2048; D_loss: [ 0.34310406]; G_loss: [ 1.07475674]\n",
      "Iter-2304; D_loss: [ 0.33957267]; G_loss: [ 1.08219576]\n",
      "Iter-2560; D_loss: [ 0.34651589]; G_loss: [ 1.09452569]\n",
      "epoch: 12\n",
      "Iter-0; D_loss: [ 0.3206718]; G_loss: [ 1.09062827]\n",
      "Iter-256; D_loss: [ 0.35156447]; G_loss: [ 1.11461473]\n",
      "Iter-512; D_loss: [ 0.30916095]; G_loss: [ 1.10235035]\n",
      "Iter-768; D_loss: [ 0.31594223]; G_loss: [ 1.11444092]\n",
      "Iter-1024; D_loss: [ 0.31590241]; G_loss: [ 1.12300348]\n",
      "Iter-1280; D_loss: [ 0.31935984]; G_loss: [ 1.13322031]\n",
      "Iter-1536; D_loss: [ 0.31041345]; G_loss: [ 1.13707042]\n",
      "Iter-1792; D_loss: [ 0.31378099]; G_loss: [ 1.14707994]\n",
      "Iter-2048; D_loss: [ 0.29866406]; G_loss: [ 1.14779544]\n",
      "Iter-2304; D_loss: [ 0.29567528]; G_loss: [ 1.15457928]\n",
      "Iter-2560; D_loss: [ 0.30336303]; G_loss: [ 1.16648412]\n",
      "epoch: 13\n",
      "Iter-0; D_loss: [ 0.27937165]; G_loss: [ 1.16273618]\n",
      "Iter-256; D_loss: [ 0.3094174]; G_loss: [ 1.18554711]\n",
      "Iter-512; D_loss: [ 0.26960552]; G_loss: [ 1.17384291]\n",
      "Iter-768; D_loss: [ 0.27693507]; G_loss: [ 1.18547225]\n",
      "Iter-1024; D_loss: [ 0.27726826]; G_loss: [ 1.1935066]\n",
      "Iter-1280; D_loss: [ 0.28116077]; G_loss: [ 1.20323014]\n",
      "Iter-1536; D_loss: [ 0.27243385]; G_loss: [ 1.2064985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1792; D_loss: [ 0.27676672]; G_loss: [ 1.21630204]\n",
      "Iter-2048; D_loss: [ 0.26216698]; G_loss: [ 1.21661377]\n",
      "Iter-2304; D_loss: [ 0.25955397]; G_loss: [ 1.22293162]\n",
      "Iter-2560; D_loss: [ 0.26777136]; G_loss: [ 1.23446238]\n",
      "epoch: 14\n",
      "Iter-0; D_loss: [ 0.24537048]; G_loss: [ 1.23087752]\n",
      "Iter-256; D_loss: [ 0.27437285]; G_loss: [ 1.25253999]\n",
      "Iter-512; D_loss: [ 0.23701312]; G_loss: [ 1.24143851]\n",
      "Iter-768; D_loss: [ 0.24469703]; G_loss: [ 1.252635]\n",
      "Iter-1024; D_loss: [ 0.24523732]; G_loss: [ 1.26016581]\n",
      "Iter-1280; D_loss: [ 0.24937242]; G_loss: [ 1.26942325]\n",
      "Iter-1536; D_loss: [ 0.24084347]; G_loss: [ 1.27221727]\n",
      "Iter-1792; D_loss: [ 0.24592242]; G_loss: [ 1.2818172]\n",
      "Iter-2048; D_loss: [ 0.23176652]; G_loss: [ 1.28178883]\n",
      "Iter-2304; D_loss: [ 0.22941685]; G_loss: [ 1.28769159]\n",
      "Iter-2560; D_loss: [ 0.23805198]; G_loss: [ 1.29888654]\n",
      "epoch: 15\n",
      "Iter-0; D_loss: [ 0.21704008]; G_loss: [ 1.29544544]\n",
      "Iter-256; D_loss: [ 0.24488129]; G_loss: [ 1.3160013]\n",
      "Iter-512; D_loss: [ 0.20980944]; G_loss: [ 1.30551744]\n",
      "Iter-768; D_loss: [ 0.2177318]; G_loss: [ 1.31629443]\n",
      "Iter-1024; D_loss: [ 0.21837538]; G_loss: [ 1.32338917]\n",
      "Iter-1280; D_loss: [ 0.2226252]; G_loss: [ 1.33217514]\n",
      "Iter-1536; D_loss: [ 0.21427512]; G_loss: [ 1.33457696]\n",
      "Iter-1792; D_loss: [ 0.21993141]; G_loss: [ 1.3439678]\n",
      "Iter-2048; D_loss: [ 0.20618755]; G_loss: [ 1.34366977]\n",
      "Iter-2304; D_loss: [ 0.20403787]; G_loss: [ 1.34919202]\n",
      "Iter-2560; D_loss: [ 0.21299484]; G_loss: [ 1.36007881]\n",
      "epoch: 16\n",
      "Iter-0; D_loss: [ 0.19317926]; G_loss: [ 1.35676682]\n",
      "Iter-256; D_loss: [ 0.21981947]; G_loss: [ 1.37626517]\n",
      "Iter-512; D_loss: [ 0.18688139]; G_loss: [ 1.36638141]\n",
      "Iter-768; D_loss: [ 0.19494712]; G_loss: [ 1.37679148]\n",
      "Iter-1024; D_loss: [ 0.19565126]; G_loss: [ 1.38346863]\n",
      "Iter-1280; D_loss: [ 0.19989899]; G_loss: [ 1.39179599]\n",
      "Iter-1536; D_loss: [ 0.19172163]; G_loss: [ 1.39386308]\n",
      "Iter-1792; D_loss: [ 0.19783054]; G_loss: [ 1.40304327]\n",
      "Iter-2048; D_loss: [ 0.18446827]; G_loss: [ 1.40251184]\n",
      "Iter-2304; D_loss: [ 0.18248561]; G_loss: [ 1.40770233]\n",
      "Iter-2560; D_loss: [ 0.19167814]; G_loss: [ 1.41829014]\n",
      "epoch: 17\n",
      "Iter-0; D_loss: [ 0.1729307]; G_loss: [ 1.41510653]\n",
      "Iter-256; D_loss: [ 0.19833818]; G_loss: [ 1.43359113]\n",
      "Iter-512; D_loss: [ 0.16741237]; G_loss: [ 1.42431819]\n",
      "Iter-768; D_loss: [ 0.17553124]; G_loss: [ 1.43434644]\n",
      "Iter-1024; D_loss: [ 0.17627352]; G_loss: [ 1.44064307]\n",
      "Iter-1280; D_loss: [ 0.18043865]; G_loss: [ 1.44856334]\n",
      "Iter-1536; D_loss: [ 0.17242935]; G_loss: [ 1.45031798]\n",
      "Iter-1792; D_loss: [ 0.17889915]; G_loss: [ 1.45929682]\n",
      "Iter-2048; D_loss: [ 0.16590844]; G_loss: [ 1.45858645]\n",
      "Iter-2304; D_loss: [ 0.16405502]; G_loss: [ 1.46347976]\n",
      "Iter-2560; D_loss: [ 0.1734132]; G_loss: [ 1.47379017]\n",
      "epoch: 18\n",
      "Iter-0; D_loss: [ 0.15562278]; G_loss: [ 1.47070336]\n",
      "Iter-256; D_loss: [ 0.17980735]; G_loss: [ 1.48823464]\n",
      "Iter-512; D_loss: [ 0.15075818]; G_loss: [ 1.47953963]\n",
      "Iter-768; D_loss: [ 0.15885866]; G_loss: [ 1.4892087]\n",
      "Iter-1024; D_loss: [ 0.15962908]; G_loss: [ 1.49518156]\n",
      "Iter-1280; D_loss: [ 0.16363955]; G_loss: [ 1.50266421]\n",
      "Iter-1536; D_loss: [ 0.15581566]; G_loss: [ 1.50418031]\n",
      "Iter-1792; D_loss: [ 0.16254954]; G_loss: [ 1.51295388]\n",
      "Iter-2048; D_loss: [ 0.14992397]; G_loss: [ 1.51207495]\n",
      "Iter-2304; D_loss: [ 0.14816979]; G_loss: [ 1.51669729]\n",
      "Iter-2560; D_loss: [ 0.1576422]; G_loss: [ 1.52674603]\n",
      "epoch: 19\n",
      "Iter-0; D_loss: [ 0.14071253]; G_loss: [ 1.52377796]\n",
      "Iter-256; D_loss: [ 0.16369574]; G_loss: [ 1.54039836]\n",
      "Iter-512; D_loss: [ 0.136408]; G_loss: [ 1.53223109]\n",
      "Iter-768; D_loss: [ 0.14444327]; G_loss: [ 1.54156685]\n",
      "Iter-1024; D_loss: [ 0.14522798]; G_loss: [ 1.54723513]\n",
      "Iter-1280; D_loss: [ 0.14903948]; G_loss: [ 1.55431402]\n",
      "Iter-1536; D_loss: [ 0.14141294]; G_loss: [ 1.55563402]\n",
      "Iter-1792; D_loss: [ 0.14834785]; G_loss: [ 1.5641923]\n",
      "Iter-2048; D_loss: [ 0.13606709]; G_loss: [ 1.56321716]\n",
      "Iter-2304; D_loss: [ 0.13439572]; G_loss: [ 1.56757975]\n",
      "Iter-2560; D_loss: [ 0.14393775]; G_loss: [ 1.57736242]\n",
      "epoch: 20\n",
      "Iter-0; D_loss: [ 0.1277937]; G_loss: [ 1.57449603]\n",
      "Iter-256; D_loss: [ 0.1496129]; G_loss: [ 1.59024704]\n",
      "Iter-512; D_loss: [ 0.12395671]; G_loss: [ 1.58261681]\n",
      "Iter-768; D_loss: [ 0.13189733]; G_loss: [ 1.59161901]\n",
      "Iter-1024; D_loss: [ 0.13269502]; G_loss: [ 1.59701908]\n",
      "Iter-1280; D_loss: [ 0.13628069]; G_loss: [ 1.60369146]\n",
      "Iter-1536; D_loss: [ 0.1288556]; G_loss: [ 1.60485733]\n",
      "Iter-1792; D_loss: [ 0.13593347]; G_loss: [ 1.61321628]\n",
      "Iter-2048; D_loss: [ 0.12399114]; G_loss: [ 1.6121316]\n",
      "Iter-2304; D_loss: [ 0.12239039]; G_loss: [ 1.61626947]\n",
      "Iter-2560; D_loss: [ 0.13195023]; G_loss: [ 1.62580323]\n",
      "epoch: 21\n",
      "Iter-0; D_loss: [ 0.11652523]; G_loss: [ 1.62302744]\n",
      "Iter-256; D_loss: [ 0.1372419]; G_loss: [ 1.63799107]\n",
      "Iter-512; D_loss: [ 0.11309183]; G_loss: [ 1.63084006]\n",
      "Iter-768; D_loss: [ 0.12091133]; G_loss: [ 1.63951313]\n",
      "Iter-1024; D_loss: [ 0.12172297]; G_loss: [ 1.64467919]\n",
      "Iter-1280; D_loss: [ 0.12506917]; G_loss: [ 1.65100181]\n",
      "Iter-1536; D_loss: [ 0.11784431]; G_loss: [ 1.65200901]\n",
      "Iter-1792; D_loss: [ 0.12500794]; G_loss: [ 1.66015565]\n",
      "Iter-2048; D_loss: [ 0.11340511]; G_loss: [ 1.65900767]\n",
      "Iter-2304; D_loss: [ 0.11186285]; G_loss: [ 1.66293168]\n",
      "Iter-2560; D_loss: [ 0.12140015]; G_loss: [ 1.67221117]\n",
      "epoch: 22\n",
      "Iter-0; D_loss: [ 0.10664523]; G_loss: [ 1.66954041]\n",
      "Iter-256; D_loss: [ 0.126316]; G_loss: [ 1.68376195]\n",
      "Iter-512; D_loss: [ 0.1035562]; G_loss: [ 1.67707145]\n",
      "Iter-768; D_loss: [ 0.11123799]; G_loss: [ 1.6854459]\n",
      "Iter-1024; D_loss: [ 0.11206023]; G_loss: [ 1.69037473]\n",
      "Iter-1280; D_loss: [ 0.11516994]; G_loss: [ 1.69634604]\n",
      "Iter-1536; D_loss: [ 0.10814558]; G_loss: [ 1.69723916]\n",
      "Iter-1792; D_loss: [ 0.11535457]; G_loss: [ 1.70519459]\n",
      "Iter-2048; D_loss: [ 0.10408343]; G_loss: [ 1.70397878]\n",
      "Iter-2304; D_loss: [ 0.10259365]; G_loss: [ 1.70771122]\n",
      "Iter-2560; D_loss: [ 0.11207156]; G_loss: [ 1.71676028]\n",
      "epoch: 23\n",
      "Iter-0; D_loss: [ 0.0979507]; G_loss: [ 1.71417654]\n",
      "Iter-256; D_loss: [ 0.11663275]; G_loss: [ 1.72770691]\n",
      "Iter-512; D_loss: [ 0.09515229]; G_loss: [ 1.72143817]\n",
      "Iter-768; D_loss: [ 0.10267587]; G_loss: [ 1.7295351]\n",
      "Iter-1024; D_loss: [ 0.1035145]; G_loss: [ 1.73425388]\n",
      "Iter-1280; D_loss: [ 0.10638539]; G_loss: [ 1.73990762]\n",
      "Iter-1536; D_loss: [ 0.0995608]; G_loss: [ 1.74069059]\n",
      "Iter-1792; D_loss: [ 0.10678728]; G_loss: [ 1.74845159]\n",
      "Iter-2048; D_loss: [ 0.09584153]; G_loss: [ 1.74721622]\n",
      "Iter-2304; D_loss: [ 0.09439258]; G_loss: [ 1.75077415]\n",
      "Iter-2560; D_loss: [ 0.10378214]; G_loss: [ 1.75956917]\n",
      "epoch: 24\n",
      "Iter-0; D_loss: [ 0.09025545]; G_loss: [ 1.75709796]\n",
      "Iter-256; D_loss: [ 0.10800426]; G_loss: [ 1.76995182]\n",
      "Iter-512; D_loss: [ 0.08770519]; G_loss: [ 1.76408732]\n",
      "Iter-768; D_loss: [ 0.095055]; G_loss: [ 1.7718792]\n",
      "Iter-1024; D_loss: [ 0.09591344]; G_loss: [ 1.7764343]\n",
      "Iter-1280; D_loss: [ 0.09855044]; G_loss: [ 1.78178751]\n",
      "Iter-1536; D_loss: [ 0.09192698]; G_loss: [ 1.7824837]\n",
      "Iter-1792; D_loss: [ 0.09914345]; G_loss: [ 1.79006481]\n",
      "Iter-2048; D_loss: [ 0.08851424]; G_loss: [ 1.78879488]\n",
      "Iter-2304; D_loss: [ 0.08710673]; G_loss: [ 1.79219675]\n",
      "Iter-2560; D_loss: [ 0.09638096]; G_loss: [ 1.80075669]\n",
      "epoch: 25\n",
      "Iter-0; D_loss: [ 0.08341467]; G_loss: [ 1.79837286]\n",
      "Iter-256; D_loss: [ 0.10029162]; G_loss: [ 1.81064487]\n",
      "Iter-512; D_loss: [ 0.08108179]; G_loss: [ 1.80513048]\n",
      "Iter-768; D_loss: [ 0.08824942]; G_loss: [ 1.81265879]\n",
      "Iter-1024; D_loss: [ 0.08912681]; G_loss: [ 1.81705236]\n",
      "Iter-1280; D_loss: [ 0.09154283]; G_loss: [ 1.82210922]\n",
      "Iter-1536; D_loss: [ 0.08511385]; G_loss: [ 1.82273376]\n",
      "Iter-1792; D_loss: [ 0.09230341]; G_loss: [ 1.83013558]\n",
      "Iter-2048; D_loss: [ 0.08197381]; G_loss: [ 1.82884073]\n",
      "Iter-2304; D_loss: [ 0.08061364]; G_loss: [ 1.83210552]\n",
      "Iter-2560; D_loss: [ 0.08975282]; G_loss: [ 1.84043622]\n",
      "epoch: 26\n",
      "Iter-0; D_loss: [ 0.07731044]; G_loss: [ 1.83814692]\n",
      "Iter-256; D_loss: [ 0.09337443]; G_loss: [ 1.84984386]\n",
      "Iter-512; D_loss: [ 0.07516646]; G_loss: [ 1.84466565]\n",
      "Iter-768; D_loss: [ 0.08214678]; G_loss: [ 1.85195374]\n",
      "Iter-1024; D_loss: [ 0.08304372]; G_loss: [ 1.85618746]\n",
      "Iter-1280; D_loss: [ 0.08524664]; G_loss: [ 1.86097908]\n",
      "Iter-1536; D_loss: [ 0.0790115]; G_loss: [ 1.8615613]\n",
      "Iter-1792; D_loss: [ 0.08615808]; G_loss: [ 1.86876678]\n",
      "Iter-2048; D_loss: [ 0.07611586]; G_loss: [ 1.86746657]\n",
      "Iter-2304; D_loss: [ 0.07479766]; G_loss: [ 1.8705914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2560; D_loss: [ 0.08378975]; G_loss: [ 1.8787086]\n",
      "epoch: 27\n",
      "Iter-0; D_loss: [ 0.07184071]; G_loss: [ 1.8765049]\n",
      "Iter-256; D_loss: [ 0.0871416]; G_loss: [ 1.8876704]\n",
      "Iter-512; D_loss: [ 0.06986267]; G_loss: [ 1.88280761]\n",
      "Iter-768; D_loss: [ 0.07665399]; G_loss: [ 1.88984501]\n",
      "Iter-1024; D_loss: [ 0.07756819]; G_loss: [ 1.89394486]\n",
      "Iter-1280; D_loss: [ 0.07956991]; G_loss: [ 1.89850283]\n",
      "Iter-1536; D_loss: [ 0.07352354]; G_loss: [ 1.89902341]\n",
      "Iter-1792; D_loss: [ 0.08061391]; G_loss: [ 1.90605593]\n",
      "Iter-2048; D_loss: [ 0.07084855]; G_loss: [ 1.90476465]\n",
      "Iter-2304; D_loss: [ 0.06957343]; G_loss: [ 1.90776801]\n",
      "Iter-2560; D_loss: [ 0.07841022]; G_loss: [ 1.91566026]\n",
      "epoch: 28\n",
      "Iter-0; D_loss: [ 0.06692711]; G_loss: [ 1.91354525]\n",
      "Iter-256; D_loss: [ 0.08150792]; G_loss: [ 1.92423141]\n",
      "Iter-512; D_loss: [ 0.06509173]; G_loss: [ 1.91965246]\n",
      "Iter-768; D_loss: [ 0.07169279]; G_loss: [ 1.92644513]\n",
      "Iter-1024; D_loss: [ 0.07262332]; G_loss: [ 1.93041933]\n",
      "Iter-1280; D_loss: [ 0.07443468]; G_loss: [ 1.93474555]\n",
      "Iter-1536; D_loss: [ 0.06856816]; G_loss: [ 1.93520081]\n",
      "Iter-1792; D_loss: [ 0.0755925]; G_loss: [ 1.94209695]\n",
      "Iter-2048; D_loss: [ 0.06609691]; G_loss: [ 1.94080126]\n",
      "Iter-2304; D_loss: [ 0.0648654]; G_loss: [ 1.94368649]\n",
      "Iter-2560; D_loss: [ 0.07353531]; G_loss: [ 1.95136178]\n",
      "epoch: 29\n",
      "Iter-0; D_loss: [ 0.06249264]; G_loss: [ 1.94935524]\n",
      "Iter-256; D_loss: [ 0.07639708]; G_loss: [ 1.95956206]\n",
      "Iter-512; D_loss: [ 0.06078382]; G_loss: [ 1.955248]\n",
      "Iter-768; D_loss: [ 0.0671936]; G_loss: [ 1.96182299]\n",
      "Iter-1024; D_loss: [ 0.06814268]; G_loss: [ 1.96568382]\n",
      "Iter-1280; D_loss: [ 0.06977592]; G_loss: [ 1.96979666]\n",
      "Iter-1536; D_loss: [ 0.06408095]; G_loss: [ 1.97023416]\n",
      "Iter-1792; D_loss: [ 0.07103105]; G_loss: [ 1.97695553]\n",
      "Iter-2048; D_loss: [ 0.06179632]; G_loss: [ 1.97564542]\n",
      "Iter-2304; D_loss: [ 0.06060623]; G_loss: [ 1.97845781]\n",
      "Iter-2560; D_loss: [ 0.06910192]; G_loss: [ 1.98592162]\n",
      "epoch: 30\n",
      "Iter-0; D_loss: [ 0.0584789]; G_loss: [ 1.98399675]\n",
      "Iter-256; D_loss: [ 0.0717473]; G_loss: [ 1.99377525]\n",
      "Iter-512; D_loss: [ 0.05688159]; G_loss: [ 1.98971546]\n",
      "Iter-768; D_loss: [ 0.06310032]; G_loss: [ 1.99607408]\n",
      "Iter-1024; D_loss: [ 0.06406751]; G_loss: [ 1.99981856]\n",
      "Iter-1280; D_loss: [ 0.06553353]; G_loss: [ 2.00372481]\n",
      "Iter-1536; D_loss: [ 0.06000561]; G_loss: [ 2.00413966]\n",
      "Iter-1792; D_loss: [ 0.06687494]; G_loss: [ 2.01069021]\n",
      "Iter-2048; D_loss: [ 0.05789319]; G_loss: [ 2.00943446]\n",
      "Iter-2304; D_loss: [ 0.05674125]; G_loss: [ 2.0121181]\n",
      "Iter-2560; D_loss: [ 0.06505767]; G_loss: [ 2.01938891]\n",
      "epoch: 31\n",
      "Iter-0; D_loss: [ 0.05483244]; G_loss: [ 2.0175364]\n",
      "Iter-256; D_loss: [ 0.06750581]; G_loss: [ 2.0269196]\n",
      "Iter-512; D_loss: [ 0.05333345]; G_loss: [ 2.02307606]\n",
      "Iter-768; D_loss: [ 0.05936763]; G_loss: [ 2.02924466]\n",
      "Iter-1024; D_loss: [ 0.06035123]; G_loss: [ 2.03289127]\n",
      "Iter-1280; D_loss: [ 0.06165992]; G_loss: [ 2.03661227]\n",
      "Iter-1536; D_loss: [ 0.05629484]; G_loss: [ 2.03699327]\n",
      "Iter-1792; D_loss: [ 0.06307899]; G_loss: [ 2.04341125]\n",
      "Iter-2048; D_loss: [ 0.05434125]; G_loss: [ 2.04215193]\n",
      "Iter-2304; D_loss: [ 0.05322721]; G_loss: [ 2.04475474]\n",
      "Iter-2560; D_loss: [ 0.06135386]; G_loss: [ 2.05182409]\n",
      "epoch: 32\n",
      "Iter-0; D_loss: [ 0.05151281]; G_loss: [ 2.05006647]\n",
      "Iter-256; D_loss: [ 0.06362955]; G_loss: [ 2.0590775]\n",
      "Iter-512; D_loss: [ 0.05010064]; G_loss: [ 2.0554533]\n",
      "Iter-768; D_loss: [ 0.0559542]; G_loss: [ 2.06142688]\n",
      "Iter-1024; D_loss: [ 0.05695136]; G_loss: [ 2.06496382]\n",
      "Iter-1280; D_loss: [ 0.05811232]; G_loss: [ 2.06849861]\n",
      "Iter-1536; D_loss: [ 0.05290613]; G_loss: [ 2.06888032]\n",
      "Iter-1792; D_loss: [ 0.05959973]; G_loss: [ 2.07512689]\n",
      "Iter-2048; D_loss: [ 0.05109844]; G_loss: [ 2.0738883]\n",
      "Iter-2304; D_loss: [ 0.0500211]; G_loss: [ 2.07642722]\n",
      "Iter-2560; D_loss: [ 0.05795554]; G_loss: [ 2.08329105]\n",
      "epoch: 33\n",
      "Iter-0; D_loss: [ 0.04848047]; G_loss: [ 2.08161902]\n",
      "Iter-256; D_loss: [ 0.06007356]; G_loss: [ 2.09027553]\n",
      "Iter-512; D_loss: [ 0.04714618]; G_loss: [ 2.08684826]\n",
      "Iter-768; D_loss: [ 0.05282471]; G_loss: [ 2.09261966]\n",
      "Iter-1024; D_loss: [ 0.05383354]; G_loss: [ 2.09608364]\n",
      "Iter-1280; D_loss: [ 0.05485926]; G_loss: [ 2.09947896]\n",
      "Iter-1536; D_loss: [ 0.04980639]; G_loss: [ 2.09982157]\n",
      "Iter-1792; D_loss: [ 0.05640619]; G_loss: [ 2.10595107]\n",
      "Iter-2048; D_loss: [ 0.04813066]; G_loss: [ 2.10472536]\n",
      "Iter-2304; D_loss: [ 0.04708922]; G_loss: [ 2.10716963]\n",
      "Iter-2560; D_loss: [ 0.05482924]; G_loss: [ 2.11385608]\n",
      "epoch: 34\n",
      "Iter-0; D_loss: [ 0.04570443]; G_loss: [ 2.11226201]\n",
      "Iter-256; D_loss: [ 0.05682021]; G_loss: [ 2.12009501]\n",
      "Iter-512; D_loss: [ 0.04567266]; G_loss: [ 2.07968044]\n",
      "Iter-768; D_loss: [ 0.05113602]; G_loss: [ 2.08694673]\n",
      "Iter-1024; D_loss: [ 0.05209705]; G_loss: [ 2.09157777]\n",
      "Iter-1280; D_loss: [ 0.05295919]; G_loss: [ 2.09552431]\n",
      "Iter-1536; D_loss: [ 0.048025]; G_loss: [ 2.09639215]\n",
      "Iter-1792; D_loss: [ 0.05451092]; G_loss: [ 2.10290956]\n",
      "Iter-2048; D_loss: [ 0.04642839]; G_loss: [ 2.1022408]\n",
      "Iter-2304; D_loss: [ 0.04539978]; G_loss: [ 2.10514736]\n",
      "Iter-2560; D_loss: [ 0.05292676]; G_loss: [ 2.11218023]\n",
      "epoch: 35\n",
      "Iter-0; D_loss: [ 0.04412007]; G_loss: [ 2.11116815]\n",
      "Iter-256; D_loss: [ 0.05474157]; G_loss: [ 2.11954713]\n",
      "Iter-512; D_loss: [ 0.04288433]; G_loss: [ 2.11682105]\n",
      "Iter-768; D_loss: [ 0.04821046]; G_loss: [ 2.1225605]\n",
      "Iter-1024; D_loss: [ 0.04922196]; G_loss: [ 2.1260941]\n",
      "Iter-1280; D_loss: [ 0.0500113]; G_loss: [ 2.12943625]\n",
      "Iter-1536; D_loss: [ 0.04522992]; G_loss: [ 2.13000989]\n",
      "Iter-1792; D_loss: [ 0.05162652]; G_loss: [ 2.13610506]\n",
      "Iter-2048; D_loss: [ 0.04376158]; G_loss: [ 2.13515449]\n",
      "Iter-2304; D_loss: [ 0.04277519]; G_loss: [ 2.13770509]\n",
      "Iter-2560; D_loss: [ 0.0501186]; G_loss: [ 2.14426899]\n",
      "epoch: 36\n",
      "Iter-0; D_loss: [ 0.04164211]; G_loss: [ 2.14305139]\n",
      "Iter-256; D_loss: [ 0.05183823]; G_loss: [ 2.15100574]\n",
      "Iter-512; D_loss: [ 0.04047763]; G_loss: [ 2.14831972]\n",
      "Iter-768; D_loss: [ 0.04564916]; G_loss: [ 2.15382719]\n",
      "Iter-1024; D_loss: [ 0.0466675]; G_loss: [ 2.15725303]\n",
      "Iter-1280; D_loss: [ 0.0473554]; G_loss: [ 2.16046071]\n",
      "Iter-1536; D_loss: [ 0.04271297]; G_loss: [ 2.16099358]\n",
      "Iter-1792; D_loss: [ 0.0490071]; G_loss: [ 2.16691852]\n",
      "Iter-2048; D_loss: [ 0.0413496]; G_loss: [ 2.16598892]\n",
      "Iter-2304; D_loss: [ 0.04039627]; G_loss: [ 2.16845632]\n",
      "Iter-2560; D_loss: [ 0.04755046]; G_loss: [ 2.17483068]\n",
      "epoch: 37\n",
      "Iter-0; D_loss: [ 0.0393797]; G_loss: [ 2.17364931]\n",
      "Iter-256; D_loss: [ 0.04916936]; G_loss: [ 2.18121386]\n",
      "Iter-512; D_loss: [ 0.03827327]; G_loss: [ 2.17856169]\n",
      "Iter-768; D_loss: [ 0.04329446]; G_loss: [ 2.18379164]\n",
      "Iter-1024; D_loss: [ 0.04431934]; G_loss: [ 2.18702435]\n",
      "Iter-1280; D_loss: [ 0.04491597]; G_loss: [ 2.18998981]\n",
      "Iter-1536; D_loss: [ 0.04040878]; G_loss: [ 2.19040823]\n",
      "Iter-1792; D_loss: [ 0.04659981]; G_loss: [ 2.19611025]\n",
      "Iter-2048; D_loss: [ 0.03914497]; G_loss: [ 2.1950841]\n",
      "Iter-2304; D_loss: [ 0.03822514]; G_loss: [ 2.19737506]\n",
      "Iter-2560; D_loss: [ 0.04519521]; G_loss: [ 2.20347738]\n",
      "epoch: 38\n",
      "Iter-0; D_loss: [ 0.03731409]; G_loss: [ 2.20227671]\n",
      "Iter-256; D_loss: [ 0.04672531]; G_loss: [ 2.20955896]\n",
      "Iter-512; D_loss: [ 0.0362622]; G_loss: [ 2.20703793]\n",
      "Iter-768; D_loss: [ 0.04113513]; G_loss: [ 2.21213078]\n",
      "Iter-1024; D_loss: [ 0.04216414]; G_loss: [ 2.21527648]\n",
      "Iter-1280; D_loss: [ 0.04267337]; G_loss: [ 2.21812296]\n",
      "Iter-1536; D_loss: [ 0.03829307]; G_loss: [ 2.21851587]\n",
      "Iter-1792; D_loss: [ 0.04437842]; G_loss: [ 2.22409534]\n",
      "Iter-2048; D_loss: [ 0.03711668]; G_loss: [ 2.22308612]\n",
      "Iter-2304; D_loss: [ 0.03622842]; G_loss: [ 2.22531223]\n",
      "Iter-2560; D_loss: [ 0.04301526]; G_loss: [ 2.2312541]\n",
      "epoch: 39\n",
      "Iter-0; D_loss: [ 0.03540803]; G_loss: [ 2.23011351]\n",
      "Iter-256; D_loss: [ 0.04445883]; G_loss: [ 2.23713803]\n",
      "Iter-512; D_loss: [ 0.03440417]; G_loss: [ 2.23475003]\n",
      "Iter-768; D_loss: [ 0.03913301]; G_loss: [ 2.23968434]\n",
      "Iter-1024; D_loss: [ 0.04016464]; G_loss: [ 2.24275804]\n",
      "Iter-1280; D_loss: [ 0.0405924]; G_loss: [ 2.24548292]\n",
      "Iter-1536; D_loss: [ 0.0363354]; G_loss: [ 2.24586391]\n",
      "Iter-1792; D_loss: [ 0.04231409]; G_loss: [ 2.25132322]\n",
      "Iter-2048; D_loss: [ 0.03523939]; G_loss: [ 2.25031686]\n",
      "Iter-2304; D_loss: [ 0.03438172]; G_loss: [ 2.25249553]\n",
      "Iter-2560; D_loss: [ 0.04098724]; G_loss: [ 2.25827932]\n",
      "epoch: 40\n",
      "Iter-0; D_loss: [ 0.03364308]; G_loss: [ 2.25718045]\n",
      "Iter-256; D_loss: [ 0.04235175]; G_loss: [ 2.26397252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-512; D_loss: [ 0.03268298]; G_loss: [ 2.26170564]\n",
      "Iter-768; D_loss: [ 0.03727275]; G_loss: [ 2.26649308]\n",
      "Iter-1024; D_loss: [ 0.03830585]; G_loss: [ 2.26949835]\n",
      "Iter-1280; D_loss: [ 0.03865736]; G_loss: [ 2.27213287]\n",
      "Iter-1536; D_loss: [ 0.03452016]; G_loss: [ 2.27249384]\n",
      "Iter-1792; D_loss: [ 0.04039245]; G_loss: [ 2.2778132]\n",
      "Iter-2048; D_loss: [ 0.0334997]; G_loss: [ 2.27685738]\n",
      "Iter-2304; D_loss: [ 0.03267001]; G_loss: [ 2.27898097]\n",
      "Iter-2560; D_loss: [ 0.03909652]; G_loss: [ 2.28458881]\n",
      "epoch: 41\n",
      "Iter-0; D_loss: [ 0.03200548]; G_loss: [ 2.28356147]\n",
      "Iter-256; D_loss: [ 0.04039101]; G_loss: [ 2.2901206]\n",
      "Iter-512; D_loss: [ 0.03108673]; G_loss: [ 2.2879653]\n",
      "Iter-768; D_loss: [ 0.0355415]; G_loss: [ 2.29261851]\n",
      "Iter-1024; D_loss: [ 0.03657472]; G_loss: [ 2.29556513]\n",
      "Iter-1280; D_loss: [ 0.03685643]; G_loss: [ 2.29807663]\n",
      "Iter-1536; D_loss: [ 0.03283458]; G_loss: [ 2.29844904]\n",
      "Iter-1792; D_loss: [ 0.03860277]; G_loss: [ 2.30365729]\n",
      "Iter-2048; D_loss: [ 0.03188303]; G_loss: [ 2.30270696]\n",
      "Iter-2304; D_loss: [ 0.03108139]; G_loss: [ 2.3047781]\n",
      "Iter-2560; D_loss: [ 0.0373325]; G_loss: [ 2.31023383]\n",
      "epoch: 42\n",
      "Iter-0; D_loss: [ 0.03048415]; G_loss: [ 2.30928016]\n",
      "Iter-256; D_loss: [ 0.03856226]; G_loss: [ 2.31562757]\n",
      "Iter-512; D_loss: [ 0.02960277]; G_loss: [ 2.3135705]\n",
      "Iter-768; D_loss: [ 0.03392728]; G_loss: [ 2.31808901]\n",
      "Iter-1024; D_loss: [ 0.03495894]; G_loss: [ 2.32096744]\n",
      "Iter-1280; D_loss: [ 0.0351759]; G_loss: [ 2.32338929]\n",
      "Iter-1536; D_loss: [ 0.03126702]; G_loss: [ 2.32375193]\n",
      "Iter-1792; D_loss: [ 0.0369312]; G_loss: [ 2.32884383]\n",
      "Iter-2048; D_loss: [ 0.0303789]; G_loss: [ 2.32791615]\n",
      "Iter-2304; D_loss: [ 0.02960405]; G_loss: [ 2.32994056]\n",
      "Iter-2560; D_loss: [ 0.0356831]; G_loss: [ 2.3352561]\n",
      "epoch: 43\n",
      "Iter-0; D_loss: [ 0.02906689]; G_loss: [ 2.33434653]\n",
      "Iter-256; D_loss: [ 0.03685341]; G_loss: [ 2.34048605]\n",
      "Iter-512; D_loss: [ 0.02822017]; G_loss: [ 2.33852243]\n",
      "Iter-768; D_loss: [ 0.03242024]; G_loss: [ 2.34293747]\n",
      "Iter-1024; D_loss: [ 0.03344856]; G_loss: [ 2.34574652]\n",
      "Iter-1280; D_loss: [ 0.03360602]; G_loss: [ 2.3480649]\n",
      "Iter-1536; D_loss: [ 0.02980689]; G_loss: [ 2.34844661]\n",
      "Iter-1792; D_loss: [ 0.03536819]; G_loss: [ 2.35343194]\n",
      "Iter-2048; D_loss: [ 0.02897799]; G_loss: [ 2.35253477]\n",
      "Iter-2304; D_loss: [ 0.02822819]; G_loss: [ 2.35449719]\n",
      "Iter-2560; D_loss: [ 0.03413985]; G_loss: [ 2.35967755]\n",
      "epoch: 44\n",
      "Iter-0; D_loss: [ 0.02774674]; G_loss: [ 2.35881186]\n",
      "Iter-256; D_loss: [ 0.0352571]; G_loss: [ 2.3647635]\n",
      "Iter-512; D_loss: [ 0.02693123]; G_loss: [ 2.36289549]\n",
      "Iter-768; D_loss: [ 0.03101109]; G_loss: [ 2.36717367]\n",
      "Iter-1024; D_loss: [ 0.03203518]; G_loss: [ 2.36993313]\n",
      "Iter-1280; D_loss: [ 0.03213891]; G_loss: [ 2.37218428]\n",
      "Iter-1536; D_loss: [ 0.02844356]; G_loss: [ 2.37254381]\n",
      "Iter-1792; D_loss: [ 0.03390382]; G_loss: [ 2.37742925]\n",
      "Iter-2048; D_loss: [ 0.02766926]; G_loss: [ 2.3765502]\n",
      "Iter-2304; D_loss: [ 0.02694441]; G_loss: [ 2.37845731]\n",
      "Iter-2560; D_loss: [ 0.03269243]; G_loss: [ 2.38351226]\n",
      "epoch: 45\n",
      "Iter-0; D_loss: [ 0.02651344]; G_loss: [ 2.38270235]\n",
      "Iter-256; D_loss: [ 0.03376155]; G_loss: [ 2.38847232]\n",
      "Iter-512; D_loss: [ 0.02572687]; G_loss: [ 2.38668466]\n",
      "Iter-768; D_loss: [ 0.02969128]; G_loss: [ 2.39087224]\n",
      "Iter-1024; D_loss: [ 0.03070951]; G_loss: [ 2.39356279]\n",
      "Iter-1280; D_loss: [ 0.0307641]; G_loss: [ 2.39574051]\n",
      "Iter-1536; D_loss: [ 0.02716947]; G_loss: [ 2.39608383]\n",
      "Iter-1792; D_loss: [ 0.03341831]; G_loss: [ 2.35240817]\n",
      "Iter-2048; D_loss: [ 0.02737603]; G_loss: [ 2.3500886]\n",
      "Iter-2304; D_loss: [ 0.02663521]; G_loss: [ 2.35413671]\n",
      "Iter-2560; D_loss: [ 0.03218136]; G_loss: [ 2.36092639]\n",
      "epoch: 46\n",
      "Iter-0; D_loss: [ 0.02617368]; G_loss: [ 2.36182904]\n",
      "Iter-256; D_loss: [ 0.03314324]; G_loss: [ 2.36896896]\n",
      "Iter-512; D_loss: [ 0.02535207]; G_loss: [ 2.36857605]\n",
      "Iter-768; D_loss: [ 0.02917779]; G_loss: [ 2.37361503]\n",
      "Iter-1024; D_loss: [ 0.03016946]; G_loss: [ 2.37678218]\n",
      "Iter-1280; D_loss: [ 0.03017885]; G_loss: [ 2.37933517]\n",
      "Iter-1536; D_loss: [ 0.02666697]; G_loss: [ 2.38012815]\n",
      "Iter-1792; D_loss: [ 0.03192598]; G_loss: [ 2.38523674]\n",
      "Iter-2048; D_loss: [ 0.02596528]; G_loss: [ 2.38478851]\n",
      "Iter-2304; D_loss: [ 0.02527824]; G_loss: [ 2.38698125]\n",
      "Iter-2560; D_loss: [ 0.03070369]; G_loss: [ 2.39206147]\n",
      "epoch: 47\n",
      "Iter-0; D_loss: [ 0.02492481]; G_loss: [ 2.39164162]\n",
      "Iter-256; D_loss: [ 0.03168461]; G_loss: [ 2.39735794]\n",
      "Iter-512; D_loss: [ 0.0241733]; G_loss: [ 2.39603186]\n",
      "Iter-768; D_loss: [ 0.02791048]; G_loss: [ 2.40028644]\n",
      "Iter-1024; D_loss: [ 0.02890559]; G_loss: [ 2.40316129]\n",
      "Iter-1280; D_loss: [ 0.02888021]; G_loss: [ 2.40547371]\n",
      "Iter-1536; D_loss: [ 0.02546476]; G_loss: [ 2.40602827]\n",
      "Iter-1792; D_loss: [ 0.03063055]; G_loss: [ 2.41083121]\n",
      "Iter-2048; D_loss: [ 0.02481472]; G_loss: [ 2.41021991]\n",
      "Iter-2304; D_loss: [ 0.02415176]; G_loss: [ 2.41222048]\n",
      "Iter-2560; D_loss: [ 0.02943041]; G_loss: [ 2.41709805]\n",
      "epoch: 48\n",
      "Iter-0; D_loss: [ 0.02384192]; G_loss: [ 2.41663265]\n",
      "Iter-256; D_loss: [ 0.03038057]; G_loss: [ 2.42210388]\n",
      "Iter-512; D_loss: [ 0.02311588]; G_loss: [ 2.42076397]\n",
      "Iter-768; D_loss: [ 0.0267537]; G_loss: [ 2.42482853]\n",
      "Iter-1024; D_loss: [ 0.02774252]; G_loss: [ 2.42757058]\n",
      "Iter-1280; D_loss: [ 0.02768009]; G_loss: [ 2.42974997]\n",
      "Iter-1536; D_loss: [ 0.02435815]; G_loss: [ 2.43028235]\n",
      "Iter-1792; D_loss: [ 0.0294268]; G_loss: [ 2.43497634]\n",
      "Iter-2048; D_loss: [ 0.02374974]; G_loss: [ 2.43436623]\n",
      "Iter-2304; D_loss: [ 0.02310799]; G_loss: [ 2.43632889]\n",
      "Iter-2560; D_loss: [ 0.02824037]; G_loss: [ 2.4410727]\n",
      "epoch: 49\n",
      "Iter-0; D_loss: [ 0.02283401]; G_loss: [ 2.44063759]\n",
      "Iter-256; D_loss: [ 0.02916092]; G_loss: [ 2.44594622]\n",
      "Iter-512; D_loss: [ 0.02212964]; G_loss: [ 2.44467163]\n",
      "Iter-768; D_loss: [ 0.02566977]; G_loss: [ 2.44862199]\n",
      "Iter-1024; D_loss: [ 0.02665167]; G_loss: [ 2.45128727]\n",
      "Iter-1280; D_loss: [ 0.02655463]; G_loss: [ 2.45338798]\n",
      "Iter-1536; D_loss: [ 0.02332232]; G_loss: [ 2.45389462]\n",
      "Iter-1792; D_loss: [ 0.02829497]; G_loss: [ 2.45843601]\n",
      "Iter-2048; D_loss: [ 0.0227528]; G_loss: [ 2.45781684]\n",
      "Iter-2304; D_loss: [ 0.02213209]; G_loss: [ 2.45968604]\n",
      "Iter-2560; D_loss: [ 0.02712367]; G_loss: [ 2.46427917]\n",
      "epoch: 50\n",
      "Iter-0; D_loss: [ 0.02189121]; G_loss: [ 2.46384168]\n",
      "Iter-256; D_loss: [ 0.02801631]; G_loss: [ 2.46895552]\n",
      "Iter-512; D_loss: [ 0.02120813]; G_loss: [ 2.46770048]\n",
      "Iter-768; D_loss: [ 0.02465397]; G_loss: [ 2.47151327]\n",
      "Iter-1024; D_loss: [ 0.02562988]; G_loss: [ 2.47410321]\n",
      "Iter-1280; D_loss: [ 0.02550017]; G_loss: [ 2.47610545]\n",
      "Iter-1536; D_loss: [ 0.02235504]; G_loss: [ 2.47659564]\n",
      "Iter-1792; D_loss: [ 0.02723272]; G_loss: [ 2.48104596]\n",
      "Iter-2048; D_loss: [ 0.0218204]; G_loss: [ 2.48042822]\n",
      "Iter-2304; D_loss: [ 0.02121962]; G_loss: [ 2.48226762]\n",
      "Iter-2560; D_loss: [ 0.02607348]; G_loss: [ 2.48673058]\n",
      "epoch: 51\n",
      "Iter-0; D_loss: [ 0.02100728]; G_loss: [ 2.48631287]\n",
      "Iter-256; D_loss: [ 0.02693957]; G_loss: [ 2.49128866]\n",
      "Iter-512; D_loss: [ 0.02034378]; G_loss: [ 2.49008346]\n",
      "Iter-768; D_loss: [ 0.02369848]; G_loss: [ 2.49378705]\n",
      "Iter-1024; D_loss: [ 0.02466713]; G_loss: [ 2.49628663]\n",
      "Iter-1280; D_loss: [ 0.02450753]; G_loss: [ 2.49817657]\n",
      "Iter-1536; D_loss: [ 0.02144666]; G_loss: [ 2.49862194]\n",
      "Iter-1792; D_loss: [ 0.02623133]; G_loss: [ 2.50295758]\n",
      "Iter-2048; D_loss: [ 0.02094594]; G_loss: [ 2.50232601]\n",
      "Iter-2304; D_loss: [ 0.02036414]; G_loss: [ 2.50407624]\n",
      "Iter-2560; D_loss: [ 0.02508482]; G_loss: [ 2.50838423]\n",
      "epoch: 52\n",
      "Iter-0; D_loss: [ 0.02017904]; G_loss: [ 2.50798655]\n",
      "Iter-256; D_loss: [ 0.0259275]; G_loss: [ 2.51278853]\n",
      "Iter-512; D_loss: [ 0.01953505]; G_loss: [ 2.51160073]\n",
      "Iter-768; D_loss: [ 0.02280131]; G_loss: [ 2.51521087]\n",
      "Iter-1024; D_loss: [ 0.02376265]; G_loss: [ 2.51765418]\n",
      "Iter-1280; D_loss: [ 0.02357492]; G_loss: [ 2.51948547]\n",
      "Iter-1536; D_loss: [ 0.02059494]; G_loss: [ 2.51994228]\n",
      "Iter-1792; D_loss: [ 0.02528767]; G_loss: [ 2.52416015]\n",
      "Iter-2048; D_loss: [ 0.02012509]; G_loss: [ 2.5235498]\n",
      "Iter-2304; D_loss: [ 0.0195608]; G_loss: [ 2.5252769]\n",
      "Iter-2560; D_loss: [ 0.02415211]; G_loss: [ 2.52947378]\n",
      "epoch: 53\n",
      "Iter-0; D_loss: [ 0.01939887]; G_loss: [ 2.52910018]\n",
      "Iter-256; D_loss: [ 0.02497141]; G_loss: [ 2.53375554]\n",
      "Iter-512; D_loss: [ 0.01877303]; G_loss: [ 2.53262997]\n",
      "Iter-768; D_loss: [ 0.02195372]; G_loss: [ 2.53616405]\n",
      "Iter-1024; D_loss: [ 0.02290729]; G_loss: [ 2.53855252]\n",
      "Iter-1280; D_loss: [ 0.0226926]; G_loss: [ 2.54033875]\n",
      "Iter-1536; D_loss: [ 0.01979199]; G_loss: [ 2.5407691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1792; D_loss: [ 0.02439437]; G_loss: [ 2.5449295]\n",
      "Iter-2048; D_loss: [ 0.01935064]; G_loss: [ 2.54433155]\n",
      "Iter-2304; D_loss: [ 0.01880373]; G_loss: [ 2.54601455]\n",
      "Iter-2560; D_loss: [ 0.02326893]; G_loss: [ 2.55012441]\n",
      "epoch: 54\n",
      "Iter-0; D_loss: [ 0.01866313]; G_loss: [ 2.54976702]\n",
      "Iter-256; D_loss: [ 0.02406713]; G_loss: [ 2.55431485]\n",
      "Iter-512; D_loss: [ 0.01805409]; G_loss: [ 2.55323243]\n",
      "Iter-768; D_loss: [ 0.02115223]; G_loss: [ 2.55667353]\n",
      "Iter-1024; D_loss: [ 0.0220972]; G_loss: [ 2.55902481]\n",
      "Iter-1280; D_loss: [ 0.02185854]; G_loss: [ 2.5607543]\n",
      "Iter-1536; D_loss: [ 0.01903457]; G_loss: [ 2.56120753]\n",
      "Iter-1792; D_loss: [ 0.02354806]; G_loss: [ 2.56526709]\n",
      "Iter-2048; D_loss: [ 0.01861956]; G_loss: [ 2.56467438]\n",
      "Iter-2304; D_loss: [ 0.01808928]; G_loss: [ 2.56633186]\n",
      "Iter-2560; D_loss: [ 0.02243304]; G_loss: [ 2.57035327]\n",
      "epoch: 55\n",
      "Iter-0; D_loss: [ 0.01796747]; G_loss: [ 2.57001257]\n",
      "Iter-256; D_loss: [ 0.02321147]; G_loss: [ 2.57445598]\n",
      "Iter-512; D_loss: [ 0.01737485]; G_loss: [ 2.57342291]\n",
      "Iter-768; D_loss: [ 0.02039422]; G_loss: [ 2.57678008]\n",
      "Iter-1024; D_loss: [ 0.02132896]; G_loss: [ 2.57909083]\n",
      "Iter-1280; D_loss: [ 0.0210692]; G_loss: [ 2.58076501]\n",
      "Iter-1536; D_loss: [ 0.01831864]; G_loss: [ 2.58121514]\n",
      "Iter-1792; D_loss: [ 0.02274499]; G_loss: [ 2.5851779]\n",
      "Iter-2048; D_loss: [ 0.01792862]; G_loss: [ 2.58462787]\n",
      "Iter-2304; D_loss: [ 0.01741424]; G_loss: [ 2.5862546]\n",
      "Iter-2560; D_loss: [ 0.02163902]; G_loss: [ 2.59016418]\n",
      "epoch: 56\n",
      "Iter-0; D_loss: [ 0.0173097]; G_loss: [ 2.58986759]\n",
      "Iter-256; D_loss: [ 0.02240029]; G_loss: [ 2.59417677]\n",
      "Iter-512; D_loss: [ 0.01673241]; G_loss: [ 2.59319878]\n",
      "Iter-768; D_loss: [ 0.01967565]; G_loss: [ 2.59648347]\n",
      "Iter-1024; D_loss: [ 0.02060005]; G_loss: [ 2.59874249]\n",
      "Iter-1280; D_loss: [ 0.02032102]; G_loss: [ 2.60038257]\n",
      "Iter-1536; D_loss: [ 0.01764124]; G_loss: [ 2.60082555]\n",
      "Iter-1792; D_loss: [ 0.02198237]; G_loss: [ 2.6047132]\n",
      "Iter-2048; D_loss: [ 0.01727465]; G_loss: [ 2.6041882]\n",
      "Iter-2304; D_loss: [ 0.01677569]; G_loss: [ 2.60578322]\n",
      "Iter-2560; D_loss: [ 0.0208857]; G_loss: [ 2.60959601]\n",
      "epoch: 57\n",
      "Iter-0; D_loss: [ 0.01668644]; G_loss: [ 2.60932231]\n",
      "Iter-256; D_loss: [ 0.02163088]; G_loss: [ 2.61354899]\n",
      "Iter-512; D_loss: [ 0.01612434]; G_loss: [ 2.61259747]\n",
      "Iter-768; D_loss: [ 0.01899411]; G_loss: [ 2.61580348]\n",
      "Iter-1024; D_loss: [ 0.01990832]; G_loss: [ 2.61803722]\n",
      "Iter-1280; D_loss: [ 0.01961133]; G_loss: [ 2.61962748]\n",
      "Iter-1536; D_loss: [ 0.01700003]; G_loss: [ 2.62006855]\n",
      "Iter-1792; D_loss: [ 0.02125785]; G_loss: [ 2.62388539]\n",
      "Iter-2048; D_loss: [ 0.01665499]; G_loss: [ 2.62335515]\n",
      "Iter-2304; D_loss: [ 0.01617112]; G_loss: [ 2.62493587]\n",
      "Iter-2560; D_loss: [ 0.02016885]; G_loss: [ 2.62865281]\n",
      "epoch: 58\n",
      "Iter-0; D_loss: [ 0.01609614]; G_loss: [ 2.62841058]\n",
      "Iter-256; D_loss: [ 0.02090037]; G_loss: [ 2.63252044]\n",
      "Iter-512; D_loss: [ 0.01554846]; G_loss: [ 2.63162374]\n",
      "Iter-768; D_loss: [ 0.01834712]; G_loss: [ 2.63475752]\n",
      "Iter-1024; D_loss: [ 0.01925041]; G_loss: [ 2.63695526]\n",
      "Iter-1280; D_loss: [ 0.01893758]; G_loss: [ 2.63850284]\n",
      "Iter-1536; D_loss: [ 0.01639244]; G_loss: [ 2.63893247]\n",
      "Iter-1792; D_loss: [ 0.0205685]; G_loss: [ 2.64268661]\n",
      "Iter-2048; D_loss: [ 0.01606793]; G_loss: [ 2.64218521]\n",
      "Iter-2304; D_loss: [ 0.0155983]; G_loss: [ 2.64371514]\n",
      "Iter-2560; D_loss: [ 0.01948747]; G_loss: [ 2.64735532]\n",
      "epoch: 59\n",
      "Iter-0; D_loss: [ 0.01553581]; G_loss: [ 2.64715648]\n",
      "Iter-256; D_loss: [ 0.02020584]; G_loss: [ 2.65115404]\n",
      "Iter-512; D_loss: [ 0.01500227]; G_loss: [ 2.65030408]\n",
      "Iter-768; D_loss: [ 0.01773132]; G_loss: [ 2.65336156]\n",
      "Iter-1024; D_loss: [ 0.01862532]; G_loss: [ 2.65552092]\n",
      "Iter-1280; D_loss: [ 0.01829717]; G_loss: [ 2.65703344]\n",
      "Iter-1536; D_loss: [ 0.01581587]; G_loss: [ 2.65747261]\n",
      "Iter-1792; D_loss: [ 0.01991221]; G_loss: [ 2.6611495]\n",
      "Iter-2048; D_loss: [ 0.01551061]; G_loss: [ 2.66064477]\n",
      "Iter-2304; D_loss: [ 0.01505517]; G_loss: [ 2.66215754]\n",
      "Iter-2560; D_loss: [ 0.01883968]; G_loss: [ 2.6657269]\n",
      "epoch: 60\n",
      "Iter-0; D_loss: [ 0.01500409]; G_loss: [ 2.66553974]\n",
      "Iter-256; D_loss: [ 0.01954533]; G_loss: [ 2.66945219]\n",
      "Iter-512; D_loss: [ 0.01448376]; G_loss: [ 2.66863155]\n",
      "Iter-768; D_loss: [ 0.01714589]; G_loss: [ 2.67163467]\n",
      "Iter-1024; D_loss: [ 0.01803006]; G_loss: [ 2.67375135]\n",
      "Iter-1280; D_loss: [ 0.01768798]; G_loss: [ 2.67521739]\n",
      "Iter-1536; D_loss: [ 0.01526885]; G_loss: [ 2.67566681]\n",
      "Iter-1792; D_loss: [ 0.01928707]; G_loss: [ 2.67926669]\n",
      "Iter-2048; D_loss: [ 0.01498133]; G_loss: [ 2.67878318]\n",
      "Iter-2304; D_loss: [ 0.01453935]; G_loss: [ 2.68028355]\n",
      "Iter-2560; D_loss: [ 0.01822207]; G_loss: [ 2.68375349]\n",
      "epoch: 61\n",
      "Iter-0; D_loss: [ 0.01449866]; G_loss: [ 2.68360114]\n",
      "Iter-256; D_loss: [ 0.01891613]; G_loss: [ 2.68741655]\n",
      "Iter-512; D_loss: [ 0.01399106]; G_loss: [ 2.68662953]\n",
      "Iter-768; D_loss: [ 0.01658845]; G_loss: [ 2.68957353]\n",
      "Iter-1024; D_loss: [ 0.01746282]; G_loss: [ 2.6916604]\n",
      "Iter-1280; D_loss: [ 0.01710816]; G_loss: [ 2.69308448]\n",
      "Iter-1536; D_loss: [ 0.01474911]; G_loss: [ 2.6935215]\n",
      "Iter-1792; D_loss: [ 0.01869044]; G_loss: [ 2.69707346]\n",
      "Iter-2048; D_loss: [ 0.01447859]; G_loss: [ 2.69661546]\n",
      "Iter-2304; D_loss: [ 0.01404928]; G_loss: [ 2.69808459]\n",
      "Iter-2560; D_loss: [ 0.01763367]; G_loss: [ 2.70147061]\n",
      "epoch: 62\n",
      "Iter-0; D_loss: [ 0.01401791]; G_loss: [ 2.70135069]\n",
      "Iter-256; D_loss: [ 0.01831691]; G_loss: [ 2.70508146]\n",
      "Iter-512; D_loss: [ 0.01352244]; G_loss: [ 2.704319]\n",
      "Iter-768; D_loss: [ 0.0160571]; G_loss: [ 2.70720863]\n",
      "Iter-1024; D_loss: [ 0.01692188]; G_loss: [ 2.70925522]\n",
      "Iter-1280; D_loss: [ 0.01655574]; G_loss: [ 2.71065211]\n",
      "Iter-1536; D_loss: [ 0.01425457]; G_loss: [ 2.71109676]\n",
      "Iter-1792; D_loss: [ 0.01812029]; G_loss: [ 2.71455312]\n",
      "Iter-2048; D_loss: [ 0.01400036]; G_loss: [ 2.71413589]\n",
      "Iter-2304; D_loss: [ 0.01358308]; G_loss: [ 2.71557069]\n",
      "Iter-2560; D_loss: [ 0.01707244]; G_loss: [ 2.71888757]\n",
      "epoch: 63\n",
      "Iter-0; D_loss: [ 0.01356008]; G_loss: [ 2.7187829]\n",
      "Iter-256; D_loss: [ 0.01774502]; G_loss: [ 2.72241855]\n",
      "Iter-512; D_loss: [ 0.01307631]; G_loss: [ 2.72171259]\n",
      "Iter-768; D_loss: [ 0.01555069]; G_loss: [ 2.72454977]\n",
      "Iter-1024; D_loss: [ 0.01640545]; G_loss: [ 2.72655106]\n",
      "Iter-1280; D_loss: [ 0.01602916]; G_loss: [ 2.72791934]\n",
      "Iter-1536; D_loss: [ 0.01378409]; G_loss: [ 2.72835588]\n",
      "Iter-1792; D_loss: [ 0.01757645]; G_loss: [ 2.73177409]\n",
      "Iter-2048; D_loss: [ 0.01354474]; G_loss: [ 2.73134303]\n",
      "Iter-2304; D_loss: [ 0.01313945]; G_loss: [ 2.73277688]\n",
      "Iter-2560; D_loss: [ 0.01653673]; G_loss: [ 2.73601365]\n",
      "epoch: 64\n",
      "Iter-0; D_loss: [ 0.01312384]; G_loss: [ 2.73591971]\n",
      "Iter-256; D_loss: [ 0.01719945]; G_loss: [ 2.73949242]\n",
      "Iter-512; D_loss: [ 0.01265154]; G_loss: [ 2.73880434]\n",
      "Iter-768; D_loss: [ 0.0150674]; G_loss: [ 2.74158335]\n",
      "Iter-1024; D_loss: [ 0.0159116]; G_loss: [ 2.74355769]\n",
      "Iter-1280; D_loss: [ 0.01552678]; G_loss: [ 2.74489355]\n",
      "Iter-1536; D_loss: [ 0.01333584]; G_loss: [ 2.74533343]\n",
      "Iter-1792; D_loss: [ 0.01705663]; G_loss: [ 2.74869251]\n",
      "Iter-2048; D_loss: [ 0.01311069]; G_loss: [ 2.74828553]\n",
      "Iter-2304; D_loss: [ 0.01271672]; G_loss: [ 2.74968576]\n",
      "Iter-2560; D_loss: [ 0.01602526]; G_loss: [ 2.75285888]\n",
      "epoch: 65\n",
      "Iter-0; D_loss: [ 0.01270798]; G_loss: [ 2.75278974]\n",
      "Iter-256; D_loss: [ 0.01667812]; G_loss: [ 2.75627351]\n",
      "Iter-512; D_loss: [ 0.01224658]; G_loss: [ 2.75560379]\n",
      "Iter-768; D_loss: [ 0.01460636]; G_loss: [ 2.75834155]\n",
      "Iter-1024; D_loss: [ 0.0154398]; G_loss: [ 2.76029277]\n",
      "Iter-1280; D_loss: [ 0.01504685]; G_loss: [ 2.76158643]\n",
      "Iter-1536; D_loss: [ 0.01290864]; G_loss: [ 2.7620368]\n",
      "Iter-1792; D_loss: [ 0.01655932]; G_loss: [ 2.76532245]\n",
      "Iter-2048; D_loss: [ 0.01269693]; G_loss: [ 2.76493549]\n",
      "Iter-2304; D_loss: [ 0.01231379]; G_loss: [ 2.76630545]\n",
      "Iter-2560; D_loss: [ 0.01553537]; G_loss: [ 2.76942515]\n",
      "epoch: 66\n",
      "Iter-0; D_loss: [ 0.01231108]; G_loss: [ 2.76937938]\n",
      "Iter-256; D_loss: [ 0.01617999]; G_loss: [ 2.77278876]\n",
      "Iter-512; D_loss: [ 0.01186047]; G_loss: [ 2.77216291]\n",
      "Iter-768; D_loss: [ 0.01416606]; G_loss: [ 2.77483797]\n",
      "Iter-1024; D_loss: [ 0.01498835]; G_loss: [ 2.77674174]\n",
      "Iter-1280; D_loss: [ 0.01458861]; G_loss: [ 2.77801299]\n",
      "Iter-1536; D_loss: [ 0.0125012]; G_loss: [ 2.77848077]\n",
      "Iter-1792; D_loss: [ 0.01608317]; G_loss: [ 2.78171182]\n",
      "Iter-2048; D_loss: [ 0.01230204]; G_loss: [ 2.78132844]\n",
      "Iter-2304; D_loss: [ 0.01192956]; G_loss: [ 2.78269124]\n",
      "Iter-2560; D_loss: [ 0.01506739]; G_loss: [ 2.7857337]\n",
      "epoch: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [ 0.01193225]; G_loss: [ 2.7856977]\n",
      "Iter-256; D_loss: [ 0.01570341]; G_loss: [ 2.78903985]\n",
      "Iter-512; D_loss: [ 0.01149199]; G_loss: [ 2.78843975]\n",
      "Iter-768; D_loss: [ 0.01374506]; G_loss: [ 2.79105544]\n",
      "Iter-1024; D_loss: [ 0.01455577]; G_loss: [ 2.79294658]\n",
      "Iter-1280; D_loss: [ 0.01415039]; G_loss: [ 2.7942071]\n",
      "Iter-1536; D_loss: [ 0.0121122]; G_loss: [ 2.79464698]\n",
      "Iter-1792; D_loss: [ 0.01562694]; G_loss: [ 2.79781961]\n",
      "Iter-2048; D_loss: [ 0.0119248]; G_loss: [ 2.79745507]\n",
      "Iter-2304; D_loss: [ 0.01156259]; G_loss: [ 2.79879498]\n",
      "Iter-2560; D_loss: [ 0.01461897]; G_loss: [ 2.80177259]\n",
      "epoch: 68\n",
      "Iter-0; D_loss: [ 0.01157038]; G_loss: [ 2.80176783]\n",
      "Iter-256; D_loss: [ 0.01524737]; G_loss: [ 2.80504489]\n",
      "Iter-512; D_loss: [ 0.01113972]; G_loss: [ 2.80447245]\n",
      "Iter-768; D_loss: [ 0.01334243]; G_loss: [ 2.80703878]\n",
      "Iter-1024; D_loss: [ 0.01414126]; G_loss: [ 2.80890632]\n",
      "Iter-1280; D_loss: [ 0.01373129]; G_loss: [ 2.8101182]\n",
      "Iter-1536; D_loss: [ 0.01174088]; G_loss: [ 2.81057549]\n",
      "Iter-1792; D_loss: [ 0.01519014]; G_loss: [ 2.81369781]\n",
      "Iter-2048; D_loss: [ 0.01156405]; G_loss: [ 2.81333089]\n",
      "Iter-2304; D_loss: [ 0.01121213]; G_loss: [ 2.81466746]\n",
      "Iter-2560; D_loss: [ 0.01418927]; G_loss: [ 2.81758237]\n",
      "epoch: 69\n",
      "Iter-0; D_loss: [ 0.01122416]; G_loss: [ 2.8175869]\n",
      "Iter-256; D_loss: [ 0.01481046]; G_loss: [ 2.82078123]\n",
      "Iter-512; D_loss: [ 0.01080308]; G_loss: [ 2.82024145]\n",
      "Iter-768; D_loss: [ 0.01295688]; G_loss: [ 2.82277894]\n",
      "Iter-1024; D_loss: [ 0.01374384]; G_loss: [ 2.82459927]\n",
      "Iter-1280; D_loss: [ 0.01332991]; G_loss: [ 2.8258028]\n",
      "Iter-1536; D_loss: [ 0.01138542]; G_loss: [ 2.82624269]\n",
      "Iter-1792; D_loss: [ 0.01477063]; G_loss: [ 2.829319]\n",
      "Iter-2048; D_loss: [ 0.0112186]; G_loss: [ 2.82897949]\n",
      "Iter-2304; D_loss: [ 0.01087682]; G_loss: [ 2.83030343]\n",
      "Iter-2560; D_loss: [ 0.01377761]; G_loss: [ 2.8331604]\n",
      "epoch: 70\n",
      "Iter-0; D_loss: [ 0.01089283]; G_loss: [ 2.83318543]\n",
      "Iter-256; D_loss: [ 0.01439154]; G_loss: [ 2.83630753]\n",
      "Iter-512; D_loss: [ 0.01048081]; G_loss: [ 2.83580232]\n",
      "Iter-768; D_loss: [ 0.01258699]; G_loss: [ 2.83827615]\n",
      "Iter-1024; D_loss: [ 0.01336267]; G_loss: [ 2.84007144]\n",
      "Iter-1280; D_loss: [ 0.01294562]; G_loss: [ 2.84126472]\n",
      "Iter-1536; D_loss: [ 0.01104571]; G_loss: [ 2.84169579]\n",
      "Iter-1792; D_loss: [ 0.0143684]; G_loss: [ 2.84472919]\n",
      "Iter-2048; D_loss: [ 0.01088832]; G_loss: [ 2.84440851]\n",
      "Iter-2304; D_loss: [ 0.0105561]; G_loss: [ 2.84569931]\n",
      "Iter-2560; D_loss: [ 0.01338295]; G_loss: [ 2.84850335]\n",
      "epoch: 71\n",
      "Iter-0; D_loss: [ 0.01057589]; G_loss: [ 2.84853864]\n",
      "Iter-256; D_loss: [ 0.01398982]; G_loss: [ 2.8516047]\n",
      "Iter-512; D_loss: [ 0.010172]; G_loss: [ 2.85110068]\n",
      "Iter-768; D_loss: [ 0.01223271]; G_loss: [ 2.85353851]\n",
      "Iter-1024; D_loss: [ 0.01299691]; G_loss: [ 2.85532165]\n",
      "Iter-1280; D_loss: [ 0.01257691]; G_loss: [ 2.85647511]\n",
      "Iter-1536; D_loss: [ 0.01072051]; G_loss: [ 2.85687518]\n",
      "Iter-1792; D_loss: [ 0.01398375]; G_loss: [ 2.85968995]\n",
      "Iter-2048; D_loss: [ 0.01066195]; G_loss: [ 2.84695673]\n",
      "Iter-2304; D_loss: [ 0.01033506]; G_loss: [ 2.84913945]\n",
      "Iter-2560; D_loss: [ 0.01308309]; G_loss: [ 2.85311055]\n",
      "epoch: 72\n",
      "Iter-0; D_loss: [ 0.01034349]; G_loss: [ 2.85446596]\n",
      "Iter-256; D_loss: [ 0.01366756]; G_loss: [ 2.85879016]\n",
      "Iter-512; D_loss: [ 0.00993087]; G_loss: [ 2.8595705]\n",
      "Iter-768; D_loss: [ 0.01193814]; G_loss: [ 2.86316442]\n",
      "Iter-1024; D_loss: [ 0.01268291]; G_loss: [ 2.86598063]\n",
      "Iter-1280; D_loss: [ 0.012257]; G_loss: [ 2.86812091]\n",
      "Iter-1536; D_loss: [ 0.01043514]; G_loss: [ 2.86948037]\n",
      "Iter-1792; D_loss: [ 0.01363629]; G_loss: [ 2.87310553]\n",
      "Iter-2048; D_loss: [ 0.01028224]; G_loss: [ 2.87338161]\n",
      "Iter-2304; D_loss: [ 0.00996527]; G_loss: [ 2.87516403]\n",
      "Iter-2560; D_loss: [ 0.01264843]; G_loss: [ 2.87835002]\n",
      "epoch: 73\n",
      "Iter-0; D_loss: [ 0.00998782]; G_loss: [ 2.87890911]\n",
      "Iter-256; D_loss: [ 0.01323856]; G_loss: [ 2.88225961]\n",
      "Iter-512; D_loss: [ 0.00959419]; G_loss: [ 2.88210821]\n",
      "Iter-768; D_loss: [ 0.0115634]; G_loss: [ 2.88475585]\n",
      "Iter-1024; D_loss: [ 0.01230226]; G_loss: [ 2.88681126]\n",
      "Iter-1280; D_loss: [ 0.01188181]; G_loss: [ 2.88821578]\n",
      "Iter-1536; D_loss: [ 0.01010435]; G_loss: [ 2.8889122]\n",
      "Iter-1792; D_loss: [ 0.01325451]; G_loss: [ 2.8920207]\n",
      "Iter-2048; D_loss: [ 0.00996568]; G_loss: [ 2.89196444]\n",
      "Iter-2304; D_loss: [ 0.00965963]; G_loss: [ 2.8934052]\n",
      "Iter-2560; D_loss: [ 0.01227773]; G_loss: [ 2.89618635]\n",
      "epoch: 74\n",
      "Iter-0; D_loss: [ 0.00969009]; G_loss: [ 2.8964107]\n",
      "Iter-256; D_loss: [ 0.01286692]; G_loss: [ 2.89942288]\n",
      "Iter-512; D_loss: [ 0.00930773]; G_loss: [ 2.89914203]\n",
      "Iter-768; D_loss: [ 0.01123658]; G_loss: [ 2.9015708]\n",
      "Iter-1024; D_loss: [ 0.01196479]; G_loss: [ 2.90340519]\n",
      "Iter-1280; D_loss: [ 0.01154456]; G_loss: [ 2.90462422]\n",
      "Iter-1536; D_loss: [ 0.00980722]; G_loss: [ 2.90520883]\n",
      "Iter-1792; D_loss: [ 0.01290278]; G_loss: [ 2.90812969]\n",
      "Iter-2048; D_loss: [ 0.00967794]; G_loss: [ 2.90795875]\n",
      "Iter-2304; D_loss: [ 0.00938095]; G_loss: [ 2.90925956]\n",
      "Iter-2560; D_loss: [ 0.01193528]; G_loss: [ 2.91195393]\n",
      "epoch: 75\n",
      "Iter-0; D_loss: [ 0.00941514]; G_loss: [ 2.91213608]\n",
      "Iter-256; D_loss: [ 0.01251874]; G_loss: [ 2.91507101]\n",
      "Iter-512; D_loss: [ 0.00904052]; G_loss: [ 2.91472507]\n",
      "Iter-768; D_loss: [ 0.01092956]; G_loss: [ 2.91706705]\n",
      "Iter-1024; D_loss: [ 0.01164697]; G_loss: [ 2.91879916]\n",
      "Iter-1280; D_loss: [ 0.01122613]; G_loss: [ 2.91991258]\n",
      "Iter-1536; D_loss: [ 0.0095274]; G_loss: [ 2.92040968]\n",
      "Iter-1792; D_loss: [ 0.01256842]; G_loss: [ 2.92323279]\n",
      "Iter-2048; D_loss: [ 0.00940647]; G_loss: [ 2.92302036]\n",
      "Iter-2304; D_loss: [ 0.00911764]; G_loss: [ 2.92427373]\n",
      "Iter-2560; D_loss: [ 0.01160957]; G_loss: [ 2.92685747]\n",
      "epoch: 76\n",
      "Iter-0; D_loss: [ 0.00915487]; G_loss: [ 2.92700815]\n",
      "Iter-256; D_loss: [ 0.01218711]; G_loss: [ 2.92985368]\n",
      "Iter-512; D_loss: [ 0.00878765]; G_loss: [ 2.92950869]\n",
      "Iter-768; D_loss: [ 0.01063756]; G_loss: [ 2.93177915]\n",
      "Iter-1024; D_loss: [ 0.01134432]; G_loss: [ 2.93347669]\n",
      "Iter-1280; D_loss: [ 0.01092267]; G_loss: [ 2.9345746]\n",
      "Iter-1536; D_loss: [ 0.00926121]; G_loss: [ 2.93507409]\n",
      "Iter-1792; D_loss: [ 0.01224853]; G_loss: [ 2.93784666]\n",
      "Iter-2048; D_loss: [ 0.00914701]; G_loss: [ 2.93763471]\n",
      "Iter-2304; D_loss: [ 0.0088661]; G_loss: [ 2.93886328]\n",
      "Iter-2560; D_loss: [ 0.01129735]; G_loss: [ 2.94140863]\n",
      "epoch: 77\n",
      "Iter-0; D_loss: [ 0.00890566]; G_loss: [ 2.941571]\n",
      "Iter-256; D_loss: [ 0.01186857]; G_loss: [ 2.94434905]\n",
      "Iter-512; D_loss: [ 0.0085453]; G_loss: [ 2.9440279]\n",
      "Iter-768; D_loss: [ 0.01035689]; G_loss: [ 2.94626999]\n",
      "Iter-1024; D_loss: [ 0.0110533]; G_loss: [ 2.94794488]\n",
      "Iter-1280; D_loss: [ 0.01063097]; G_loss: [ 2.94901967]\n",
      "Iter-1536; D_loss: [ 0.00900563]; G_loss: [ 2.9495151]\n",
      "Iter-1792; D_loss: [ 0.0119454]; G_loss: [ 2.95113659]\n",
      "Iter-2048; D_loss: [ 0.00930955]; G_loss: [ 2.88374901]\n",
      "Iter-2304; D_loss: [ 0.0090507]; G_loss: [ 2.88244438]\n",
      "Iter-2560; D_loss: [ 0.01141534]; G_loss: [ 2.88610268]\n",
      "epoch: 78\n",
      "Iter-0; D_loss: [ 0.0090769]; G_loss: [ 2.88745832]\n",
      "Iter-256; D_loss: [ 0.01196524]; G_loss: [ 2.8913033]\n",
      "Iter-512; D_loss: [ 0.00870778]; G_loss: [ 2.89204741]\n",
      "Iter-768; D_loss: [ 0.01047453]; G_loss: [ 2.89521217]\n",
      "Iter-1024; D_loss: [ 0.01115405]; G_loss: [ 2.8978548]\n",
      "Iter-1280; D_loss: [ 0.01072768]; G_loss: [ 2.89987063]\n",
      "Iter-1536; D_loss: [ 0.00912912]; G_loss: [ 2.90131903]\n",
      "Iter-1792; D_loss: [ 0.01200837]; G_loss: [ 2.90486836]\n",
      "Iter-2048; D_loss: [ 0.00901323]; G_loss: [ 2.90544844]\n",
      "Iter-2304; D_loss: [ 0.00874166]; G_loss: [ 2.90739322]\n",
      "Iter-2560; D_loss: [ 0.01105137]; G_loss: [ 2.91057134]\n",
      "epoch: 79\n",
      "Iter-0; D_loss: [ 0.00877651]; G_loss: [ 2.91150355]\n",
      "Iter-256; D_loss: [ 0.01160479]; G_loss: [ 2.91487217]\n",
      "Iter-512; D_loss: [ 0.00842055]; G_loss: [ 2.91526651]\n",
      "Iter-768; D_loss: [ 0.01015291]; G_loss: [ 2.91802669]\n",
      "Iter-1024; D_loss: [ 0.01082492]; G_loss: [ 2.92020035]\n",
      "Iter-1280; D_loss: [ 0.01040424]; G_loss: [ 2.92174244]\n",
      "Iter-1536; D_loss: [ 0.00884039]; G_loss: [ 2.92264223]\n",
      "Iter-1792; D_loss: [ 0.01167414]; G_loss: [ 2.92568707]\n",
      "Iter-2048; D_loss: [ 0.00873521]; G_loss: [ 2.92592168]\n",
      "Iter-2304; D_loss: [ 0.00847299]; G_loss: [ 2.92740297]\n",
      "Iter-2560; D_loss: [ 0.01073029]; G_loss: [ 2.93006349]\n",
      "epoch: 80\n",
      "Iter-0; D_loss: [ 0.00851559]; G_loss: [ 2.9305234]\n",
      "Iter-256; D_loss: [ 0.01128506]; G_loss: [ 2.93340302]\n",
      "Iter-512; D_loss: [ 0.00817209]; G_loss: [ 2.93337131]\n",
      "Iter-768; D_loss: [ 0.00987179]; G_loss: [ 2.93569064]\n",
      "Iter-1024; D_loss: [ 0.0105363]; G_loss: [ 2.93748856]\n",
      "Iter-1280; D_loss: [ 0.01011867]; G_loss: [ 2.93872881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1536; D_loss: [ 0.00858878]; G_loss: [ 2.93939614]\n",
      "Iter-1792; D_loss: [ 0.0113748]; G_loss: [ 2.94219017]\n",
      "Iter-2048; D_loss: [ 0.00849119]; G_loss: [ 2.94222069]\n",
      "Iter-2304; D_loss: [ 0.00823733]; G_loss: [ 2.9435823]\n",
      "Iter-2560; D_loss: [ 0.01044173]; G_loss: [ 2.94613075]\n",
      "epoch: 81\n",
      "Iter-0; D_loss: [ 0.00828198]; G_loss: [ 2.94652033]\n",
      "Iter-256; D_loss: [ 0.01099225]; G_loss: [ 2.94927526]\n",
      "Iter-512; D_loss: [ 0.00794639]; G_loss: [ 2.94917488]\n",
      "Iter-768; D_loss: [ 0.00961249]; G_loss: [ 2.95142722]\n",
      "Iter-1024; D_loss: [ 0.01026777]; G_loss: [ 2.95318675]\n",
      "Iter-1280; D_loss: [ 0.00985067]; G_loss: [ 2.95430088]\n",
      "Iter-1536; D_loss: [ 0.00835336]; G_loss: [ 2.95489812]\n",
      "Iter-1792; D_loss: [ 0.0110914]; G_loss: [ 2.95757508]\n",
      "Iter-2048; D_loss: [ 0.00826163]; G_loss: [ 2.95751143]\n",
      "Iter-2304; D_loss: [ 0.00801491]; G_loss: [ 2.95877528]\n",
      "Iter-2560; D_loss: [ 0.01016825]; G_loss: [ 2.96120906]\n",
      "epoch: 82\n",
      "Iter-0; D_loss: [ 0.00806164]; G_loss: [ 2.96152711]\n",
      "Iter-256; D_loss: [ 0.01071423]; G_loss: [ 2.96415663]\n",
      "Iter-512; D_loss: [ 0.00773333]; G_loss: [ 2.96401906]\n",
      "Iter-768; D_loss: [ 0.00936694]; G_loss: [ 2.96617413]\n",
      "Iter-1024; D_loss: [ 0.01001321]; G_loss: [ 2.96783972]\n",
      "Iter-1280; D_loss: [ 0.00959709]; G_loss: [ 2.96894503]\n",
      "Iter-1536; D_loss: [ 0.00813095]; G_loss: [ 2.96952271]\n",
      "Iter-1792; D_loss: [ 0.01082557]; G_loss: [ 2.97139621]\n",
      "Iter-2048; D_loss: [ 0.00804392]; G_loss: [ 2.97210574]\n",
      "Iter-2304; D_loss: [ 0.00780354]; G_loss: [ 2.97334361]\n",
      "Iter-2560; D_loss: [ 0.00990739]; G_loss: [ 2.97572541]\n",
      "epoch: 83\n",
      "Iter-0; D_loss: [ 0.00785136]; G_loss: [ 2.97605038]\n",
      "Iter-256; D_loss: [ 0.01044746]; G_loss: [ 2.97863674]\n",
      "Iter-512; D_loss: [ 0.00785393]; G_loss: [ 2.92208052]\n",
      "Iter-768; D_loss: [ 0.00947801]; G_loss: [ 2.92034483]\n",
      "Iter-1024; D_loss: [ 0.01011073]; G_loss: [ 2.92231894]\n",
      "Iter-1280; D_loss: [ 0.00968687]; G_loss: [ 2.92492294]\n",
      "Iter-1536; D_loss: [ 0.0082401]; G_loss: [ 2.92717385]\n",
      "Iter-1792; D_loss: [ 0.01087605]; G_loss: [ 2.93130374]\n",
      "Iter-2048; D_loss: [ 0.00813719]; G_loss: [ 2.93261504]\n",
      "Iter-2304; D_loss: [ 0.00789459]; G_loss: [ 2.93519139]\n",
      "Iter-2560; D_loss: [ 0.00994169]; G_loss: [ 2.93881536]\n",
      "epoch: 84\n",
      "Iter-0; D_loss: [ 0.00792981]; G_loss: [ 2.94034457]\n",
      "Iter-256; D_loss: [ 0.01046461]; G_loss: [ 2.94381094]\n",
      "Iter-512; D_loss: [ 0.00760155]; G_loss: [ 2.94444847]\n",
      "Iter-768; D_loss: [ 0.00916565]; G_loss: [ 2.94728541]\n",
      "Iter-1024; D_loss: [ 0.00978964]; G_loss: [ 2.94959331]\n",
      "Iter-1280; D_loss: [ 0.00937569]; G_loss: [ 2.95129418]\n",
      "Iter-1536; D_loss: [ 0.00796266]; G_loss: [ 2.95240545]\n",
      "Iter-1792; D_loss: [ 0.01056284]; G_loss: [ 2.95547414]\n",
      "Iter-2048; D_loss: [ 0.00787493]; G_loss: [ 2.95594478]\n",
      "Iter-2304; D_loss: [ 0.00764265]; G_loss: [ 2.95761108]\n",
      "Iter-2560; D_loss: [ 0.00964784]; G_loss: [ 2.9602983]\n",
      "epoch: 85\n",
      "Iter-0; D_loss: [ 0.00769022]; G_loss: [ 2.96103525]\n",
      "Iter-256; D_loss: [ 0.01017682]; G_loss: [ 2.96392798]\n",
      "Iter-512; D_loss: [ 0.00737549]; G_loss: [ 2.9641912]\n",
      "Iter-768; D_loss: [ 0.00891085]; G_loss: [ 2.96661925]\n",
      "Iter-1024; D_loss: [ 0.00952847]; G_loss: [ 2.9685812]\n",
      "Iter-1280; D_loss: [ 0.00911831]; G_loss: [ 2.96999454]\n",
      "Iter-1536; D_loss: [ 0.007735]; G_loss: [ 2.97091126]\n",
      "Iter-1792; D_loss: [ 0.01029276]; G_loss: [ 2.97371602]\n",
      "Iter-2048; D_loss: [ 0.00765326]; G_loss: [ 2.97397518]\n",
      "Iter-2304; D_loss: [ 0.0074276]; G_loss: [ 2.97545958]\n",
      "Iter-2560; D_loss: [ 0.00938844]; G_loss: [ 2.97797561]\n",
      "epoch: 86\n",
      "Iter-0; D_loss: [ 0.00747811]; G_loss: [ 2.97855091]\n",
      "Iter-256; D_loss: [ 0.00991417]; G_loss: [ 2.9812336]\n",
      "Iter-512; D_loss: [ 0.00717113]; G_loss: [ 2.98128796]\n",
      "Iter-768; D_loss: [ 0.00867816]; G_loss: [ 2.98344612]\n",
      "Iter-1024; D_loss: [ 0.00928827]; G_loss: [ 2.98515272]\n",
      "Iter-1280; D_loss: [ 0.00888102]; G_loss: [ 2.98633862]\n",
      "Iter-1536; D_loss: [ 0.00752637]; G_loss: [ 2.98703194]\n",
      "Iter-1792; D_loss: [ 0.01004251]; G_loss: [ 2.98964167]\n",
      "Iter-2048; D_loss: [ 0.0074506]; G_loss: [ 2.98974466]\n",
      "Iter-2304; D_loss: [ 0.00723067]; G_loss: [ 2.99106026]\n",
      "Iter-2560; D_loss: [ 0.00914869]; G_loss: [ 2.99341464]\n",
      "epoch: 87\n",
      "Iter-0; D_loss: [ 0.00728385]; G_loss: [ 2.99388456]\n",
      "Iter-256; D_loss: [ 0.00967035]; G_loss: [ 2.99645925]\n",
      "Iter-512; D_loss: [ 0.00698341]; G_loss: [ 2.99649072]\n",
      "Iter-768; D_loss: [ 0.00846203]; G_loss: [ 2.99862885]\n",
      "Iter-1024; D_loss: [ 0.00906329]; G_loss: [ 3.00031424]\n",
      "Iter-1280; D_loss: [ 0.0086578]; G_loss: [ 3.00146031]\n",
      "Iter-1536; D_loss: [ 0.00733018]; G_loss: [ 3.00215101]\n",
      "Iter-1792; D_loss: [ 0.00980445]; G_loss: [ 3.0047009]\n",
      "Iter-2048; D_loss: [ 0.00725849]; G_loss: [ 3.00481772]\n",
      "Iter-2304; D_loss: [ 0.00704354]; G_loss: [ 3.00612044]\n",
      "Iter-2560; D_loss: [ 0.00891921]; G_loss: [ 3.00841594]\n",
      "epoch: 88\n",
      "Iter-0; D_loss: [ 0.00709782]; G_loss: [ 3.00890136]\n",
      "Iter-256; D_loss: [ 0.00943568]; G_loss: [ 3.01140976]\n",
      "Iter-512; D_loss: [ 0.00680325]; G_loss: [ 3.0114522]\n",
      "Iter-768; D_loss: [ 0.00825401]; G_loss: [ 3.01353884]\n",
      "Iter-1024; D_loss: [ 0.00884662]; G_loss: [ 3.01520014]\n",
      "Iter-1280; D_loss: [ 0.00844288]; G_loss: [ 3.01631999]\n",
      "Iter-1536; D_loss: [ 0.00714161]; G_loss: [ 3.01700664]\n",
      "Iter-1792; D_loss: [ 0.00957526]; G_loss: [ 3.01951575]\n",
      "Iter-2048; D_loss: [ 0.00707372]; G_loss: [ 3.01960397]\n",
      "Iter-2304; D_loss: [ 0.00686364]; G_loss: [ 3.0208416]\n",
      "Iter-2560; D_loss: [ 0.00869882]; G_loss: [ 3.02305007]\n",
      "epoch: 89\n",
      "Iter-0; D_loss: [ 0.00691941]; G_loss: [ 3.02349186]\n",
      "Iter-256; D_loss: [ 0.00921017]; G_loss: [ 3.02590513]\n",
      "Iter-512; D_loss: [ 0.00663078]; G_loss: [ 3.02591896]\n",
      "Iter-768; D_loss: [ 0.00805471]; G_loss: [ 3.0279181]\n",
      "Iter-1024; D_loss: [ 0.00863892]; G_loss: [ 3.02949166]\n",
      "Iter-1280; D_loss: [ 0.00823742]; G_loss: [ 3.03055811]\n",
      "Iter-1536; D_loss: [ 0.00696195]; G_loss: [ 3.03118253]\n",
      "Iter-1792; D_loss: [ 0.00935584]; G_loss: [ 3.03359604]\n",
      "Iter-2048; D_loss: [ 0.00689811]; G_loss: [ 3.0336647]\n",
      "Iter-2304; D_loss: [ 0.00669263]; G_loss: [ 3.03489041]\n",
      "Iter-2560; D_loss: [ 0.0084881]; G_loss: [ 3.03706288]\n",
      "epoch: 90\n",
      "Iter-0; D_loss: [ 0.00674931]; G_loss: [ 3.03748894]\n",
      "Iter-256; D_loss: [ 0.00899396]; G_loss: [ 3.03986979]\n",
      "Iter-512; D_loss: [ 0.00646599]; G_loss: [ 3.03989506]\n",
      "Iter-768; D_loss: [ 0.00786362]; G_loss: [ 3.04185224]\n",
      "Iter-1024; D_loss: [ 0.00843921]; G_loss: [ 3.04340601]\n",
      "Iter-1280; D_loss: [ 0.00803985]; G_loss: [ 3.04444814]\n",
      "Iter-1536; D_loss: [ 0.00678932]; G_loss: [ 3.04507327]\n",
      "Iter-1792; D_loss: [ 0.00914434]; G_loss: [ 3.04746747]\n",
      "Iter-2048; D_loss: [ 0.00672886]; G_loss: [ 3.04752541]\n",
      "Iter-2304; D_loss: [ 0.00652787]; G_loss: [ 3.04873276]\n",
      "Iter-2560; D_loss: [ 0.00828483]; G_loss: [ 3.0508635]\n",
      "epoch: 91\n",
      "Iter-0; D_loss: [ 0.00658523]; G_loss: [ 3.05129242]\n",
      "Iter-256; D_loss: [ 0.00878524]; G_loss: [ 3.05362678]\n",
      "Iter-512; D_loss: [ 0.0063071]; G_loss: [ 3.05365896]\n",
      "Iter-768; D_loss: [ 0.00767904]; G_loss: [ 3.05558348]\n",
      "Iter-1024; D_loss: [ 0.00824631]; G_loss: [ 3.05712867]\n",
      "Iter-1280; D_loss: [ 0.00784913]; G_loss: [ 3.05815434]\n",
      "Iter-1536; D_loss: [ 0.00662294]; G_loss: [ 3.05877256]\n",
      "Iter-1792; D_loss: [ 0.00893957]; G_loss: [ 3.06112814]\n",
      "Iter-2048; D_loss: [ 0.00656571]; G_loss: [ 3.06119013]\n",
      "Iter-2304; D_loss: [ 0.00636902]; G_loss: [ 3.06237411]\n",
      "Iter-2560; D_loss: [ 0.00808851]; G_loss: [ 3.06445813]\n",
      "epoch: 92\n",
      "Iter-0; D_loss: [ 0.00642699]; G_loss: [ 3.06490731]\n",
      "Iter-256; D_loss: [ 0.00858341]; G_loss: [ 3.06719303]\n",
      "Iter-512; D_loss: [ 0.00615386]; G_loss: [ 3.06722403]\n",
      "Iter-768; D_loss: [ 0.00750099]; G_loss: [ 3.06913209]\n",
      "Iter-1024; D_loss: [ 0.00805999]; G_loss: [ 3.07063389]\n",
      "Iter-1280; D_loss: [ 0.00766498]; G_loss: [ 3.07164741]\n",
      "Iter-1536; D_loss: [ 0.00646241]; G_loss: [ 3.0722537]\n",
      "Iter-1792; D_loss: [ 0.00874177]; G_loss: [ 3.07457066]\n",
      "Iter-2048; D_loss: [ 0.00640835]; G_loss: [ 3.07463431]\n",
      "Iter-2304; D_loss: [ 0.00621589]; G_loss: [ 3.07581854]\n",
      "Iter-2560; D_loss: [ 0.00789909]; G_loss: [ 3.07787895]\n",
      "epoch: 93\n",
      "Iter-0; D_loss: [ 0.00627448]; G_loss: [ 3.07831001]\n",
      "Iter-256; D_loss: [ 0.00838851]; G_loss: [ 3.08056736]\n",
      "Iter-512; D_loss: [ 0.0060061]; G_loss: [ 3.08060694]\n",
      "Iter-768; D_loss: [ 0.00732902]; G_loss: [ 3.0824852]\n",
      "Iter-1024; D_loss: [ 0.00787967]; G_loss: [ 3.08397031]\n",
      "Iter-1280; D_loss: [ 0.00748705]; G_loss: [ 3.08495355]\n",
      "Iter-1536; D_loss: [ 0.00630759]; G_loss: [ 3.08556914]\n",
      "Iter-1792; D_loss: [ 0.00855041]; G_loss: [ 3.08784723]\n",
      "Iter-2048; D_loss: [ 0.00625652]; G_loss: [ 3.08790684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2304; D_loss: [ 0.00606812]; G_loss: [ 3.08907485]\n",
      "Iter-2560; D_loss: [ 0.00771587]; G_loss: [ 3.09110308]\n",
      "epoch: 94\n",
      "Iter-0; D_loss: [ 0.00612701]; G_loss: [ 3.09153724]\n",
      "Iter-256; D_loss: [ 0.00820007]; G_loss: [ 3.09374833]\n",
      "Iter-512; D_loss: [ 0.00586355]; G_loss: [ 3.09379458]\n",
      "Iter-768; D_loss: [ 0.00716269]; G_loss: [ 3.09563708]\n",
      "Iter-1024; D_loss: [ 0.00770538]; G_loss: [ 3.0971086]\n",
      "Iter-1280; D_loss: [ 0.00731521]; G_loss: [ 3.09808159]\n",
      "Iter-1536; D_loss: [ 0.00615813]; G_loss: [ 3.0986836]\n",
      "Iter-1792; D_loss: [ 0.00836497]; G_loss: [ 3.1009376]\n",
      "Iter-2048; D_loss: [ 0.00610983]; G_loss: [ 3.10101128]\n",
      "Iter-2304; D_loss: [ 0.00592543]; G_loss: [ 3.10215282]\n",
      "Iter-2560; D_loss: [ 0.00753896]; G_loss: [ 3.10413551]\n",
      "epoch: 95\n",
      "Iter-0; D_loss: [ 0.00598455]; G_loss: [ 3.10457301]\n",
      "Iter-256; D_loss: [ 0.00801758]; G_loss: [ 3.10674787]\n",
      "Iter-512; D_loss: [ 0.00572572]; G_loss: [ 3.10681057]\n",
      "Iter-768; D_loss: [ 0.00700172]; G_loss: [ 3.10862565]\n",
      "Iter-1024; D_loss: [ 0.00753668]; G_loss: [ 3.11007047]\n",
      "Iter-1280; D_loss: [ 0.00714893]; G_loss: [ 3.11103606]\n",
      "Iter-1536; D_loss: [ 0.0060137]; G_loss: [ 3.1116221]\n",
      "Iter-1792; D_loss: [ 0.00818536]; G_loss: [ 3.11384392]\n",
      "Iter-2048; D_loss: [ 0.00596818]; G_loss: [ 3.11391997]\n",
      "Iter-2304; D_loss: [ 0.00578765]; G_loss: [ 3.1150496]\n",
      "Iter-2560; D_loss: [ 0.00736759]; G_loss: [ 3.11700344]\n",
      "epoch: 96\n",
      "Iter-0; D_loss: [ 0.00584703]; G_loss: [ 3.11745214]\n",
      "Iter-256; D_loss: [ 0.00784131]; G_loss: [ 3.11960411]\n",
      "Iter-512; D_loss: [ 0.00559269]; G_loss: [ 3.11966181]\n",
      "Iter-768; D_loss: [ 0.00684616]; G_loss: [ 3.12144899]\n",
      "Iter-1024; D_loss: [ 0.00737326]; G_loss: [ 3.12287521]\n",
      "Iter-1280; D_loss: [ 0.0069881]; G_loss: [ 3.12382579]\n",
      "Iter-1536; D_loss: [ 0.0058741]; G_loss: [ 3.12440491]\n",
      "Iter-1792; D_loss: [ 0.00801135]; G_loss: [ 3.12659883]\n",
      "Iter-2048; D_loss: [ 0.00583113]; G_loss: [ 3.12667775]\n",
      "Iter-2304; D_loss: [ 0.00565434]; G_loss: [ 3.12776923]\n",
      "Iter-2560; D_loss: [ 0.00720197]; G_loss: [ 3.12970138]\n",
      "epoch: 97\n",
      "Iter-0; D_loss: [ 0.00571395]; G_loss: [ 3.13014078]\n",
      "Iter-256; D_loss: [ 0.00767053]; G_loss: [ 3.1322577]\n",
      "Iter-512; D_loss: [ 0.00546408]; G_loss: [ 3.13231945]\n",
      "Iter-768; D_loss: [ 0.00669564]; G_loss: [ 3.13409114]\n",
      "Iter-1024; D_loss: [ 0.00721519]; G_loss: [ 3.13550019]\n",
      "Iter-1280; D_loss: [ 0.00683257]; G_loss: [ 3.13642502]\n",
      "Iter-1536; D_loss: [ 0.00573924]; G_loss: [ 3.13702583]\n",
      "Iter-1792; D_loss: [ 0.00784274]; G_loss: [ 3.13917422]\n",
      "Iter-2048; D_loss: [ 0.00569871]; G_loss: [ 3.13924384]\n",
      "Iter-2304; D_loss: [ 0.00552556]; G_loss: [ 3.14034915]\n",
      "Iter-2560; D_loss: [ 0.00704167]; G_loss: [ 3.14223504]\n",
      "epoch: 98\n",
      "Iter-0; D_loss: [ 0.00558516]; G_loss: [ 3.14267492]\n",
      "Iter-256; D_loss: [ 0.00750508]; G_loss: [ 3.14476776]\n",
      "Iter-512; D_loss: [ 0.00533969]; G_loss: [ 3.14483714]\n",
      "Iter-768; D_loss: [ 0.00654981]; G_loss: [ 3.14656496]\n",
      "Iter-1024; D_loss: [ 0.00706194]; G_loss: [ 3.14796162]\n",
      "Iter-1280; D_loss: [ 0.00668186]; G_loss: [ 3.14888287]\n",
      "Iter-1536; D_loss: [ 0.0056087]; G_loss: [ 3.14945555]\n",
      "Iter-1792; D_loss: [ 0.00767913]; G_loss: [ 3.151582]\n",
      "Iter-2048; D_loss: [ 0.00557062]; G_loss: [ 3.15165377]\n",
      "Iter-2304; D_loss: [ 0.005401]; G_loss: [ 3.15275693]\n",
      "Iter-2560; D_loss: [ 0.00688652]; G_loss: [ 3.15461397]\n",
      "epoch: 99\n",
      "Iter-0; D_loss: [ 0.00546084]; G_loss: [ 3.15506411]\n",
      "Iter-256; D_loss: [ 0.0073448]; G_loss: [ 3.15710473]\n",
      "Iter-512; D_loss: [ 0.00521947]; G_loss: [ 3.15716767]\n",
      "Iter-768; D_loss: [ 0.00640862]; G_loss: [ 3.15889764]\n",
      "Iter-1024; D_loss: [ 0.00691345]; G_loss: [ 3.16025877]\n",
      "Iter-1280; D_loss: [ 0.00653599]; G_loss: [ 3.16116691]\n",
      "Iter-1536; D_loss: [ 0.00548253]; G_loss: [ 3.16174698]\n",
      "Iter-1792; D_loss: [ 0.00752046]; G_loss: [ 3.16384172]\n",
      "Iter-2048; D_loss: [ 0.0054467]; G_loss: [ 3.16392565]\n",
      "Iter-2304; D_loss: [ 0.00528043]; G_loss: [ 3.16500068]\n",
      "Iter-2560; D_loss: [ 0.00673608]; G_loss: [ 3.16682959]\n"
     ]
    }
   ],
   "source": [
    "batch_size = mb_size\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    \n",
    "\n",
    "    print('epoch:',epoch)\n",
    "    #for i in range(XX_train):\n",
    "    # Build mini-batch dataset\n",
    "    #batch_size = images.size(0)\n",
    "    #images = to_var(images.view(batch_size, -1))\n",
    "\n",
    "    it=0\n",
    "    while it+batch_size < len(X_train) :\n",
    "        \n",
    "\n",
    "        start= it\n",
    "        end= it + batch_size\n",
    "\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        X = X_train[start:end]\n",
    "\n",
    "        #c = Y_train[start:end]\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        #c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z, X)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        D_loss_real = binary_cross_entropy(D_real, ones_label)\n",
    "        D_loss_fake = binary_cross_entropy(D_fake, zeros_label)\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        D.zero_grad()\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "        G_sample = G(z, X)\n",
    "        X_fake = torch.cat([G_sample, X], 0)\n",
    "        D_fake = D(X_fake) #Here we need to give Xi along with Xg(i.e. Xg+X or G_sample+X)\n",
    "\n",
    "        G_loss = binary_cross_entropy(D_fake, ones_label_fake)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        D.zero_grad()\n",
    "\n",
    "        #Print and plot every now and then\n",
    "        #if it % 2 == 0:\n",
    "\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "        it+= batch_size\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF=pd.DataFrame()\n",
    "samples_per_class = 1000\n",
    "#c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "#c[:, np.random.randint(0, 10)] = 1.\n",
    "for i in range(14):\n",
    "    #print(i)\n",
    "    c = np.zeros(shape=[samples_per_class, y_dim], dtype='float32')\n",
    "    c[:, i] = 1.\n",
    "    c_df=pd.DataFrame(c)\n",
    "    df_SF = df_SF.append(c_df,ignore_index = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = df_SF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen = Variable(torch.randn(df_SF.shape[0], Z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gen = Variable(torch.from_numpy(c_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G(z_gen, c_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the generated iVectors we will try to check the acc by MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = samples.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = c_gen.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = pd.DataFrame(train_X1)\n",
    "train_y1 = pd.DataFrame(train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train.append(train_X1, ignore_index=True)\n",
    "train_y = Y_train.append(train_y1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X,  train_y = shuffle(train_X, train_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.values\n",
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = '/home/satishk/saved_weights/best_weights_2l_MLP_11.hdf5'\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epoch=30"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Checking Baseline Accuracy with only training data\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Baseline ERROR %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#train_X1 and train_y1 are the augmented data alone to check accuracy only on augmented data \n",
    "#feed the model.fit only with these\n",
    "train_X1 = train_X1.values\n",
    "train_y1 = train_y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Accuracy with training+augmented data train_X and train_y are 'train + augmented' data\n",
    "history = model.fit(train_X, train_y, batch_size=batch_size, epochs=nb_epoch,verbose=2, \n",
    "                    validation_data=(X_test , y_test),callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frame label accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('ERROR after Data Augmentation %:', 1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
